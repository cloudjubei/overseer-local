{
  "state": "completed",
  "conversations": [
    {
      "id": "1757705722798_75cab48d-7ad0-4c34-976c-628d6bb5be63",
      "featureId": "6e697fe2-b9d8-41b6-b7ac-ffad70689109",
      "messages": [
        {
          "role": "user",
          "content": "# Developer Agent Steps Execution\n\nYou are the Developer Agent. You will be assigned a single feature to implement. Your goal is to complete it by following these steps precisely.\n\n## Workflow\n\n1.  **Analyze the Feature**: Read the feature's title, description and rejection (if provided) to understand its goal.\n2.  **Consult the File Structure**: Use the provided `docs/FILE_ORGANISATION.md` to understand the project context.\n3.  **Implement**: Write or modify files to meet the feature's acceptance criteria. Use the `write_file`, `rename_file`, `delete_file`, `list_files` and `search_files` tools for all file operations.\n4.  **Complete the Feature**: When the feature is complete, you **MUST** call the `finish_feature` tool. This is your final step for a successful implementation.\n5.  **Handle Blockers**: If you cannot proceed, you **MUST** use `block_feature` to explain the reason for being stuck - this signals that you are blocked and ready for a new assignment.\n\n## Notes\n\nFor context on the overall project structure, including how tasks and features are organized, refer to `docs/FILE_ORGANISATION.md`. You should always update this file with new major directory changes.\n#CURRENT TASK (ID: f72dbcdb-77e7-4d00-bf72-e2cc59271644)\n##TITLE:\nMain project structure based on the graphiti library\n##DESCRIPTION:\nThere's a library `https://github.com/getzep/graphiti` that provides an upgraded RAG database - a knowledge graph. This project needs to be able to run locally and must expose an API that any client can interact with.\nFor reference, the whole library has been added under `graphiti/` .\n\n\n#ASSIGNED FEATURE: When using the service - error (ID: 6e697fe2-b9d8-41b6-b7ac-ffad70689109)\n##DESCRIPTION: After using the POST /documents API with the following data (as explained in the README.md):\n{\n  \"text\": \"Neo4j is a graph database that stores data as nodes and relationships.\",\n  \"metadata\": {\n    \"title\": \"Neo4j Intro\"\n  }\n}\n\nTHIS MASSIVE ERROR SHOWS:\n\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: name)} {position: line: 10, column: 7, offset: 207} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: entity_edges)} {position: line: 17, column: 7, offset: 413} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: uuid)} {position: line: 9, column: 7, offset: 187} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: source)} {position: line: 6, column: 7, offset: 140} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: valid_at)} {position: line: 16, column: 7, offset: 385} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: content)} {position: line: 15, column: 7, offset: 359} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: source_description)} {position: line: 14, column: 7, offset: 311} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Episodic)} {position: line: 2, column: 26, offset: 26} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: group_id)} {position: line: 5, column: 7, offset: 111} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,746 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: created_at)} {position: line: 12, column: 7, offset: 255} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,747 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: group_id)} {position: line: 11, column: 7, offset: 227} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,747 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: source)} {position: line: 13, column: 7, offset: 287} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:46,747 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: valid_at)} {position: line: 3, column: 25, offset: 60} for query: '\\n                MATCH (e:Episodic)\\n                WHERE e.valid_at <= $reference_time\\n                \\nAND e.group_id IN $group_ids\\nAND e.source = $source\\n        RETURN\\n        \\n    e.uuid AS uuid,\\n    e.name AS name,\\n    e.group_id AS group_id,\\n    e.created_at AS created_at,\\n    e.source AS source,\\n    e.source_description AS source_description,\\n    e.content AS content,\\n    e.valid_at AS valid_at,\\n    e.entity_edges AS entity_edges\\n\\n        ORDER BY e.valid_at DESC\\n        LIMIT $num_episodes\\n        '\n2025-09-12 21:30:50,161 INFO httpx: HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n2025-09-12 21:30:50,784 INFO httpx: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-12 21:30:50,806 INFO httpx: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-12 21:30:50,869 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: created_at)} {position: line: 11, column: 11, offset: 314} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,869 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: name)} {position: line: 9, column: 11, offset: 258} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,869 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: group_id)} {position: line: 10, column: 11, offset: 282} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,869 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: name_embedding)} {position: line: 4, column: 48, offset: 114} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,869 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: summary)} {position: line: 12, column: 11, offset: 350} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,869 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: uuid)} {position: line: 8, column: 11, offset: 234} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,869 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Entity)} {position: line: 2, column: 34, offset: 34} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,870 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: created_at)} {position: line: 11, column: 11, offset: 314} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,870 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: name)} {position: line: 9, column: 11, offset: 258} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,870 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: group_id)} {position: line: 10, column: 11, offset: 282} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,870 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: name_embedding)} {position: line: 4, column: 48, offset: 114} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,870 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: summary)} {position: line: 12, column: 11, offset: 350} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,871 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: uuid)} {position: line: 8, column: 11, offset: 234} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,871 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Entity)} {position: line: 2, column: 34, offset: 34} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,887 INFO httpx: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-12 21:30:50,899 INFO httpx: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n2025-09-12 21:30:50,901 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: created_at)} {position: line: 11, column: 11, offset: 314} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,901 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: name)} {position: line: 9, column: 11, offset: 258} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,901 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: group_id)} {position: line: 10, column: 11, offset: 282} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,901 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: name_embedding)} {position: line: 4, column: 48, offset: 114} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,901 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: summary)} {position: line: 12, column: 11, offset: 350} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,901 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: uuid)} {position: line: 8, column: 11, offset: 234} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,902 WARNING neo4j.notifications: Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownLabelWarning} {category: UNRECOGNIZED} {title: The provided label is not in the database.} {description: One of the labels in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing label name is: Entity)} {position: line: 2, column: 34, offset: 34} for query: '\\n                        MATCH (n:Entity)\\n                        \\n            WITH n, vector.similarity.cosine(n.name_embedding, $search_vector) AS score\\n            WHERE score > $min_score\\n            RETURN\\n            \\n        n.uuid AS uuid,\\n        n.name AS name,\\n        n.group_id AS group_id,\\n        n.created_at AS created_at,\\n        n.summary AS summary,\\n        labels(n) AS labels,\\n        properties(n) AS attributes\\n    \\n            ORDER BY score DESC\\n            LIMIT $limit\\n            '\n2025-09-12 21:30:50,949 ERROR graphiti_core.driver.neo4j_driver: Error executing Neo4j query: {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `db.index.fulltext.queryNodes`: Caused by: java.lang.IllegalArgumentException: There is no such fulltext schema index: node_name_and_summary}\nCALL db.index.fulltext.queryNodes(\"node_name_and_summary\", $query, {limit: $limit})YIELD node AS n, score\n            WITH n, score\n            ORDER BY score DESC\n            LIMIT $limit\n            RETURN\n            \n        n.uuid AS uuid,\n        n.name AS name,\n        n.group_id AS group_id,\n        n.created_at AS created_at,\n        n.summary AS summary,\n        labels(n) AS labels,\n        properties(n) AS attributes\n    \n{'database_': 'neo4j'}\n2025-09-12 21:30:50,949 ERROR graphiti_core.driver.neo4j_driver: Error executing Neo4j query: {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `db.index.fulltext.queryNodes`: Caused by: java.lang.IllegalArgumentException: There is no such fulltext schema index: node_name_and_summary}\nCALL db.index.fulltext.queryNodes(\"node_name_and_summary\", $query, {limit: $limit})YIELD node AS n, score\n            WITH n, score\n            ORDER BY score DESC\n            LIMIT $limit\n            RETURN\n            \n        n.uuid AS uuid,\n        n.name AS name,\n        n.group_id AS group_id,\n        n.created_at AS created_at,\n        n.summary AS summary,\n        labels(n) AS labels,\n        properties(n) AS attributes\n    \n{'database_': 'neo4j'}\n2025-09-12 21:30:50,949 ERROR graphiti_core.driver.neo4j_driver: Error executing Neo4j query: {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `db.index.fulltext.queryNodes`: Caused by: java.lang.IllegalArgumentException: There is no such fulltext schema index: node_name_and_summary}\nCALL db.index.fulltext.queryNodes(\"node_name_and_summary\", $query, {limit: $limit})YIELD node AS n, score\n            WITH n, score\n            ORDER BY score DESC\n            LIMIT $limit\n            RETURN\n            \n        n.uuid AS uuid,\n        n.name AS name,\n        n.group_id AS group_id,\n        n.created_at AS created_at,\n        n.summary AS summary,\n        labels(n) AS labels,\n        properties(n) AS attributes\n    \n{'database_': 'neo4j'}\n\n\n\n\n#ACCEPTANCE CRITERIA:\n\n#TOOL SIGNATURES:\n- read_files(paths: list[str]) -> list[str] - Read the content of one or more files at the given relative paths. Returns an array of strings (one per file).\n- search_files(query: str, path: str = '.') -> list[str] - Search for files by name or textual content under the given path. Returns matching relative paths. The query input must be a space separated list of keywords\n- block_feature(reason: str) - Stop work on the current feature and report why you are blocked (e.g., missing context, unclear requirements).\n- finish_feature() - Mark the current feature as complete and end the run. Use only when the work fully meets the acceptance criteria.\n- list_files(path: str) - List files and directories at a relative path from the project root.\n- write_file(filename: str, content: str) - Create or overwrite a file with the given content. Always use this to write code or docs.\n- rename_file(filename: str, new_filename: str) - Rename or move a file from one path to another.\n- delete_file(filename: str) - Delete a file. Use with caution and only when necessary.\n- run_test() -> str - Run the test for the current feature and return the output. Use to verify implementation.\n\n#RESPONSE FORMAT INSTRUCTIONS:\nYou **MUST** respond in a single, valid JSON object. This object must adhere to the following structure:\n```json\n[object Object]\n```\nThe thoughts field is for your reasoning, and tool_calls is a list of actions to execute.\nYour response will be parsed as JSON. Do not include any text outside of this JSON object.\nAs responses to the tool calls you will send, you will also receive JSON objects in the form:\n```json\n[{\n\"name\":\"tool_nameA\",\n\"result\":\"...\"\n}...{\n\"name\":\"tool_nameZ\",\n\"result\":\"...\"\n}]\n```\n\n#CONTEXT FILES PROVIDED:\n{\"docs/FILE_ORGANISATION.md\":\"Project File Organisation\\n\\nThis document outlines the repository layout. Update this file whenever you introduce new major directories or restructure the project.\\n\\nTop-level\\n- pyproject.toml: Poetry configuration and dependency management using PEP 621 metadata.\\n- README.md: Project overview and basic usage instructions.\\n- .gitignore: Standard Python and tooling ignores.\\n- docs/: Documentation artifacts for contributors and maintainers.\\n- src/: Source code using the src/ layout.\\n- Dockerfile: Container image definition for running the FastAPI app.\\n- docker-compose.yml: Compose configuration to build and run the API locally with a single command.\\n\\nDocs\\n- docs/FILE_ORGANISATION.md: You are here. Describes the structure and conventions.\\n\\nSource\\n- src/: Python package for the application code.\\n  - __init__.py: Marks the directory as a package. Future modules for API and Graphiti integration will live here.\\n  - config.py: Centralized application configuration using environment variables via Pydantic Settings, including API host/port, log level, and Graphiti settings (storage path, reset, model/collection).\\n  - graph_service.py: Service module that initializes and provides access to a Graphiti knowledge graph instance. Centralizes graph-related logic and configuration.\\n  - main.py: FastAPI application with basic endpoints (e.g., /health) and the POST /documents endpoint to ingest text into the Graphiti knowledge graph. Uses config.py for settings and logging configuration.\\n\\nConventions\\n- Use the src/ layout. Configure Poetry to include packages from src via pyproject.toml.\\n- Keep generated files, caches, and environments out of version control (see .gitignore).\\n- Add new top-level directories only when necessary; document them here with their purpose.\\n\\nPlanned structure (to be implemented in future features)\\n- Additional routers and models for querying and managing the knowledge graph.\\n- Integration with Graphiti library for advanced knowledge graph storage and querying.\\n- Tests under a tests/ directory with pytest.\\n\"}\n\nBegin now.",
          "turn": 0,
          "askedAt": "2025-09-12T19:35:22.798Z",
          "source": "initial",
          "promptTokens": 0,
          "completionTokens": 0,
          "completedAt": "2025-09-12T19:35:22.798Z"
        },
        {
          "role": "assistant",
          "content": "{\"thoughts\":\"I'll inspect the current project structure and source to understand how Graphiti is initialized and where to hook in Neo4j schema/index initialization to resolve the missing label/properties and fulltext index errors. Then implement startup schema sync for Neo4j using Graphiti-provided setup or our own Cypher to create required indexes (like node_name_and_summary) and ensure labels/properties are compatible, updating config and app startup accordingly.\",\"tool_calls\":[{\"tool_name\":\"list_files\",\"arguments\":{\"path\":\".\"}},{\"tool_name\":\"list_files\",\"arguments\":{\"path\":\"src\"}},{\"tool_name\":\"read_files\",\"arguments\":{\"paths\":[\"src/main.py\",\"src/config.py\",\"src/graph_service.py\",\"pyproject.toml\",\"README.md\",\"docker-compose.yml\"]}},{\"tool_name\":\"search_files\",\"arguments\":{\"query\":\"graphiti Neo4j index fulltext schema\",\"path\":\"graphiti\"}},{\"tool_name\":\"search_files\",\"arguments\":{\"query\":\"node_name_and_summary\",\"path\":\"graphiti\"}},{\"tool_name\":\"search_files\",\"arguments\":{\"query\":\"Episodic Entity schema index\",\"path\":\"graphiti\"}}]}",
          "promptTokens": 10965,
          "completionTokens": 373,
          "provider": "openai",
          "model": "gpt-5",
          "turn": 1,
          "askedAt": "2025-09-12T19:35:22.801Z",
          "completedAt": "2025-09-12T19:35:33.096Z"
        },
        {
          "role": "user",
          "content": "[{\"name\":\"list_files\",\"result\":[\".env\",\".git\",\".gitignore\",\".venv\",\"Dockerfile\",\"LICENSE\",\"README.md\",\"docker-compose.yml\",\"docs\",\"graphiti\",\"poetry.lock\",\"pyproject.toml\",\"src\",\"tasks\"]},{\"name\":\"list_files\",\"result\":[\"__init__.py\",\"config.py\",\"graph_service.py\",\"main.py\"]},{\"name\":\"read_files\",\"result\":\"{\\\"src/main.py\\\":\\\"from __future__ import annotations\\\\nfrom typing import Any, Dict, Optional\\\\nfrom fastapi import FastAPI, HTTPException, Query\\\\nfrom fastapi.responses import JSONResponse\\\\nfrom pydantic import BaseModel, Field\\\\nfrom .graph_service import GraphService, GraphServiceError\\\\nfrom .config import configure_logging\\\\n\\\\n# Initialize FastAPI application\\\\napp = FastAPI(title=\\\\\\\"Graphiti API\\\\\\\", version=\\\\\\\"0.1.0\\\\\\\")\\\\n\\\\nclass DocumentCreate(BaseModel):\\\\n    text: str = Field(..., description=\\\\\\\"Raw text content to ingest into the knowledge graph\\\\\\\")\\\\n    metadata: Optional[Dict[str, Any]] = Field(\\\\n        default=None, description=\\\\\\\"Optional metadata associated with the text\\\\\\\"\\\\n    )\\\\n\\\\n@app.on_event(\\\\\\\"startup\\\\\\\")\\\\nasync def on_startup() -> None:\\\\n    configure_logging()\\\\n\\\\ndef _init_graph_service() -> GraphService:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Initialize and cache a GraphService instance on the app state using environment variables.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if getattr(app.state, \\\\\\\"graph_service\\\\\\\", None) is not None:\\\\n        return app.state.graph_service  # type: ignore[attr-defined]\\\\n    try:\\\\n        service = GraphService.from_env()\\\\n    except GraphServiceError:\\\\n        raise\\\\n    app.state.graph_service = service  # type: ignore[attr-defined]\\\\n    return service\\\\n\\\\n\\\\n@app.get(\\\\\\\"/health\\\\\\\")\\\\nasync def health_check() -> JSONResponse:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Basic health check endpoint.\\\\n\\\\n    Returns HTTP 200 OK with a simple payload to indicate the service is running.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return JSONResponse(status_code=200, content={\\\\\\\"status\\\\\\\": \\\\\\\"ok\\\\\\\"})\\\\n\\\\n\\\\n@app.post(\\\\\\\"/documents\\\\\\\")\\\\nasync def add_document(payload: DocumentCreate) -> JSONResponse:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Ingest a text document into the knowledge graph as an Episode.\\\\n\\\\n    Expects JSON body: {\\\\\\\"text\\\\\\\": \\\\\\\"...\\\\\\\", \\\\\\\"metadata\\\\\\\": {...}}\\\\n    Returns a success response including the new episode UUID.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        service = _init_graph_service()\\\\n    except GraphServiceError as exc:\\\\n        # Graph backend not available or misconfigured\\\\n        raise HTTPException(status_code=503, detail=str(exc))\\\\n\\\\n    try:\\\\n        result = await service.add_document(text=payload.text, metadata=payload.metadata)\\\\n    except GraphServiceError as exc:\\\\n        raise HTTPException(status_code=500, detail=str(exc))\\\\n    except Exception as exc:  # Defensive: unknown client error\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Failed to add document: {exc}\\\\\\\")\\\\n\\\\n    return JSONResponse(status_code=201, content={\\\\\\\"success\\\\\\\": True, \\\\\\\"result\\\\\\\": result})\\\\n\\\\n\\\\n@app.get(\\\\\\\"/query\\\\\\\")\\\\nasync def query(\\\\n    q: str = Query(..., description=\\\\\\\"Natural language query to search the knowledge graph\\\\\\\"),\\\\n    top_k: int = Query(5, ge=1, le=100, description=\\\\\\\"Maximum number of results to return\\\\\\\"),\\\\n) -> JSONResponse:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Query the knowledge graph for relevant information using hybrid search.\\\\n\\\\n    Example: GET /query?q=what+is+graphiti&top_k=5\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        service = _init_graph_service()\\\\n    except GraphServiceError as exc:\\\\n        raise HTTPException(status_code=503, detail=str(exc))\\\\n\\\\n    try:\\\\n        results = await service.search(query=q, top_k=top_k)\\\\n    except GraphServiceError as exc:\\\\n        raise HTTPException(status_code=500, detail=str(exc))\\\\n    except Exception as exc:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Failed to execute query: {exc}\\\\\\\")\\\\n\\\\n    return JSONResponse(status_code=200, content={\\\\\\\"query\\\\\\\": q, \\\\\\\"results\\\\\\\": results})\\\\n\\\",\\\"src/config.py\\\":\\\"from __future__ import annotations\\\\nimport os\\\\nimport logging\\\\nfrom functools import lru_cache\\\\nfrom typing import Optional\\\\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\\\\nfrom pydantic import Field\\\\n\\\\n\\\\nclass Settings(BaseSettings):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Application configuration managed via environment variables.\\\\n\\\\n    Environment variables:\\\\n    - API_HOST: Host interface to bind the API server to (default: 0.0.0.0)\\\\n    - API_PORT: Port number for the API server (default: 8000)\\\\n    - LOG_LEVEL: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL) default: INFO\\\\n    - GRAPHITI_STORAGE_PATH: Filesystem path for Graphiti data (default: ./data/graphiti)\\\\n    - GRAPHITI_RESET: If truthy (1/true/yes/y), resets graph storage on startup (default: false)\\\\n    - GRAPHITI_MODEL: Optional model name for Graphiti configuration (if applicable)\\\\n    - GRAPHITI_COLLECTION: Optional collection or namespace name (if applicable)\\\\n\\\\n    Notes:\\\\n    - We deliberately ignore unknown env variables (e.g., NEO4J_URI) so that loading .env does not fail,\\\\n      since GraphService reads those directly from os.environ.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    # Pydantic v2 settings config\\\\n    model_config = SettingsConfigDict(\\\\n        env_file=\\\\\\\".env\\\\\\\",\\\\n        case_sensitive=False,\\\\n        extra=\\\\\\\"ignore\\\\\\\",  # allow env variables that are not explicitly defined here\\\\n    )\\\\n\\\\n    api_host: str = Field(default=os.getenv(\\\\\\\"API_HOST\\\\\\\", \\\\\\\"0.0.0.0\\\\\\\"), description=\\\\\\\"API bind host\\\\\\\")\\\\n    api_port: int = Field(default=int(os.getenv(\\\\\\\"API_PORT\\\\\\\", \\\\\\\"8000\\\\\\\")), description=\\\\\\\"API bind port\\\\\\\")\\\\n\\\\n    log_level: str = Field(default=os.getenv(\\\\\\\"LOG_LEVEL\\\\\\\", \\\\\\\"INFO\\\\\\\"), description=\\\\\\\"Log level\\\\\\\")\\\\n\\\\n    graphiti_storage_path: str = Field(\\\\n        default=os.getenv(\\\\\\\"GRAPHITI_STORAGE_PATH\\\\\\\", os.path.join(\\\\\\\"data\\\\\\\", \\\\\\\"graphiti\\\\\\\")),\\\\n        description=\\\\\\\"Graphiti storage path\\\\\\\",\\\\n    )\\\\n    graphiti_reset: bool = Field(\\\\n        default=os.getenv(\\\\\\\"GRAPHITI_RESET\\\\\\\", \\\\\\\"false\\\\\\\").strip().lower() in {\\\\\\\"1\\\\\\\", \\\\\\\"true\\\\\\\", \\\\\\\"yes\\\\\\\", \\\\\\\"y\\\\\\\"},\\\\n        description=\\\\\\\"Reset Graphiti storage on startup\\\\\\\",\\\\n    )\\\\n    graphiti_model: Optional[str] = Field(\\\\n        default=os.getenv(\\\\\\\"GRAPHITI_MODEL\\\\\\\"), description=\\\\\\\"Graphiti model name\\\\\\\"\\\\n    )\\\\n    graphiti_collection: Optional[str] = Field(\\\\n        default=os.getenv(\\\\\\\"GRAPHITI_COLLECTION\\\\\\\"), description=\\\\\\\"Graphiti collection/namespace\\\\\\\"\\\\n    )\\\\n\\\\n\\\\n@lru_cache(maxsize=1)\\\\ndef get_settings() -> Settings:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Return a cached Settings instance loaded from environment variables.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return Settings()  # type: ignore[call-arg]\\\\n\\\\n\\\\ndef configure_logging(level_name: Optional[str] = None) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Configure root logging based on level name.\\\\n\\\\n    If level_name is None, uses the value from settings().log_level.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    settings = get_settings()\\\\n    name = (level_name or settings.log_level or \\\\\\\"INFO\\\\\\\").upper()\\\\n    level = getattr(logging, name, logging.INFO)\\\\n    logging.basicConfig(level=level, format=\\\\\\\"%(asctime)s %(levelname)s %(name)s: %(message)s\\\\\\\")\\\\n\\\",\\\"src/graph_service.py\\\":\\\"from __future__ import annotations\\\\nimport os\\\\nfrom typing import Optional, Any, Dict, List\\\\nfrom graphiti_core import Graphiti\\\\nfrom graphiti_core.nodes import EpisodeType\\\\nfrom graphiti_core.utils.datetime_utils import utc_now\\\\n\\\\n\\\\nclass GraphServiceError(RuntimeError):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Domain error raised for GraphService-related failures.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\nclass GraphService:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Centralized service to manage the Graphiti knowledge graph lifecycle and access.\\\\n\\\\n    This service correctly initializes the Graphiti library from graphiti-core and\\\\n    exposes simple async helpers to add text episodes and search the graph.\\\\n\\\\n    Usage:\\\\n        service = GraphService.from_env()\\\\n        await service.add_document(text=\\\\\\\"...\\\\\\\")\\\\n        await service.search(query=\\\\\\\"...\\\\\\\")\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(\\\\n        self,\\\\n        *,\\\\n        uri: str,\\\\n        user: Optional[str] = None,\\\\n        password: Optional[str] = None,\\\\n        graphiti_kwargs: Optional[Dict[str, Any]] = None,\\\\n    ) -> None:\\\\n        try:\\\\n            # Instantiate Graphiti using its official constructor (driver defaults to Neo4j)\\\\n            self._graph = Graphiti(uri=uri, user=user, password=password, **(graphiti_kwargs or {}))\\\\n        except Exception as exc:\\\\n            raise GraphServiceError(f\\\\\\\"Failed to initialize Graphiti: {exc}\\\\\\\")\\\\n\\\\n    @classmethod\\\\n    def from_env(\\\\n        cls,\\\\n        *,\\\\n        uri_env: str = \\\\\\\"NEO4J_URI\\\\\\\",\\\\n        user_env: str = \\\\\\\"NEO4J_USER\\\\\\\",\\\\n        password_env: str = \\\\\\\"NEO4J_PASSWORD\\\\\\\",\\\\n        **graphiti_kwargs: Any,\\\\n    ) -> \\\\\\\"GraphService\\\\\\\":\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Create a GraphService using environment variables for database connectivity.\\\\n\\\\n        Expected env vars:\\\\n        - NEO4J_URI (e.g., bolt://localhost:7687)\\\\n        - NEO4J_USER\\\\n        - NEO4J_PASSWORD\\\\n\\\\n        Note: For other backends (FalkorDB, Kuzu, Neptune), construct the appropriate\\\\n        driver externally and pass via the Graphiti(graph_driver=...) argument in the future.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        uri = os.getenv(uri_env)\\\\n        if not uri:\\\\n            raise GraphServiceError(\\\\n                f\\\\\\\"Missing required environment variable: {uri_env}. Example: bolt://localhost:7687\\\\\\\"\\\\n            )\\\\n        user = os.getenv(user_env)\\\\n        password = os.getenv(password_env)\\\\n\\\\n        return cls(uri=uri, user=user, password=password, graphiti_kwargs=graphiti_kwargs)\\\\n\\\\n    def get_graph(self) -> Graphiti:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Return the underlying Graphiti instance.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return self._graph\\\\n\\\\n    async def add_document(self, *, text: str, metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Ingest a text input as an Episode into the Graphiti knowledge graph.\\\\n\\\\n        Maps to Graphiti.add_episode(...), using sensible defaults derived from metadata.\\\\n\\\\n        Returns a summary dictionary including the new episode UUID and counts of created items.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        meta = metadata or {}\\\\n        name = str(meta.get(\\\\\\\"name\\\\\\\") or meta.get(\\\\\\\"title\\\\\\\") or \\\\\\\"episode\\\\\\\")\\\\n        source_description = str(meta.get(\\\\\\\"source_description\\\\\\\") or meta.get(\\\\\\\"source\\\\\\\") or \\\\\\\"api\\\\\\\")\\\\n        group_id = meta.get(\\\\\\\"group_id\\\\\\\")\\\\n\\\\n        # Add the text as an episode\\\\n        result = await self._graph.add_episode(\\\\n            name=name,\\\\n            episode_body=text,\\\\n            source_description=source_description,\\\\n            reference_time=utc_now(),\\\\n            source=EpisodeType.text,\\\\n            group_id=group_id,\\\\n        )\\\\n\\\\n        # Pydantic BaseModel -> dict\\\\n        try:\\\\n            payload = result.model_dump()  # pydantic v2\\\\n        except Exception:\\\\n            try:\\\\n                payload = result.dict()  # pydantic v1 fallback\\\\n            except Exception:\\\\n                payload = {\\\\n                    \\\\\\\"episode_uuid\\\\\\\": getattr(result.episode, \\\\\\\"uuid\\\\\\\", None),\\\\n                }\\\\n\\\\n        # Provide a compact summary as the return value while keeping full payload\\\\n        summary: Dict[str, Any] = {\\\\n            \\\\\\\"episode_uuid\\\\\\\": payload.get(\\\\\\\"episode\\\\\\\", {}).get(\\\\\\\"uuid\\\\\\\") if isinstance(payload.get(\\\\\\\"episode\\\\\\\"), dict) else getattr(result.episode, \\\\\\\"uuid\\\\\\\", None),\\\\n            \\\\\\\"counts\\\\\\\": {\\\\n                \\\\\\\"nodes\\\\\\\": len(getattr(result, \\\\\\\"nodes\\\\\\\", [])),\\\\n                \\\\\\\"edges\\\\\\\": len(getattr(result, \\\\\\\"edges\\\\\\\", [])),\\\\n                \\\\\\\"episodic_edges\\\\\\\": len(getattr(result, \\\\\\\"episodic_edges\\\\\\\", [])),\\\\n                \\\\\\\"communities\\\\\\\": len(getattr(result, \\\\\\\"communities\\\\\\\", [])),\\\\n                \\\\\\\"community_edges\\\\\\\": len(getattr(result, \\\\\\\"community_edges\\\\\\\", [])),\\\\n            },\\\\n            \\\\\\\"raw\\\\\\\": payload,\\\\n        }\\\\n        return summary\\\\n\\\\n    async def search(\\\\n        self,\\\\n        *,\\\\n        query: str,\\\\n        top_k: int = 5,\\\\n        center_node_uuid: Optional[str] = None,\\\\n        group_ids: Optional[List[str]] = None,\\\\n    ) -> List[Dict[str, Any]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Execute Graphiti's hybrid search and return a list of edge dicts.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        edges = await self._graph.search(\\\\n            query=query,\\\\n            center_node_uuid=center_node_uuid,\\\\n            group_ids=group_ids,\\\\n            num_results=top_k,\\\\n        )\\\\n\\\\n        def edge_to_dict(edge: Any) -> Dict[str, Any]:\\\\n            try:\\\\n                return edge.model_dump()\\\\n            except Exception:\\\\n                try:\\\\n                    return edge.dict()\\\\n                except Exception:\\\\n                    # As a final fallback, return basic attributes if present\\\\n                    return {\\\\n                        \\\\\\\"uuid\\\\\\\": getattr(edge, \\\\\\\"uuid\\\\\\\", None),\\\\n                        \\\\\\\"fact\\\\\\\": getattr(edge, \\\\\\\"fact\\\\\\\", None),\\\\n                        \\\\\\\"source_node_uuid\\\\\\\": getattr(edge, \\\\\\\"source_node_uuid\\\\\\\", None),\\\\n                        \\\\\\\"target_node_uuid\\\\\\\": getattr(edge, \\\\\\\"target_node_uuid\\\\\\\", None),\\\\n                        \\\\\\\"score\\\\\\\": getattr(edge, \\\\\\\"score\\\\\\\", None),\\\\n                    }\\\\n\\\\n        return [edge_to_dict(e) for e in edges]\\\\n\\\\n\\\\n__all__ = [\\\\\\\"GraphService\\\\\\\", \\\\\\\"GraphServiceError\\\\\\\"]\\\\n\\\",\\\"pyproject.toml\\\":\\\"[tool.poetry]\\\\nname = \\\\\\\"thefactory-knowledge\\\\\\\"\\\\nversion = \\\\\\\"0.1.0\\\\\\\"\\\\ndescription = \\\\\\\"Local API server harnessing the Graphiti knowledge graph library.\\\\\\\"\\\\nauthors = [\\\\\\\"Kamil Chmurzynski <cloudjubei@gmail.com>\\\\\\\"]\\\\nreadme = \\\\\\\"README.md\\\\\\\"\\\\npackages = [{ include = \\\\\\\"src\\\\\\\" }]\\\\n\\\\n[tool.poetry.dependencies]\\\\npython = \\\\\\\">=3.10,<4\\\\\\\"\\\\n# Core project dependencies\\\\ngraphiti-core = \\\\\\\"0.20.4\\\\\\\"\\\\nfastapi = \\\\\\\"^0.114.0\\\\\\\"\\\\nuvicorn = \\\\\\\"^0.30.0\\\\\\\"\\\\npydantic = \\\\\\\"2.11.7\\\\\\\"\\\\npydantic_settings = \\\\\\\"2.10.1\\\\\\\"\\\\n\\\\n[tool.poetry.scripts]\\\\n# Optional entrypoint if needed later\\\\n\\\\n[build-system]\\\\nrequires = [\\\\\\\"poetry-core>=1.7.0\\\\\\\"]\\\\nbuild-backend = \\\\\\\"poetry.core.masonry.api\\\\\\\"\\\\n\\\",\\\"README.md\\\":\\\"Graphiti API\\\\n\\\\nA FastAPI application that exposes a simple HTTP API over the Graphiti knowledge graph library. Use it to ingest text into a knowledge graph and run hybrid semantic queries locally.\\\\n\\\\nHighlights\\\\n- Endpoints:\\\\n  - GET /health: service liveness\\\\n  - POST /documents: ingest raw text as a Graphiti Episode\\\\n  - GET /query: hybrid search over the knowledge graph\\\\n- Configuration via environment variables (see Configuration below)\\\\n- Runs locally with Poetry or in a container with Docker\\\\n\\\\nPrerequisites\\\\n- Neo4j database (required by Graphiti)\\\\n  - Example container: neo4j:5-community (detailed instructions below)\\\\n- Python 3.10–3.13\\\\n- Poetry 1.8+\\\\n- Alternatively: Docker and Docker Compose\\\\n\\\\nSetting Up Neo4j Database (Required)\\\\n\\\\nThe Graphiti API requires a Neo4j database to function. Follow these step-by-step instructions to set up Neo4j locally from scratch:\\\\n\\\\nOption 1: Neo4j with Docker (Recommended for Development)\\\\n\\\\n1) Install Docker\\\\n   - Download and install Docker Desktop from https://www.docker.com/products/docker-desktop\\\\n   - Verify installation: `docker --version`\\\\n\\\\n2) Create a Neo4j container\\\\n   Choose a strong password and replace 'your_secure_password' in the command below:\\\\n   \\\\n   docker run -d \\\\\\\\\\\\n     --name neo4j-graphiti \\\\\\\\\\\\n     -p 7474:7474 -p 7687:7687 \\\\\\\\\\\\n     -e NEO4J_AUTH=neo4j/your_secure_password \\\\\\\\\\\\n     -v neo4j-data:/data \\\\\\\\\\\\n     -v neo4j-logs:/logs \\\\\\\\\\\\n     -v neo4j-import:/var/lib/neo4j/import \\\\\\\\\\\\n     -v neo4j-plugins:/plugins \\\\\\\\\\\\n     neo4j:5-community\\\\n\\\\n   This command:\\\\n   - Creates a container named 'neo4j-graphiti'\\\\n   - Exposes port 7474 (web interface) and 7687 (bolt protocol)\\\\n   - Sets username 'neo4j' with your chosen password\\\\n   - Creates persistent volumes for data, logs, imports, and plugins\\\\n   - Uses Neo4j Community Edition version 5\\\\n\\\\n3) Verify Neo4j is running\\\\n   Check container status:\\\\n   docker ps\\\\n   \\\\n   You should see the neo4j-graphiti container in the list.\\\\n   \\\\n   Check logs for any errors:\\\\n   docker logs neo4j-graphiti\\\\n   \\\\n   Wait for the message \\\\\\\"Started\\\\\\\" to appear in the logs (this may take 30-60 seconds on first startup).\\\\n\\\\n4) Access Neo4j Browser (Optional)\\\\n   Open your web browser and go to: http://localhost:7474\\\\n   \\\\n   Login with:\\\\n   - Username: neo4j\\\\n   - Password: your_secure_password (the one you set in step 2)\\\\n   \\\\n   You should see the Neo4j Browser interface, confirming the database is ready.\\\\n\\\\n5) Test connectivity\\\\n   Run a simple test query in Neo4j Browser:\\\\n   MATCH (n) RETURN count(n)\\\\n   \\\\n   This should return 0 (empty database) without errors.\\\\n\\\\nOption 2: Neo4j Desktop (GUI Application)\\\\n\\\\n1) Download Neo4j Desktop\\\\n   - Go to https://neo4j.com/download/\\\\n   - Download Neo4j Desktop for your operating system\\\\n   - Install following the platform-specific instructions\\\\n\\\\n2) Create a new project\\\\n   - Launch Neo4j Desktop\\\\n   - Click \\\\\\\"New Project\\\\\\\" and give it a name (e.g., \\\\\\\"Graphiti API\\\\\\\")\\\\n\\\\n3) Create a database\\\\n   - In your project, click \\\\\\\"Add Database\\\\\\\" → \\\\\\\"Local DBMS\\\\\\\"\\\\n   - Name: \\\\\\\"graphiti-db\\\\\\\" (or your preferred name)\\\\n   - Password: Choose a secure password\\\\n   - Version: Select Neo4j 5.x (latest available)\\\\n   - Click \\\\\\\"Create\\\\\\\"\\\\n\\\\n4) Start the database\\\\n   - Click the \\\\\\\"Start\\\\\\\" button on your database\\\\n   - Wait for the status to show \\\\\\\"Active\\\\\\\" (green dot)\\\\n\\\\n5) Note connection details\\\\n   - Click on your database to see details\\\\n   - Note the bolt URL (typically bolt://localhost:7687)\\\\n   - Username is 'neo4j' by default\\\\n   - Password is what you set in step 3\\\\n\\\\nOption 3: Neo4j Server Installation (Production)\\\\n\\\\nFor production deployments, follow the official Neo4j installation guide:\\\\nhttps://neo4j.com/docs/operations-manual/current/installation/\\\\n\\\\nManaging Your Neo4j Instance\\\\n\\\\nStarting Neo4j (Docker method):\\\\ndocker start neo4j-graphiti\\\\n\\\\nStopping Neo4j (Docker method):\\\\ndocker stop neo4j-graphiti\\\\n\\\\nViewing logs (Docker method):\\\\ndocker logs neo4j-graphiti\\\\n\\\\nRemoving Neo4j container (if needed):\\\\ndocker stop neo4j-graphiti\\\\ndocker rm neo4j-graphiti\\\\n# Note: This removes the container but preserves data in volumes\\\\n\\\\nQuick Start\\\\n\\\\nOnce Neo4j is running, choose one of these options to run the Graphiti API:\\\\n\\\\nOption A: Run locally with Poetry\\\\n1) Clone and enter the repo\\\\n   git clone <your-repo-url>\\\\n   cd <your-repo>\\\\n\\\\n2) Set required environment (Neo4j)\\\\n   The API requires access to your Neo4j instance. Create a .env file at the repo root:\\\\n   \\\\n   # Neo4j Connection (Required)\\\\n   NEO4J_URI=bolt://localhost:7687\\\\n   NEO4J_USER=neo4j\\\\n   NEO4J_PASSWORD=your_secure_password\\\\n   \\\\n   # API Settings (Optional)\\\\n   API_HOST=0.0.0.0\\\\n   API_PORT=8000\\\\n   LOG_LEVEL=INFO\\\\n   \\\\n   # Graphiti Options (Optional)\\\\n   GRAPHITI_STORAGE_PATH=./data/graphiti\\\\n   GRAPHITI_RESET=false\\\\n   GRAPHITI_MODEL=\\\\n   GRAPHITI_COLLECTION=\\\\n   \\\\n   Replace 'your_secure_password' with the password you set for Neo4j.\\\\n\\\\n3) Install dependencies\\\\n   poetry install\\\\n\\\\n4) Run the application\\\\n   poetry run uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload\\\\n\\\\n5) Verify everything works\\\\n   Test the health endpoint:\\\\n   curl http://localhost:8000/health\\\\n   \\\\n   Expected response: {\\\\\\\"status\\\\\\\": \\\\\\\"ok\\\\\\\"}\\\\n   \\\\n   Open the API docs:\\\\n   - Swagger UI: http://localhost:8000/docs\\\\n   - ReDoc: http://localhost:8000/redoc\\\\n\\\\nOption B: Run with Docker\\\\nA. Build and run directly\\\\n1) Build the image\\\\n   docker build -t local .\\\\n\\\\n2) Run the container (pass Neo4j creds)\\\\n   docker run --rm -p 8000:8000 \\\\\\\\\\\\n     -e NEO4J_URI=bolt://host.docker.internal:7687 \\\\\\\\\\\\n     -e NEO4J_USER=neo4j \\\\\\\\\\\\n     -e NEO4J_PASSWORD=your_secure_password \\\\\\\\\\\\n     -e LOG_LEVEL=INFO \\\\\\\\\\\\n     --name thefactory-knowledge local\\\\n\\\\n   Note: On Linux, replace host.docker.internal with your host IP or run Neo4j in another container on the same network.\\\\n\\\\n3) Visit docs\\\\n   http://localhost:8000/docs\\\\n\\\\nB. Use Docker Compose\\\\nThe provided docker-compose.yml defines the API service but does not inject your environment variables by default. Create an override file to pass them through.\\\\n\\\\n1) Create docker-compose.override.yml with your env:\\\\n   services:\\\\n     api:\\\\n       environment:\\\\n         - NEO4J_URI=${NEO4J_URI}\\\\n         - NEO4J_USER=${NEO4J_USER}\\\\n         - NEO4J_PASSWORD=${NEO4J_PASSWORD}\\\\n         - API_HOST=${API_HOST:-0.0.0.0}\\\\n         - API_PORT=${API_PORT:-8000}\\\\n         - LOG_LEVEL=${LOG_LEVEL:-INFO}\\\\n\\\\n2) Create a .env file at repo root with values:\\\\n   NEO4J_URI=bolt://localhost:7687\\\\n   NEO4J_USER=neo4j\\\\n   NEO4J_PASSWORD=your_secure_password\\\\n\\\\n3) Start the service\\\\n   docker compose up --build\\\\n\\\\n4) Visit docs\\\\n   http://localhost:8000/docs\\\\n\\\\nComplete Setup Verification\\\\n\\\\nTo ensure everything is working correctly:\\\\n\\\\n1) Test the health endpoint:\\\\n   curl http://localhost:8000/health\\\\n   Expected: {\\\\\\\"status\\\\\\\": \\\\\\\"ok\\\\\\\"}\\\\n\\\\n2) Test document ingestion:\\\\n   curl -X POST http://localhost:8000/documents \\\\\\\\\\\\n     -H \\\\\\\"Content-Type: application/json\\\\\\\" \\\\\\\\\\\\n     -d '{\\\\\\\"text\\\\\\\": \\\\\\\"Neo4j is a graph database that stores data as nodes and relationships.\\\\\\\", \\\\\\\"metadata\\\\\\\": {\\\\\\\"title\\\\\\\": \\\\\\\"Neo4j Intro\\\\\\\"}}'\\\\n   \\\\n   Expected: {\\\\\\\"success\\\\\\\": true, \\\\\\\"result\\\\\\\": {\\\\\\\"episode_uuid\\\\\\\": \\\\\\\"...\\\\\\\", ...}}\\\\n\\\\n3) Test querying:\\\\n   curl -G http://localhost:8000/query --data-urlencode \\\\\\\"q=what is Neo4j\\\\\\\"\\\\n   \\\\n   Expected: {\\\\\\\"query\\\\\\\": \\\\\\\"what is Neo4j\\\\\\\", \\\\\\\"results\\\\\\\": [...]}\\\\n\\\\nIf all tests pass, your API is successfully connected to Neo4j and ready to serve clients!\\\\n\\\\nConfiguration\\\\nEnvironment variables (authoritative names are in src/config.py):\\\\n- API_HOST: Host interface for the API (default: 0.0.0.0)\\\\n- API_PORT: Port for the API (default: 8000)\\\\n- LOG_LEVEL: Logging level (default: INFO)\\\\n\\\\n- NEO4J_URI: Required. Example: bolt://localhost:7687\\\\n- NEO4J_USER: Required. Example: neo4j\\\\n- NEO4J_PASSWORD: Required. Example: your_password\\\\n\\\\nOptional Graphiti-related settings (may be used in future features):\\\\n- GRAPHITI_STORAGE_PATH: Default ./data/graphiti\\\\n- GRAPHITI_RESET: Reset underlying storage on startup (default: false)\\\\n- GRAPHITI_MODEL: Optional model name\\\\n- GRAPHITI_COLLECTION: Optional collection/namespace\\\\n\\\\nAPI Usage\\\\n- Health check\\\\n  Method: GET\\\\n  URL: /health\\\\n  Example:\\\\n    curl -s http://localhost:8000/health\\\\n  Response:\\\\n    {\\\\\\\"status\\\\\\\": \\\\\\\"ok\\\\\\\"}\\\\n\\\\n- Ingest document\\\\n  Method: POST\\\\n  URL: /documents\\\\n  Body (JSON):\\\\n    {\\\\n      \\\\\\\"text\\\\\\\": \\\\\\\"Graphiti is a knowledge graph for RAG.\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {\\\\\\\"title\\\\\\\": \\\\\\\"Intro\\\\\\\", \\\\\\\"source\\\\\\\": \\\\\\\"docs\\\\\\\"}\\\\n    }\\\\n  Example:\\\\n    curl -X POST http://localhost:8000/documents \\\\\\\\\\\\n      -H \\\\\\\"Content-Type: application/json\\\\\\\" \\\\\\\\\\\\n      -d '{\\\\\\\"text\\\\\\\": \\\\\\\"Graphiti is a knowledge graph for RAG.\\\\\\\", \\\\\\\"metadata\\\\\\\": {\\\\\\\"title\\\\\\\": \\\\\\\"Intro\\\\\\\"}}'\\\\n  Success response (201):\\\\n    {\\\\\\\"success\\\\\\\": true, \\\\\\\"result\\\\\\\": {\\\\\\\"episode_uuid\\\\\\\": \\\\\\\"...\\\\\\\", \\\\\\\"counts\\\\\\\": { ... }, \\\\\\\"raw\\\\\\\": { ... }}}\\\\n\\\\n- Query graph\\\\n  Method: GET\\\\n  URL: /query\\\\n  Params:\\\\n    - q: query string (required)\\\\n    - top_k: max results (default 5)\\\\n  Example:\\\\n    curl -G http://localhost:8000/query --data-urlencode \\\\\\\"q=what is graphiti\\\\\\\" --data-urlencode \\\\\\\"top_k=5\\\\\\\"\\\\n  Success response (200):\\\\n    {\\\\\\\"query\\\\\\\": \\\\\\\"what is graphiti\\\\\\\", \\\\\\\"results\\\\\\\": [ {\\\\\\\"uuid\\\\\\\": \\\\\\\"...\\\\\\\", \\\\\\\"fact\\\\\\\": \\\\\\\"...\\\\\\\", ...}, ... ]}\\\\n\\\\nNotes\\\\n- The Graphiti API expects a working Neo4j connection. If connection variables are missing or incorrect, endpoints like /documents and /query will return 503/500 errors.\\\\n- Additional provider-specific settings (e.g., for embeddings or LLMs) may be required depending on how you extend Graphiti usage. Consult the Graphiti documentation if you integrate those features.\\\\n\\\\nDevelopment\\\\n- Code location: src/\\\\n  - main.py: FastAPI app and routes\\\\n  - graph_service.py: Graphiti integration (init, add document, search)\\\\n  - config.py: Settings and logging configuration\\\\n- Run locally (dev):\\\\n  poetry run uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload\\\\n- Formatting/linting: Add your preferred tools (e.g., ruff, black, isort) to pyproject.toml.\\\\n\\\\nTroubleshooting\\\\n\\\\nNeo4j Connection Issues:\\\\n- Connection refused to bolt://localhost:7687: \\\\n  * Check if Neo4j is running: `docker ps` (for Docker) or check Neo4j Desktop\\\\n  * Verify the port 7687 is not blocked by firewall\\\\n  * Ensure NEO4J_URI matches your Neo4j instance address\\\\n\\\\n- Authentication failed:\\\\n  * Verify NEO4J_USER and NEO4J_PASSWORD match your Neo4j credentials\\\\n  * For new Neo4j instances, the default user is 'neo4j'\\\\n  * Check if you need to change the initial password\\\\n\\\\n- Neo4j container won't start:\\\\n  * Check logs: `docker logs neo4j-graphiti`\\\\n  * Ensure ports 7474 and 7687 are not already in use\\\\n  * Try removing and recreating the container\\\\n\\\\nAPI Issues:\\\\n- 503 Service Unavailable when calling endpoints: Ensure NEO4J_URI/USER/PASSWORD are set correctly and Neo4j is reachable.\\\\n- 500 errors during ingestion/search: Increase verbosity with LOG_LEVEL=DEBUG and check logs.\\\\n- Docker networking on Linux: If using docker run, host.docker.internal may not resolve; use the host IP or run Neo4j in a user-defined network with the API container.\\\\n\\\\nLicense\\\\nSee LICENSE in this repository.\\\\n\\\\nAcknowledgements\\\\n- Graphiti by Zep: https://github.com/getzep/graphiti\\\\n- FastAPI: https://fastapi.tiangolo.com/\\\\n- Neo4j: https://neo4j.com/\\\\n\\\",\\\"docker-compose.yml\\\":\\\"version: \\\\\\\"3.9\\\\\\\"\\\\n\\\\nservices:\\\\n  api:\\\\n    build: .\\\\n    image: local\\\\n    container_name: thefactory-knowledge\\\\n    ports:\\\\n      - \\\\\\\"8000:8000\\\\\\\"\\\\n    environment:\\\\n      - PYTHONUNBUFFERED=1\\\\n    volumes:\\\\n      - ./src:/app/src:ro\\\\n    restart: unless-stopped\\\\n\\\"}\"},{\"name\":\"search_files\",\"result\":[\"graphiti/README.md\",\"graphiti/examples/ecommerce/runner.ipynb\",\"graphiti/examples/ecommerce/runner.py\",\"graphiti/examples/langgraph-agent/agent.ipynb\",\"graphiti/examples/podcast/podcast_runner.py\",\"graphiti/examples/podcast/transcript_parser.py\",\"graphiti/examples/quickstart/README.md\",\"graphiti/examples/quickstart/quickstart_falkordb.py\",\"graphiti/examples/quickstart/quickstart_neo4j.py\",\"graphiti/examples/quickstart/quickstart_neptune.py\",\"graphiti/examples/quickstart/requirements.txt\",\"graphiti/examples/wizard_of_oz/runner.py\",\"graphiti/graphiti_core/__init__.py\",\"graphiti/graphiti_core/cross_encoder/bge_reranker_client.py\",\"graphiti/graphiti_core/cross_encoder/gemini_reranker_client.py\",\"graphiti/graphiti_core/driver/__init__.py\",\"graphiti/graphiti_core/driver/driver.py\",\"graphiti/graphiti_core/driver/falkordb_driver.py\",\"graphiti/graphiti_core/driver/kuzu_driver.py\",\"graphiti/graphiti_core/driver/neo4j_driver.py\",\"graphiti/graphiti_core/driver/neptune_driver.py\",\"graphiti/graphiti_core/edges.py\",\"graphiti/graphiti_core/embedder/gemini.py\",\"graphiti/graphiti_core/embedder/voyage.py\",\"graphiti/graphiti_core/errors.py\",\"graphiti/graphiti_core/graph_queries.py\",\"graphiti/graphiti_core/graphiti.py\",\"graphiti/graphiti_core/graphiti_types.py\",\"graphiti/graphiti_core/helpers.py\",\"graphiti/graphiti_core/llm_client/anthropic_client.py\",\"graphiti/graphiti_core/llm_client/client.py\",\"graphiti/graphiti_core/llm_client/gemini_client.py\",\"graphiti/graphiti_core/llm_client/groq_client.py\",\"graphiti/graphiti_core/llm_client/openai_generic_client.py\",\"graphiti/graphiti_core/llm_client/utils.py\",\"graphiti/graphiti_core/models/edges/edge_db_queries.py\",\"graphiti/graphiti_core/models/nodes/node_db_queries.py\",\"graphiti/graphiti_core/nodes.py\",\"graphiti/graphiti_core/prompts/dedupe_nodes.py\",\"graphiti/graphiti_core/search/search.py\",\"graphiti/graphiti_core/search/search_config.py\",\"graphiti/graphiti_core/search/search_config_recipes.py\",\"graphiti/graphiti_core/search/search_filters.py\",\"graphiti/graphiti_core/search/search_helpers.py\",\"graphiti/graphiti_core/search/search_utils.py\",\"graphiti/graphiti_core/telemetry/__init__.py\",\"graphiti/graphiti_core/telemetry/telemetry.py\",\"graphiti/graphiti_core/utils/bulk_utils.py\",\"graphiti/graphiti_core/utils/maintenance/community_operations.py\",\"graphiti/graphiti_core/utils/maintenance/edge_operations.py\",\"graphiti/graphiti_core/utils/maintenance/graph_data_operations.py\",\"graphiti/graphiti_core/utils/maintenance/node_operations.py\",\"graphiti/graphiti_core/utils/maintenance/temporal_operations.py\",\"graphiti/graphiti_core/utils/ontology_utils/entity_types_utils.py\",\"graphiti/pyproject.toml\"]},{\"name\":\"search_files\",\"result\":[\"graphiti/graphiti_core/driver/neptune_driver.py\",\"graphiti/graphiti_core/graph_queries.py\",\"graphiti/graphiti_core/search/search_utils.py\"]},{\"name\":\"search_files\",\"result\":[\"graphiti/README.md\",\"graphiti/examples/ecommerce/runner.ipynb\",\"graphiti/examples/langgraph-agent/agent.ipynb\",\"graphiti/examples/podcast/podcast_runner.py\",\"graphiti/examples/podcast/podcast_transcript.txt\",\"graphiti/examples/podcast/transcript_parser.py\",\"graphiti/examples/quickstart/README.md\",\"graphiti/graphiti_core/driver/driver.py\",\"graphiti/graphiti_core/driver/falkordb_driver.py\",\"graphiti/graphiti_core/driver/kuzu_driver.py\",\"graphiti/graphiti_core/driver/neo4j_driver.py\",\"graphiti/graphiti_core/driver/neptune_driver.py\",\"graphiti/graphiti_core/edges.py\",\"graphiti/graphiti_core/errors.py\",\"graphiti/graphiti_core/graph_queries.py\",\"graphiti/graphiti_core/graphiti.py\",\"graphiti/graphiti_core/helpers.py\",\"graphiti/graphiti_core/llm_client/anthropic_client.py\",\"graphiti/graphiti_core/llm_client/client.py\",\"graphiti/graphiti_core/llm_client/gemini_client.py\",\"graphiti/graphiti_core/llm_client/openai_generic_client.py\",\"graphiti/graphiti_core/models/edges/edge_db_queries.py\",\"graphiti/graphiti_core/models/nodes/node_db_queries.py\",\"graphiti/graphiti_core/nodes.py\",\"graphiti/graphiti_core/prompts/dedupe_nodes.py\",\"graphiti/graphiti_core/prompts/eval.py\",\"graphiti/graphiti_core/prompts/extract_edges.py\",\"graphiti/graphiti_core/prompts/extract_nodes.py\",\"graphiti/graphiti_core/prompts/summarize_nodes.py\",\"graphiti/graphiti_core/search/search.py\",\"graphiti/graphiti_core/search/search_config.py\",\"graphiti/graphiti_core/search/search_helpers.py\",\"graphiti/graphiti_core/search/search_utils.py\",\"graphiti/graphiti_core/utils/bulk_utils.py\",\"graphiti/graphiti_core/utils/maintenance/__init__.py\",\"graphiti/graphiti_core/utils/maintenance/community_operations.py\",\"graphiti/graphiti_core/utils/maintenance/edge_operations.py\",\"graphiti/graphiti_core/utils/maintenance/graph_data_operations.py\",\"graphiti/graphiti_core/utils/maintenance/node_operations.py\",\"graphiti/graphiti_core/utils/maintenance/temporal_operations.py\",\"graphiti/graphiti_core/utils/ontology_utils/entity_types_utils.py\"]}]",
          "turn": 1,
          "askedAt": "2025-09-12T19:35:33.097Z",
          "completedAt": "2025-09-12T19:35:33.340Z",
          "source": "tools",
          "promptTokens": 0,
          "completionTokens": 0
        },
        {
          "role": "assistant",
          "content": "{\"thoughts\":\"Open graphiti_core Neo4j driver and related schema/init utilities to see how to create required labels/indexes (e.g., node_name_and_summary) and hook them into app startup.\",\"tool_calls\":[{\"tool_name\":\"read_files\",\"arguments\":{\"paths\":[\"graphiti/graphiti_core/driver/neo4j_driver.py\",\"graphiti/graphiti_core/graphiti.py\",\"graphiti/graphiti_core/graph_queries.py\",\"graphiti/graphiti_core/models/nodes/node_db_queries.py\",\"graphiti/graphiti_core/models/edges/edge_db_queries.py\",\"graphiti/graphiti_core/search/search_utils.py\"]}}]}",
          "promptTokens": 20056,
          "completionTokens": 208,
          "provider": "openai",
          "model": "gpt-5",
          "turn": 2,
          "askedAt": "2025-09-12T19:35:33.342Z",
          "completedAt": "2025-09-12T19:35:38.864Z"
        },
        {
          "role": "user",
          "content": "[{\"name\":\"read_files\",\"result\":\"{\\\"graphiti/graphiti_core/driver/neo4j_driver.py\\\":\\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nCopyright 2024, Zep Software, Inc.\\\\n\\\\nLicensed under the Apache License, Version 2.0 (the \\\\\\\"License\\\\\\\");\\\\nyou may not use this file except in compliance with the License.\\\\nYou may obtain a copy of the License at\\\\n\\\\n    http://www.apache.org/licenses/LICENSE-2.0\\\\n\\\\nUnless required by applicable law or agreed to in writing, software\\\\ndistributed under the License is distributed on an \\\\\\\"AS IS\\\\\\\" BASIS,\\\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\nSee the License for the specific language governing permissions and\\\\nlimitations under the License.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport logging\\\\nfrom collections.abc import Coroutine\\\\nfrom typing import Any\\\\n\\\\nfrom neo4j import AsyncGraphDatabase, EagerResult\\\\nfrom typing_extensions import LiteralString\\\\n\\\\nfrom graphiti_core.driver.driver import GraphDriver, GraphDriverSession, GraphProvider\\\\nfrom graphiti_core.helpers import semaphore_gather\\\\n\\\\nlogger = logging.getLogger(__name__)\\\\n\\\\ntry:\\\\n    import boto3\\\\n    from opensearchpy import OpenSearch, Urllib3AWSV4SignerAuth, Urllib3HttpConnection\\\\n\\\\n    _HAS_OPENSEARCH = True\\\\nexcept ImportError:\\\\n    boto3 = None\\\\n    OpenSearch = None\\\\n    Urllib3AWSV4SignerAuth = None\\\\n    Urllib3HttpConnection = None\\\\n    _HAS_OPENSEARCH = False\\\\n\\\\n\\\\nclass Neo4jDriver(GraphDriver):\\\\n    provider = GraphProvider.NEO4J\\\\n\\\\n    def __init__(\\\\n        self,\\\\n        uri: str,\\\\n        user: str | None,\\\\n        password: str | None,\\\\n        database: str = 'neo4j',\\\\n        aoss_host: str | None = None,\\\\n        aoss_port: int | None = None,\\\\n    ):\\\\n        super().__init__()\\\\n        self.client = AsyncGraphDatabase.driver(\\\\n            uri=uri,\\\\n            auth=(user or '', password or ''),\\\\n        )\\\\n        self._database = database\\\\n\\\\n        self.aoss_client = None\\\\n        if aoss_host and aoss_port and boto3 is not None:\\\\n            try:\\\\n                session = boto3.Session()\\\\n                self.aoss_client = OpenSearch(  # type: ignore\\\\n                    hosts=[{'host': aoss_host, 'port': aoss_port}],\\\\n                    http_auth=Urllib3AWSV4SignerAuth(  # type: ignore\\\\n                        session.get_credentials(), session.region_name, 'aoss'\\\\n                    ),\\\\n                    use_ssl=True,\\\\n                    verify_certs=True,\\\\n                    connection_class=Urllib3HttpConnection,\\\\n                    pool_maxsize=20,\\\\n                )  # type: ignore\\\\n            except Exception as e:\\\\n                logger.warning(f'Failed to initialize OpenSearch client: {e}')\\\\n                self.aoss_client = None\\\\n\\\\n    async def execute_query(self, cypher_query_: LiteralString, **kwargs: Any) -> EagerResult:\\\\n        # Check if database_ is provided in kwargs.\\\\n        # If not populated, set the value to retain backwards compatibility\\\\n        params = kwargs.pop('params', None)\\\\n        if params is None:\\\\n            params = {}\\\\n        params.setdefault('database_', self._database)\\\\n\\\\n        try:\\\\n            result = await self.client.execute_query(cypher_query_, parameters_=params, **kwargs)\\\\n        except Exception as e:\\\\n            logger.error(f'Error executing Neo4j query: {e}\\\\\\\\n{cypher_query_}\\\\\\\\n{params}')\\\\n            raise\\\\n\\\\n        return result\\\\n\\\\n    def session(self, database: str | None = None) -> GraphDriverSession:\\\\n        _database = database or self._database\\\\n        return self.client.session(database=_database)  # type: ignore\\\\n\\\\n    async def close(self) -> None:\\\\n        return await self.client.close()\\\\n\\\\n    def delete_all_indexes(self) -> Coroutine:\\\\n        if self.aoss_client:\\\\n            return semaphore_gather(\\\\n                self.client.execute_query(\\\\n                    'CALL db.indexes() YIELD name DROP INDEX name',\\\\n                ),\\\\n                self.delete_aoss_indices(),\\\\n            )\\\\n        return self.client.execute_query(\\\\n            'CALL db.indexes() YIELD name DROP INDEX name',\\\\n        )\\\\n\\\",\\\"graphiti/graphiti_core/graphiti.py\\\":\\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nCopyright 2024, Zep Software, Inc.\\\\n\\\\nLicensed under the Apache License, Version 2.0 (the \\\\\\\"License\\\\\\\");\\\\nyou may not use this file except in compliance with the License.\\\\nYou may obtain a copy of the License at\\\\n\\\\n    http://www.apache.org/licenses/LICENSE-2.0\\\\n\\\\nUnless required by applicable law or agreed to in writing, software\\\\ndistributed under the License is distributed on an \\\\\\\"AS IS\\\\\\\" BASIS,\\\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\nSee the License for the specific language governing permissions and\\\\nlimitations under the License.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport logging\\\\nfrom datetime import datetime\\\\nfrom time import time\\\\n\\\\nfrom dotenv import load_dotenv\\\\nfrom pydantic import BaseModel\\\\nfrom typing_extensions import LiteralString\\\\n\\\\nfrom graphiti_core.cross_encoder.client import CrossEncoderClient\\\\nfrom graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient\\\\nfrom graphiti_core.driver.driver import GraphDriver\\\\nfrom graphiti_core.driver.neo4j_driver import Neo4jDriver\\\\nfrom graphiti_core.edges import (\\\\n    CommunityEdge,\\\\n    Edge,\\\\n    EntityEdge,\\\\n    EpisodicEdge,\\\\n    create_entity_edge_embeddings,\\\\n)\\\\nfrom graphiti_core.embedder import EmbedderClient, OpenAIEmbedder\\\\nfrom graphiti_core.graphiti_types import GraphitiClients\\\\nfrom graphiti_core.helpers import (\\\\n    get_default_group_id,\\\\n    semaphore_gather,\\\\n    validate_excluded_entity_types,\\\\n    validate_group_id,\\\\n)\\\\nfrom graphiti_core.llm_client import LLMClient, OpenAIClient\\\\nfrom graphiti_core.nodes import (\\\\n    CommunityNode,\\\\n    EntityNode,\\\\n    EpisodeType,\\\\n    EpisodicNode,\\\\n    Node,\\\\n    create_entity_node_embeddings,\\\\n)\\\\nfrom graphiti_core.search.search import SearchConfig, search\\\\nfrom graphiti_core.search.search_config import DEFAULT_SEARCH_LIMIT, SearchResults\\\\nfrom graphiti_core.search.search_config_recipes import (\\\\n    COMBINED_HYBRID_SEARCH_CROSS_ENCODER,\\\\n    EDGE_HYBRID_SEARCH_NODE_DISTANCE,\\\\n    EDGE_HYBRID_SEARCH_RRF,\\\\n)\\\\nfrom graphiti_core.search.search_filters import SearchFilters\\\\nfrom graphiti_core.search.search_utils import (\\\\n    RELEVANT_SCHEMA_LIMIT,\\\\n    get_edge_invalidation_candidates,\\\\n    get_mentioned_nodes,\\\\n    get_relevant_edges,\\\\n)\\\\nfrom graphiti_core.telemetry import capture_event\\\\nfrom graphiti_core.utils.bulk_utils import (\\\\n    RawEpisode,\\\\n    add_nodes_and_edges_bulk,\\\\n    dedupe_edges_bulk,\\\\n    dedupe_nodes_bulk,\\\\n    extract_nodes_and_edges_bulk,\\\\n    resolve_edge_pointers,\\\\n    retrieve_previous_episodes_bulk,\\\\n)\\\\nfrom graphiti_core.utils.datetime_utils import utc_now\\\\nfrom graphiti_core.utils.maintenance.community_operations import (\\\\n    build_communities,\\\\n    remove_communities,\\\\n    update_community,\\\\n)\\\\nfrom graphiti_core.utils.maintenance.edge_operations import (\\\\n    build_duplicate_of_edges,\\\\n    build_episodic_edges,\\\\n    extract_edges,\\\\n    resolve_extracted_edge,\\\\n    resolve_extracted_edges,\\\\n)\\\\nfrom graphiti_core.utils.maintenance.graph_data_operations import (\\\\n    EPISODE_WINDOW_LEN,\\\\n    build_indices_and_constraints,\\\\n    retrieve_episodes,\\\\n)\\\\nfrom graphiti_core.utils.maintenance.node_operations import (\\\\n    extract_attributes_from_nodes,\\\\n    extract_nodes,\\\\n    resolve_extracted_nodes,\\\\n)\\\\nfrom graphiti_core.utils.ontology_utils.entity_types_utils import validate_entity_types\\\\n\\\\nlogger = logging.getLogger(__name__)\\\\n\\\\nload_dotenv()\\\\n\\\\n\\\\nclass AddEpisodeResults(BaseModel):\\\\n    episode: EpisodicNode\\\\n    episodic_edges: list[EpisodicEdge]\\\\n    nodes: list[EntityNode]\\\\n    edges: list[EntityEdge]\\\\n    communities: list[CommunityNode]\\\\n    community_edges: list[CommunityEdge]\\\\n\\\\n\\\\nclass AddBulkEpisodeResults(BaseModel):\\\\n    episodes: list[EpisodicNode]\\\\n    episodic_edges: list[EpisodicEdge]\\\\n    nodes: list[EntityNode]\\\\n    edges: list[EntityEdge]\\\\n    communities: list[CommunityNode]\\\\n    community_edges: list[CommunityEdge]\\\\n\\\\n\\\\nclass AddTripletResults(BaseModel):\\\\n    nodes: list[EntityNode]\\\\n    edges: list[EntityEdge]\\\\n\\\\n\\\\nclass Graphiti:\\\\n    def __init__(\\\\n        self,\\\\n        uri: str | None = None,\\\\n        user: str | None = None,\\\\n        password: str | None = None,\\\\n        llm_client: LLMClient | None = None,\\\\n        embedder: EmbedderClient | None = None,\\\\n        cross_encoder: CrossEncoderClient | None = None,\\\\n        store_raw_episode_content: bool = True,\\\\n        graph_driver: GraphDriver | None = None,\\\\n        max_coroutines: int | None = None,\\\\n        ensure_ascii: bool = False,\\\\n    ):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Initialize a Graphiti instance.\\\\n\\\\n        This constructor sets up a connection to a graph database and initializes\\\\n        the LLM client for natural language processing tasks.\\\\n\\\\n        Parameters\\\\n        ----------\\\\n        uri : str\\\\n            The URI of the Neo4j database.\\\\n        user : str\\\\n            The username for authenticating with the Neo4j database.\\\\n        password : str\\\\n            The password for authenticating with the Neo4j database.\\\\n        llm_client : LLMClient | None, optional\\\\n            An instance of LLMClient for natural language processing tasks.\\\\n            If not provided, a default OpenAIClient will be initialized.\\\\n        embedder : EmbedderClient | None, optional\\\\n            An instance of EmbedderClient for embedding tasks.\\\\n            If not provided, a default OpenAIEmbedder will be initialized.\\\\n        cross_encoder : CrossEncoderClient | None, optional\\\\n            An instance of CrossEncoderClient for reranking tasks.\\\\n            If not provided, a default OpenAIRerankerClient will be initialized.\\\\n        store_raw_episode_content : bool, optional\\\\n            Whether to store the raw content of episodes. Defaults to True.\\\\n        graph_driver : GraphDriver | None, optional\\\\n            An instance of GraphDriver for database operations.\\\\n            If not provided, a default Neo4jDriver will be initialized.\\\\n        max_coroutines : int | None, optional\\\\n            The maximum number of concurrent operations allowed. Overrides SEMAPHORE_LIMIT set in the environment.\\\\n            If not set, the Graphiti default is used.\\\\n        ensure_ascii : bool, optional\\\\n            Whether to escape non-ASCII characters in JSON serialization for prompts. Defaults to False.\\\\n            Set as False to preserve non-ASCII characters (e.g., Korean, Japanese, Chinese) in their\\\\n            original form, making them readable in LLM logs and improving model understanding.\\\\n\\\\n        Returns\\\\n        -------\\\\n        None\\\\n\\\\n        Notes\\\\n        -----\\\\n        This method establishes a connection to a graph database (Neo4j by default) using the provided\\\\n        credentials. It also sets up the LLM client, either using the provided client\\\\n        or by creating a default OpenAIClient.\\\\n\\\\n        The default database name is defined during the driver’s construction. If a different database name\\\\n        is required, it should be specified in the URI or set separately after\\\\n        initialization.\\\\n\\\\n        The OpenAI API key is expected to be set in the environment variables.\\\\n        Make sure to set the OPENAI_API_KEY environment variable before initializing\\\\n        Graphiti if you're using the default OpenAIClient.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        if graph_driver:\\\\n            self.driver = graph_driver\\\\n        else:\\\\n            if uri is None:\\\\n                raise ValueError('uri must be provided when graph_driver is None')\\\\n            self.driver = Neo4jDriver(uri, user, password)\\\\n\\\\n        self.store_raw_episode_content = store_raw_episode_content\\\\n        self.max_coroutines = max_coroutines\\\\n        self.ensure_ascii = ensure_ascii\\\\n        if llm_client:\\\\n            self.llm_client = llm_client\\\\n        else:\\\\n            self.llm_client = OpenAIClient()\\\\n        if embedder:\\\\n            self.embedder = embedder\\\\n        else:\\\\n            self.embedder = OpenAIEmbedder()\\\\n        if cross_encoder:\\\\n            self.cross_encoder = cross_encoder\\\\n        else:\\\\n            self.cross_encoder = OpenAIRerankerClient()\\\\n\\\\n        self.clients = GraphitiClients(\\\\n            driver=self.driver,\\\\n            llm_client=self.llm_client,\\\\n            embedder=self.embedder,\\\\n            cross_encoder=self.cross_encoder,\\\\n            ensure_ascii=self.ensure_ascii,\\\\n        )\\\\n\\\\n        # Capture telemetry event\\\\n        self._capture_initialization_telemetry()\\\\n\\\\n    def _capture_initialization_telemetry(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Capture telemetry event for Graphiti initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            # Detect provider types from class names\\\\n            llm_provider = self._get_provider_type(self.llm_client)\\\\n            embedder_provider = self._get_provider_type(self.embedder)\\\\n            reranker_provider = self._get_provider_type(self.cross_encoder)\\\\n            database_provider = self._get_provider_type(self.driver)\\\\n\\\\n            properties = {\\\\n                'llm_provider': llm_provider,\\\\n                'embedder_provider': embedder_provider,\\\\n                'reranker_provider': reranker_provider,\\\\n                'database_provider': database_provider,\\\\n            }\\\\n\\\\n            capture_event('graphiti_initialized', properties)\\\\n        except Exception:\\\\n            # Silently handle telemetry errors\\\\n            pass\\\\n\\\\n    def _get_provider_type(self, client) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get provider type from client class name.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if client is None:\\\\n            return 'none'\\\\n\\\\n        class_name = client.__class__.__name__.lower()\\\\n\\\\n        # LLM providers\\\\n        if 'openai' in class_name:\\\\n            return 'openai'\\\\n        elif 'azure' in class_name:\\\\n            return 'azure'\\\\n        elif 'anthropic' in class_name:\\\\n            return 'anthropic'\\\\n        elif 'crossencoder' in class_name:\\\\n            return 'crossencoder'\\\\n        elif 'gemini' in class_name:\\\\n            return 'gemini'\\\\n        elif 'groq' in class_name:\\\\n            return 'groq'\\\\n        # Database providers\\\\n        elif 'neo4j' in class_name:\\\\n            return 'neo4j'\\\\n        elif 'falkor' in class_name:\\\\n            return 'falkordb'\\\\n        # Embedder providers\\\\n        elif 'voyage' in class_name:\\\\n            return 'voyage'\\\\n        else:\\\\n            return 'unknown'\\\\n\\\\n    async def close(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Close the connection to the Neo4j database.\\\\n\\\\n        This method safely closes the driver connection to the Neo4j database.\\\\n        It should be called when the Graphiti instance is no longer needed or\\\\n        when the application is shutting down.\\\\n\\\\n        Parameters\\\\n        ----------\\\\n        self\\\\n\\\\n        Returns\\\\n        -------\\\\n        None\\\\n\\\\n        Notes\\\\n        -----\\\\n        It's important to close the driver connection to release system resources\\\\n        and ensure that all pending transactions are completed or rolled back.\\\\n        This method should be called as part of a cleanup process, potentially\\\\n        in a context manager or a shutdown hook.\\\\n\\\\n        Example:\\\\n            graphiti = Graphiti(uri, user, password)\\\\n            try:\\\\n                # Use graphiti...\\\\n            finally:\\\\n                graphiti.close()\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await self.driver.close()\\\\n\\\\n    async def build_indices_and_constraints(self, delete_existing: bool = False):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Build indices and constraints in the Neo4j database.\\\\n\\\\n        This method sets up the necessary indices and constraints in the Neo4j database\\\\n        to optimize query performance and ensure data integrity for the knowledge graph.\\\\n\\\\n        Parameters\\\\n        ----------\\\\n        self\\\\n        delete_existing : bool, optional\\\\n            Whether to clear existing indices before creating new ones.\\\\n\\\\n\\\\n        Returns\\\\n        -------\\\\n        None\\\\n\\\\n        Notes\\\\n        -----\\\\n        This method should typically be called once during the initial setup of the\\\\n        knowledge graph or when updating the database schema. It uses the\\\\n        `build_indices_and_constraints` function from the\\\\n        `graphiti_core.utils.maintenance.graph_data_operations` module to perform\\\\n        the actual database operations.\\\\n\\\\n        The specific indices and constraints created depend on the implementation\\\\n        of the `build_indices_and_constraints` function. Refer to that function's\\\\n        documentation for details on the exact database schema modifications.\\\\n\\\\n        Caution: Running this method on a large existing database may take some time\\\\n        and could impact database performance during execution.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await build_indices_and_constraints(self.driver, delete_existing)\\\\n\\\\n    async def retrieve_episodes(\\\\n        self,\\\\n        reference_time: datetime,\\\\n        last_n: int = EPISODE_WINDOW_LEN,\\\\n        group_ids: list[str] | None = None,\\\\n        source: EpisodeType | None = None,\\\\n    ) -> list[EpisodicNode]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Retrieve the last n episodic nodes from the graph.\\\\n\\\\n        This method fetches a specified number of the most recent episodic nodes\\\\n        from the graph, relative to the given reference time.\\\\n\\\\n        Parameters\\\\n        ----------\\\\n        reference_time : datetime\\\\n            The reference time to retrieve episodes before.\\\\n        last_n : int, optional\\\\n            The number of episodes to retrieve. Defaults to EPISODE_WINDOW_LEN.\\\\n        group_ids : list[str | None], optional\\\\n            The group ids to return data from.\\\\n\\\\n        Returns\\\\n        -------\\\\n        list[EpisodicNode]\\\\n            A list of the most recent EpisodicNode objects.\\\\n\\\\n        Notes\\\\n        -----\\\\n        The actual retrieval is performed by the `retrieve_episodes` function\\\\n        from the `graphiti_core.utils` module.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return await retrieve_episodes(self.driver, reference_time, last_n, group_ids, source)\\\\n\\\\n    async def add_episode(\\\\n        self,\\\\n        name: str,\\\\n        episode_body: str,\\\\n        source_description: str,\\\\n        reference_time: datetime,\\\\n        source: EpisodeType = EpisodeType.message,\\\\n        group_id: str | None = None,\\\\n        uuid: str | None = None,\\\\n        update_communities: bool = False,\\\\n        entity_types: dict[str, type[BaseModel]] | None = None,\\\\n        excluded_entity_types: list[str] | None = None,\\\\n        previous_episode_uuids: list[str] | None = None,\\\\n        edge_types: dict[str, type[BaseModel]] | None = None,\\\\n        edge_type_map: dict[tuple[str, str], list[str]] | None = None,\\\\n    ) -> AddEpisodeResults:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Process an episode and update the graph.\\\\n\\\\n        This method extracts information from the episode, creates nodes and edges,\\\\n        and updates the graph database accordingly.\\\\n\\\\n        Parameters\\\\n        ----------\\\\n        name : str\\\\n            The name of the episode.\\\\n        episode_body : str\\\\n            The content of the episode.\\\\n        source_description : str\\\\n            A description of the episode's source.\\\\n        reference_time : datetime\\\\n            The reference time for the episode.\\\\n        source : EpisodeType, optional\\\\n            The type of the episode. Defaults to EpisodeType.message.\\\\n        group_id : str | None\\\\n            An id for the graph partition the episode is a part of.\\\\n        uuid : str | None\\\\n            Optional uuid of the episode.\\\\n        update_communities : bool\\\\n            Optional. Whether to update communities with new node information\\\\n        entity_types : dict[str, BaseModel] | None\\\\n            Optional. Dictionary mapping entity type names to their Pydantic model definitions.\\\\n        excluded_entity_types : list[str] | None\\\\n            Optional. List of entity type names to exclude from the graph. Entities classified\\\\n            into these types will not be added to the graph. Can include 'Entity' to exclude\\\\n            the default entity type.\\\\n        previous_episode_uuids : list[str] | None\\\\n            Optional.  list of episode uuids to use as the previous episodes. If this is not provided,\\\\n            the most recent episodes by created_at date will be used.\\\\n\\\\n        Returns\\\\n        -------\\\\n        None\\\\n\\\\n        Notes\\\\n        -----\\\\n        This method performs several steps including node extraction, edge extraction,\\\\n        deduplication, and database updates. It also handles embedding generation\\\\n        and edge invalidation.\\\\n\\\\n        It is recommended to run this method as a background process, such as in a queue.\\\\n        It's important that each episode is added sequentially and awaited before adding\\\\n        the next one. For web applications, consider using FastAPI's background tasks\\\\n        or a dedicated task queue like Celery for this purpose.\\\\n\\\\n        Example using FastAPI background tasks:\\\\n            @app.post(\\\\\\\"/add_episode\\\\\\\")\\\\n            async def add_episode_endpoint(episode_data: EpisodeData):\\\\n                background_tasks.add_task(graphiti.add_episode, **episode_data.dict())\\\\n                return {\\\\\\\"message\\\\\\\": \\\\\\\"Episode processing started\\\\\\\"}\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            start = time()\\\\n            now = utc_now()\\\\n\\\\n            # if group_id is None, use the default group id by the provider\\\\n            group_id = group_id or get_default_group_id(self.driver.provider)\\\\n            validate_entity_types(entity_types)\\\\n\\\\n            validate_excluded_entity_types(excluded_entity_types, entity_types)\\\\n            validate_group_id(group_id)\\\\n\\\\n            previous_episodes = (\\\\n                await self.retrieve_episodes(\\\\n                    reference_time,\\\\n                    last_n=RELEVANT_SCHEMA_LIMIT,\\\\n                    group_ids=[group_id],\\\\n                    source=source,\\\\n                )\\\\n                if previous_episode_uuids is None\\\\n                else await EpisodicNode.get_by_uuids(self.driver, previous_episode_uuids)\\\\n            )\\\\n\\\\n            episode = (\\\\n                await EpisodicNode.get_by_uuid(self.driver, uuid)\\\\n                if uuid is not None\\\\n                else EpisodicNode(\\\\n                    name=name,\\\\n                    group_id=group_id,\\\\n                    labels=[],\\\\n                    source=source,\\\\n                    content=episode_body,\\\\n                    source_description=source_description,\\\\n                    created_at=now,\\\\n                    valid_at=reference_time,\\\\n                )\\\\n            )\\\\n\\\\n            # Create default edge type map\\\\n            edge_type_map_default = (\\\\n                {('Entity', 'Entity'): list(edge_types.keys())}\\\\n                if edge_types is not None\\\\n                else {('Entity', 'Entity'): []}\\\\n            )\\\\n\\\\n            # Extract entities as nodes\\\\n\\\\n            extracted_nodes = await extract_nodes(\\\\n                self.clients, episode, previous_episodes, entity_types, excluded_entity_types\\\\n            )\\\\n\\\\n            # Extract edges and resolve nodes\\\\n            (nodes, uuid_map, node_duplicates), extracted_edges = await semaphore_gather(\\\\n                resolve_extracted_nodes(\\\\n                    self.clients,\\\\n                    extracted_nodes,\\\\n                    episode,\\\\n                    previous_episodes,\\\\n                    entity_types,\\\\n                ),\\\\n                extract_edges(\\\\n                    self.clients,\\\\n                    episode,\\\\n                    extracted_nodes,\\\\n                    previous_episodes,\\\\n                    edge_type_map or edge_type_map_default,\\\\n                    group_id,\\\\n                    edge_types,\\\\n                ),\\\\n                max_coroutines=self.max_coroutines,\\\\n            )\\\\n\\\\n            edges = resolve_edge_pointers(extracted_edges, uuid_map)\\\\n\\\\n            (resolved_edges, invalidated_edges), hydrated_nodes = await semaphore_gather(\\\\n                resolve_extracted_edges(\\\\n                    self.clients,\\\\n                    edges,\\\\n                    episode,\\\\n                    nodes,\\\\n                    edge_types or {},\\\\n                    edge_type_map or edge_type_map_default,\\\\n                ),\\\\n                extract_attributes_from_nodes(\\\\n                    self.clients, nodes, episode, previous_episodes, entity_types\\\\n                ),\\\\n                max_coroutines=self.max_coroutines,\\\\n            )\\\\n\\\\n            duplicate_of_edges = build_duplicate_of_edges(episode, now, node_duplicates)\\\\n\\\\n            entity_edges = resolved_edges + invalidated_edges + duplicate_of_edges\\\\n\\\\n            episodic_edges = build_episodic_edges(nodes, episode.uuid, now)\\\\n\\\\n            episode.entity_edges = [edge.uuid for edge in entity_edges]\\\\n\\\\n            if not self.store_raw_episode_content:\\\\n                episode.content = ''\\\\n\\\\n            await add_nodes_and_edges_bulk(\\\\n                self.driver, [episode], episodic_edges, hydrated_nodes, entity_edges, self.embedder\\\\n            )\\\\n\\\\n            communities = []\\\\n            community_edges = []\\\\n\\\\n            # Update any communities\\\\n            if update_communities:\\\\n                communities, community_edges = await semaphore_gather(\\\\n                    *[\\\\n                        update_community(\\\\n                            self.driver, self.llm_client, self.embedder, node, self.ensure_ascii\\\\n                        )\\\\n                        for node in nodes\\\\n                    ],\\\\n                    max_coroutines=self.max_coroutines,\\\\n                )\\\\n            end = time()\\\\n            logger.info(f'Completed add_episode in {(end - start) * 1000} ms')\\\\n\\\\n            return AddEpisodeResults(\\\\n                episode=episode,\\\\n                episodic_edges=episodic_edges,\\\\n                nodes=hydrated_nodes,\\\\n                edges=entity_edges,\\\\n                communities=communities,\\\\n                community_edges=community_edges,\\\\n            )\\\\n\\\\n        except Exception as e:\\\\n            raise e\\\\n\\\\n    async def add_episode_bulk(\\\\n        self,\\\\n        bulk_episodes: list[RawEpisode],\\\\n        group_id: str | None = None,\\\\n        entity_types: dict[str, type[BaseModel]] | None = None,\\\\n        excluded_entity_types: list[str] | None = None,\\\\n        edge_types: dict[str, type[BaseModel]] | None = None,\\\\n        edge_type_map: dict[tuple[str, str], list[str]] | None = None,\\\\n    ) -> AddBulkEpisodeResults:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Process multiple episodes in bulk and update the graph.\\\\n\\\\n        This method extracts information from multiple episodes, creates nodes and edges,\\\\n        and updates the graph database accordingly, all in a single batch operation.\\\\n\\\\n        Parameters\\\\n        ----------\\\\n        bulk_episodes : list[RawEpisode]\\\\n            A list of RawEpisode objects to be processed and added to the graph.\\\\n        group_id : str | None\\\\n            An id for the graph partition the episode is a part of.\\\\n\\\\n        Returns\\\\n        -------\\\\n        AddBulkEpisodeResults\\\\n\\\\n        Notes\\\\n        -----\\\\n        This method performs several steps including:\\\\n        - Saving all episodes to the database\\\\n        - Retrieving previous episode context for each new episode\\\\n        - Extracting nodes and edges from all episodes\\\\n        - Generating embeddings for nodes and edges\\\\n        - Deduplicating nodes and edges\\\\n        - Saving nodes, episodic edges, and entity edges to the knowledge graph\\\\n\\\\n        This bulk operation is designed for efficiency when processing multiple episodes\\\\n        at once. However, it's important to ensure that the bulk operation doesn't\\\\n        overwhelm system resources. Consider implementing rate limiting or chunking for\\\\n        very large batches of episodes.\\\\n\\\\n        Important: This method does not perform edge invalidation or date extraction steps.\\\\n        If these operations are required, use the `add_episode` method instead for each\\\\n        individual episode.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            start = time()\\\\n            now = utc_now()\\\\n\\\\n            # if group_id is None, use the default group id by the provider\\\\n            group_id = group_id or get_default_group_id(self.driver.provider)\\\\n            validate_group_id(group_id)\\\\n\\\\n            # Create default edge type map\\\\n            edge_type_map_default = (\\\\n                {('Entity', 'Entity'): list(edge_types.keys())}\\\\n                if edge_types is not None\\\\n                else {('Entity', 'Entity'): []}\\\\n            )\\\\n\\\\n            episodes = [\\\\n                await EpisodicNode.get_by_uuid(self.driver, episode.uuid)\\\\n                if episode.uuid is not None\\\\n                else EpisodicNode(\\\\n                    name=episode.name,\\\\n                    labels=[],\\\\n                    source=episode.source,\\\\n                    content=episode.content,\\\\n                    source_description=episode.source_description,\\\\n                    group_id=group_id,\\\\n                    created_at=now,\\\\n                    valid_at=episode.reference_time,\\\\n                )\\\\n                for episode in bulk_episodes\\\\n            ]\\\\n\\\\n            episodes_by_uuid: dict[str, EpisodicNode] = {\\\\n                episode.uuid: episode for episode in episodes\\\\n            }\\\\n\\\\n            # Save all episodes\\\\n            await add_nodes_and_edges_bulk(\\\\n                driver=self.driver,\\\\n                episodic_nodes=episodes,\\\\n                episodic_edges=[],\\\\n                entity_nodes=[],\\\\n                entity_edges=[],\\\\n                embedder=self.embedder,\\\\n            )\\\\n\\\\n            # Get previous episode context for each episode\\\\n            episode_context = await retrieve_previous_episodes_bulk(self.driver, episodes)\\\\n\\\\n            # Extract all nodes and edges for each episode\\\\n            extracted_nodes_bulk, extracted_edges_bulk = await extract_nodes_and_edges_bulk(\\\\n                self.clients,\\\\n                episode_context,\\\\n                edge_type_map=edge_type_map or edge_type_map_default,\\\\n                edge_types=edge_types,\\\\n                entity_types=entity_types,\\\\n                excluded_entity_types=excluded_entity_types,\\\\n            )\\\\n\\\\n            # Dedupe extracted nodes in memory\\\\n            nodes_by_episode, uuid_map = await dedupe_nodes_bulk(\\\\n                self.clients, extracted_nodes_bulk, episode_context, entity_types\\\\n            )\\\\n\\\\n            # Create Episodic Edges\\\\n            episodic_edges: list[EpisodicEdge] = []\\\\n            for episode_uuid, nodes in nodes_by_episode.items():\\\\n                episodic_edges.extend(build_episodic_edges(nodes, episode_uuid, now))\\\\n\\\\n            # re-map edge pointers so that they don't point to discard dupe nodes\\\\n            extracted_edges_bulk_updated: list[list[EntityEdge]] = [\\\\n                resolve_edge_pointers(edges, uuid_map) for edges in extracted_edges_bulk\\\\n            ]\\\\n\\\\n            # Dedupe extracted edges in memory\\\\n            edges_by_episode = await dedupe_edges_bulk(\\\\n                self.clients,\\\\n                extracted_edges_bulk_updated,\\\\n                episode_context,\\\\n                [],\\\\n                edge_types or {},\\\\n                edge_type_map or edge_type_map_default,\\\\n            )\\\\n\\\\n            # Extract node attributes\\\\n            nodes_by_uuid: dict[str, EntityNode] = {\\\\n                node.uuid: node for nodes in nodes_by_episode.values() for node in nodes\\\\n            }\\\\n\\\\n            extract_attributes_params: list[tuple[EntityNode, list[EpisodicNode]]] = []\\\\n            for node in nodes_by_uuid.values():\\\\n                episode_uuids: list[str] = []\\\\n                for episode_uuid, mentioned_nodes in nodes_by_episode.items():\\\\n                    for mentioned_node in mentioned_nodes:\\\\n                        if node.uuid == mentioned_node.uuid:\\\\n                            episode_uuids.append(episode_uuid)\\\\n                            break\\\\n\\\\n                episode_mentions: list[EpisodicNode] = [\\\\n                    episodes_by_uuid[episode_uuid] for episode_uuid in episode_uuids\\\\n                ]\\\\n                episode_mentions.sort(key=lambda x: x.valid_at, reverse=True)\\\\n\\\\n                extract_attributes_params.append((node, episode_mentions))\\\\n\\\\n            new_hydrated_nodes: list[list[EntityNode]] = await semaphore_gather(\\\\n                *[\\\\n                    extract_attributes_from_nodes(\\\\n                        self.clients,\\\\n                        [params[0]],\\\\n                        params[1][0],\\\\n                        params[1][0:],\\\\n                        entity_types,\\\\n                    )\\\\n                    for params in extract_attributes_params\\\\n                ]\\\\n            )\\\\n\\\\n            hydrated_nodes = [node for nodes in new_hydrated_nodes for node in nodes]\\\\n\\\\n            # Update nodes_by_uuid map with the hydrated nodes\\\\n            for hydrated_node in hydrated_nodes:\\\\n                nodes_by_uuid[hydrated_node.uuid] = hydrated_node\\\\n\\\\n            # Resolve nodes and edges against the existing graph\\\\n            nodes_by_episode_unique: dict[str, list[EntityNode]] = {}\\\\n            nodes_uuid_set: set[str] = set()\\\\n            for episode, _ in episode_context:\\\\n                nodes_by_episode_unique[episode.uuid] = []\\\\n                nodes = [nodes_by_uuid[node.uuid] for node in nodes_by_episode[episode.uuid]]\\\\n                for node in nodes:\\\\n                    if node.uuid not in nodes_uuid_set:\\\\n                        nodes_by_episode_unique[episode.uuid].append(node)\\\\n                        nodes_uuid_set.add(node.uuid)\\\\n\\\\n            node_results = await semaphore_gather(\\\\n                *[\\\\n                    resolve_extracted_nodes(\\\\n                        self.clients,\\\\n                        nodes_by_episode_unique[episode.uuid],\\\\n                        episode,\\\\n                        previous_episodes,\\\\n                        entity_types,\\\\n                    )\\\\n                    for episode, previous_episodes in episode_context\\\\n                ]\\\\n            )\\\\n\\\\n            resolved_nodes: list[EntityNode] = []\\\\n            uuid_map: dict[str, str] = {}\\\\n            node_duplicates: list[tuple[EntityNode, EntityNode]] = []\\\\n            for result in node_results:\\\\n                resolved_nodes.extend(result[0])\\\\n                uuid_map.update(result[1])\\\\n                node_duplicates.extend(result[2])\\\\n\\\\n            # Update nodes_by_uuid map with the resolved nodes\\\\n            for resolved_node in resolved_nodes:\\\\n                nodes_by_uuid[resolved_node.uuid] = resolved_node\\\\n\\\\n            # update nodes_by_episode_unique mapping\\\\n            for episode_uuid, nodes in nodes_by_episode_unique.items():\\\\n                updated_nodes: list[EntityNode] = []\\\\n                for node in nodes:\\\\n                    updated_node_uuid = uuid_map.get(node.uuid, node.uuid)\\\\n                    updated_node = nodes_by_uuid[updated_node_uuid]\\\\n                    updated_nodes.append(updated_node)\\\\n\\\\n                nodes_by_episode_unique[episode_uuid] = updated_nodes\\\\n\\\\n            hydrated_nodes_results: list[list[EntityNode]] = await semaphore_gather(\\\\n                *[\\\\n                    extract_attributes_from_nodes(\\\\n                        self.clients,\\\\n                        nodes_by_episode_unique[episode.uuid],\\\\n                        episode,\\\\n                        previous_episodes,\\\\n                        entity_types,\\\\n                    )\\\\n                    for episode, previous_episodes in episode_context\\\\n                ]\\\\n            )\\\\n\\\\n            final_hydrated_nodes = [node for nodes in hydrated_nodes_results for node in nodes]\\\\n\\\\n            edges_by_episode_unique: dict[str, list[EntityEdge]] = {}\\\\n            edges_uuid_set: set[str] = set()\\\\n            for episode_uuid, edges in edges_by_episode.items():\\\\n                edges_with_updated_pointers = resolve_edge_pointers(edges, uuid_map)\\\\n                edges_by_episode_unique[episode_uuid] = []\\\\n\\\\n                for edge in edges_with_updated_pointers:\\\\n                    if edge.uuid not in edges_uuid_set:\\\\n                        edges_by_episode_unique[episode_uuid].append(edge)\\\\n                        edges_uuid_set.add(edge.uuid)\\\\n\\\\n            edge_results = await semaphore_gather(\\\\n                *[\\\\n                    resolve_extracted_edges(\\\\n                        self.clients,\\\\n                        edges_by_episode_unique[episode.uuid],\\\\n                        episode,\\\\n                        hydrated_nodes,\\\\n                        edge_types or {},\\\\n                        edge_type_map or edge_type_map_default,\\\\n                    )\\\\n                    for episode in episodes\\\\n                ]\\\\n            )\\\\n\\\\n            resolved_edges: list[EntityEdge] = []\\\\n            invalidated_edges: list[EntityEdge] = []\\\\n            for result in edge_results:\\\\n                resolved_edges.extend(result[0])\\\\n                invalidated_edges.extend(result[1])\\\\n\\\\n            # Resolved pointers for episodic edges\\\\n            resolved_episodic_edges = resolve_edge_pointers(episodic_edges, uuid_map)\\\\n\\\\n            # save data to KG\\\\n            await add_nodes_and_edges_bulk(\\\\n                self.driver,\\\\n                episodes,\\\\n                resolved_episodic_edges,\\\\n                final_hydrated_nodes,\\\\n                resolved_edges + invalidated_edges,\\\\n                self.embedder,\\\\n            )\\\\n\\\\n            end = time()\\\\n            logger.info(f'Completed add_episode_bulk in {(end - start) * 1000} ms')\\\\n\\\\n            return AddBulkEpisodeResults(\\\\n                episodes=episodes,\\\\n                episodic_edges=resolved_episodic_edges,\\\\n                nodes=final_hydrated_nodes,\\\\n                edges=resolved_edges + invalidated_edges,\\\\n                communities=[],\\\\n                community_edges=[],\\\\n            )\\\\n\\\\n        except Exception as e:\\\\n            raise e\\\\n\\\\n    async def build_communities(\\\\n        self, group_ids: list[str] | None = None\\\\n    ) -> tuple[list[CommunityNode], list[CommunityEdge]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Use a community clustering algorithm to find communities of nodes. Create community nodes summarising\\\\n        the content of these communities.\\\\n        ----------\\\\n        query : list[str] | None\\\\n            Optional. Create communities only for the listed group_ids. If blank the entire graph will be used.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Clear existing communities\\\\n        await remove_communities(self.driver)\\\\n\\\\n        community_nodes, community_edges = await build_communities(\\\\n            self.driver, self.llm_client, group_ids\\\\n        )\\\\n\\\\n        await semaphore_gather(\\\\n            *[node.generate_name_embedding(self.embedder) for node in community_nodes],\\\\n            max_coroutines=self.max_coroutines,\\\\n        )\\\\n\\\\n        await semaphore_gather(\\\\n            *[node.save(self.driver) for node in community_nodes],\\\\n            max_coroutines=self.max_coroutines,\\\\n        )\\\\n        await semaphore_gather(\\\\n            *[edge.save(self.driver) for edge in community_edges],\\\\n            max_coroutines=self.max_coroutines,\\\\n        )\\\\n\\\\n        return community_nodes, community_edges\\\\n\\\\n    async def search(\\\\n        self,\\\\n        query: str,\\\\n        center_node_uuid: str | None = None,\\\\n        group_ids: list[str] | None = None,\\\\n        num_results=DEFAULT_SEARCH_LIMIT,\\\\n        search_filter: SearchFilters | None = None,\\\\n    ) -> list[EntityEdge]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Perform a hybrid search on the knowledge graph.\\\\n\\\\n        This method executes a search query on the graph, combining vector and\\\\n        text-based search techniques to retrieve relevant facts, returning the edges as a string.\\\\n\\\\n        This is our basic out-of-the-box search, for more robust results we recommend using our more advanced\\\\n        search method graphiti.search_().\\\\n\\\\n        Parameters\\\\n        ----------\\\\n        query : str\\\\n            The search query string.\\\\n        center_node_uuid: str, optional\\\\n            Facts will be reranked based on proximity to this node\\\\n        group_ids : list[str | None] | None, optional\\\\n            The graph partitions to return data from.\\\\n        num_results : int, optional\\\\n            The maximum number of results to return. Defaults to 10.\\\\n\\\\n        Returns\\\\n        -------\\\\n        list\\\\n            A list of EntityEdge objects that are relevant to the search query.\\\\n\\\\n        Notes\\\\n        -----\\\\n        This method uses a SearchConfig with num_episodes set to 0 and\\\\n        num_results set to the provided num_results parameter.\\\\n\\\\n        The search is performed using the current date and time as the reference\\\\n        point for temporal relevance.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        search_config = (\\\\n            EDGE_HYBRID_SEARCH_RRF if center_node_uuid is None else EDGE_HYBRID_SEARCH_NODE_DISTANCE\\\\n        )\\\\n        search_config.limit = num_results\\\\n\\\\n        edges = (\\\\n            await search(\\\\n                self.clients,\\\\n                query,\\\\n                group_ids,\\\\n                search_config,\\\\n                search_filter if search_filter is not None else SearchFilters(),\\\\n                center_node_uuid,\\\\n            )\\\\n        ).edges\\\\n\\\\n        return edges\\\\n\\\\n    async def _search(\\\\n        self,\\\\n        query: str,\\\\n        config: SearchConfig,\\\\n        group_ids: list[str] | None = None,\\\\n        center_node_uuid: str | None = None,\\\\n        bfs_origin_node_uuids: list[str] | None = None,\\\\n        search_filter: SearchFilters | None = None,\\\\n    ) -> SearchResults:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"DEPRECATED\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return await self.search_(\\\\n            query, config, group_ids, center_node_uuid, bfs_origin_node_uuids, search_filter\\\\n        )\\\\n\\\\n    async def search_(\\\\n        self,\\\\n        query: str,\\\\n        config: SearchConfig = COMBINED_HYBRID_SEARCH_CROSS_ENCODER,\\\\n        group_ids: list[str] | None = None,\\\\n        center_node_uuid: str | None = None,\\\\n        bfs_origin_node_uuids: list[str] | None = None,\\\\n        search_filter: SearchFilters | None = None,\\\\n    ) -> SearchResults:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"search_ (replaces _search) is our advanced search method that returns Graph objects (nodes and edges) rather\\\\n        than a list of facts. This endpoint allows the end user to utilize more advanced features such as filters and\\\\n        different search and reranker methodologies across different layers in the graph.\\\\n\\\\n        For different config recipes refer to search/search_config_recipes.\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        return await search(\\\\n            self.clients,\\\\n            query,\\\\n            group_ids,\\\\n            config,\\\\n            search_filter if search_filter is not None else SearchFilters(),\\\\n            center_node_uuid,\\\\n            bfs_origin_node_uuids,\\\\n        )\\\\n\\\\n    async def get_nodes_and_edges_by_episode(self, episode_uuids: list[str]) -> SearchResults:\\\\n        episodes = await EpisodicNode.get_by_uuids(self.driver, episode_uuids)\\\\n\\\\n        edges_list = await semaphore_gather(\\\\n            *[EntityEdge.get_by_uuids(self.driver, episode.entity_edges) for episode in episodes],\\\\n            max_coroutines=self.max_coroutines,\\\\n        )\\\\n\\\\n        edges: list[EntityEdge] = [edge for lst in edges_list for edge in lst]\\\\n\\\\n        nodes = await get_mentioned_nodes(self.driver, episodes)\\\\n\\\\n        return SearchResults(edges=edges, nodes=nodes)\\\\n\\\\n    async def add_triplet(\\\\n        self, source_node: EntityNode, edge: EntityEdge, target_node: EntityNode\\\\n    ) -> AddTripletResults:\\\\n        if source_node.name_embedding is None:\\\\n            await source_node.generate_name_embedding(self.embedder)\\\\n        if target_node.name_embedding is None:\\\\n            await target_node.generate_name_embedding(self.embedder)\\\\n        if edge.fact_embedding is None:\\\\n            await edge.generate_embedding(self.embedder)\\\\n\\\\n        nodes, uuid_map, _ = await resolve_extracted_nodes(\\\\n            self.clients,\\\\n            [source_node, target_node],\\\\n        )\\\\n\\\\n        updated_edge = resolve_edge_pointers([edge], uuid_map)[0]\\\\n\\\\n        related_edges = (await get_relevant_edges(self.driver, [updated_edge], SearchFilters()))[0]\\\\n        existing_edges = (\\\\n            await get_edge_invalidation_candidates(self.driver, [updated_edge], SearchFilters())\\\\n        )[0]\\\\n\\\\n        resolved_edge, invalidated_edges, _ = await resolve_extracted_edge(\\\\n            self.llm_client,\\\\n            updated_edge,\\\\n            related_edges,\\\\n            existing_edges,\\\\n            EpisodicNode(\\\\n                name='',\\\\n                source=EpisodeType.text,\\\\n                source_description='',\\\\n                content='',\\\\n                valid_at=edge.valid_at or utc_now(),\\\\n                entity_edges=[],\\\\n                group_id=edge.group_id,\\\\n            ),\\\\n            None,\\\\n            self.ensure_ascii,\\\\n        )\\\\n\\\\n        edges: list[EntityEdge] = [resolved_edge] + invalidated_edges\\\\n\\\\n        await create_entity_edge_embeddings(self.embedder, edges)\\\\n        await create_entity_node_embeddings(self.embedder, nodes)\\\\n\\\\n        await add_nodes_and_edges_bulk(self.driver, [], [], nodes, edges, self.embedder)\\\\n        return AddTripletResults(edges=edges, nodes=nodes)\\\\n\\\\n    async def remove_episode(self, episode_uuid: str):\\\\n        # Find the episode to be deleted\\\\n        episode = await EpisodicNode.get_by_uuid(self.driver, episode_uuid)\\\\n\\\\n        # Find edges mentioned by the episode\\\\n        edges = await EntityEdge.get_by_uuids(self.driver, episode.entity_edges)\\\\n\\\\n        # We should only delete edges created by the episode\\\\n        edges_to_delete: list[EntityEdge] = []\\\\n        for edge in edges:\\\\n            if edge.episodes and edge.episodes[0] == episode.uuid:\\\\n                edges_to_delete.append(edge)\\\\n\\\\n        # Find nodes mentioned by the episode\\\\n        nodes = await get_mentioned_nodes(self.driver, [episode])\\\\n        # We should delete all nodes that are only mentioned in the deleted episode\\\\n        nodes_to_delete: list[EntityNode] = []\\\\n        for node in nodes:\\\\n            query: LiteralString = 'MATCH (e:Episodic)-[:MENTIONS]->(n:Entity {uuid: $uuid}) RETURN count(*) AS episode_count'\\\\n            records, _, _ = await self.driver.execute_query(query, uuid=node.uuid, routing_='r')\\\\n\\\\n            for record in records:\\\\n                if record['episode_count'] == 1:\\\\n                    nodes_to_delete.append(node)\\\\n\\\\n        await Edge.delete_by_uuids(self.driver, [edge.uuid for edge in edges_to_delete])\\\\n        await Node.delete_by_uuids(self.driver, [node.uuid for node in nodes_to_delete])\\\\n\\\\n        await episode.delete(self.driver)\\\\n\\\",\\\"graphiti/graphiti_core/graph_queries.py\\\":\\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nDatabase query utilities for different graph database backends.\\\\n\\\\nThis module provides database-agnostic query generation for Neo4j and FalkorDB,\\\\nsupporting index creation, fulltext search, and bulk operations.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom typing_extensions import LiteralString\\\\n\\\\nfrom graphiti_core.driver.driver import GraphProvider\\\\n\\\\n# Mapping from Neo4j fulltext index names to FalkorDB node labels\\\\nNEO4J_TO_FALKORDB_MAPPING = {\\\\n    'node_name_and_summary': 'Entity',\\\\n    'community_name': 'Community',\\\\n    'episode_content': 'Episodic',\\\\n    'edge_name_and_fact': 'RELATES_TO',\\\\n}\\\\n# Mapping from fulltext index names to Kuzu node labels\\\\nINDEX_TO_LABEL_KUZU_MAPPING = {\\\\n    'node_name_and_summary': 'Entity',\\\\n    'community_name': 'Community',\\\\n    'episode_content': 'Episodic',\\\\n    'edge_name_and_fact': 'RelatesToNode_',\\\\n}\\\\n\\\\n\\\\ndef get_range_indices(provider: GraphProvider) -> list[LiteralString]:\\\\n    if provider == GraphProvider.FALKORDB:\\\\n        return [\\\\n            # Entity node\\\\n            'CREATE INDEX FOR (n:Entity) ON (n.uuid, n.group_id, n.name, n.created_at)',\\\\n            # Episodic node\\\\n            'CREATE INDEX FOR (n:Episodic) ON (n.uuid, n.group_id, n.created_at, n.valid_at)',\\\\n            # Community node\\\\n            'CREATE INDEX FOR (n:Community) ON (n.uuid)',\\\\n            # RELATES_TO edge\\\\n            'CREATE INDEX FOR ()-[e:RELATES_TO]-() ON (e.uuid, e.group_id, e.name, e.created_at, e.expired_at, e.valid_at, e.invalid_at)',\\\\n            # MENTIONS edge\\\\n            'CREATE INDEX FOR ()-[e:MENTIONS]-() ON (e.uuid, e.group_id)',\\\\n            # HAS_MEMBER edge\\\\n            'CREATE INDEX FOR ()-[e:HAS_MEMBER]-() ON (e.uuid)',\\\\n        ]\\\\n\\\\n    if provider == GraphProvider.KUZU:\\\\n        return []\\\\n\\\\n    return [\\\\n        'CREATE INDEX entity_uuid IF NOT EXISTS FOR (n:Entity) ON (n.uuid)',\\\\n        'CREATE INDEX episode_uuid IF NOT EXISTS FOR (n:Episodic) ON (n.uuid)',\\\\n        'CREATE INDEX community_uuid IF NOT EXISTS FOR (n:Community) ON (n.uuid)',\\\\n        'CREATE INDEX relation_uuid IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.uuid)',\\\\n        'CREATE INDEX mention_uuid IF NOT EXISTS FOR ()-[e:MENTIONS]-() ON (e.uuid)',\\\\n        'CREATE INDEX has_member_uuid IF NOT EXISTS FOR ()-[e:HAS_MEMBER]-() ON (e.uuid)',\\\\n        'CREATE INDEX entity_group_id IF NOT EXISTS FOR (n:Entity) ON (n.group_id)',\\\\n        'CREATE INDEX episode_group_id IF NOT EXISTS FOR (n:Episodic) ON (n.group_id)',\\\\n        'CREATE INDEX community_group_id IF NOT EXISTS FOR (n:Community) ON (n.group_id)',\\\\n        'CREATE INDEX relation_group_id IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.group_id)',\\\\n        'CREATE INDEX mention_group_id IF NOT EXISTS FOR ()-[e:MENTIONS]-() ON (e.group_id)',\\\\n        'CREATE INDEX name_entity_index IF NOT EXISTS FOR (n:Entity) ON (n.name)',\\\\n        'CREATE INDEX created_at_entity_index IF NOT EXISTS FOR (n:Entity) ON (n.created_at)',\\\\n        'CREATE INDEX created_at_episodic_index IF NOT EXISTS FOR (n:Episodic) ON (n.created_at)',\\\\n        'CREATE INDEX valid_at_episodic_index IF NOT EXISTS FOR (n:Episodic) ON (n.valid_at)',\\\\n        'CREATE INDEX name_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.name)',\\\\n        'CREATE INDEX created_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.created_at)',\\\\n        'CREATE INDEX expired_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.expired_at)',\\\\n        'CREATE INDEX valid_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.valid_at)',\\\\n        'CREATE INDEX invalid_at_edge_index IF NOT EXISTS FOR ()-[e:RELATES_TO]-() ON (e.invalid_at)',\\\\n    ]\\\\n\\\\n\\\\ndef get_fulltext_indices(provider: GraphProvider) -> list[LiteralString]:\\\\n    if provider == GraphProvider.FALKORDB:\\\\n        return [\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"CREATE FULLTEXT INDEX FOR (e:Episodic) ON (e.content, e.source, e.source_description, e.group_id)\\\\\\\"\\\\\\\"\\\\\\\",\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"CREATE FULLTEXT INDEX FOR (n:Entity) ON (n.name, n.summary, n.group_id)\\\\\\\"\\\\\\\"\\\\\\\",\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"CREATE FULLTEXT INDEX FOR (n:Community) ON (n.name, n.group_id)\\\\\\\"\\\\\\\"\\\\\\\",\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"CREATE FULLTEXT INDEX FOR ()-[e:RELATES_TO]-() ON (e.name, e.fact, e.group_id)\\\\\\\"\\\\\\\"\\\\\\\",\\\\n        ]\\\\n\\\\n    if provider == GraphProvider.KUZU:\\\\n        return [\\\\n            \\\\\\\"CALL CREATE_FTS_INDEX('Episodic', 'episode_content', ['content', 'source', 'source_description']);\\\\\\\",\\\\n            \\\\\\\"CALL CREATE_FTS_INDEX('Entity', 'node_name_and_summary', ['name', 'summary']);\\\\\\\",\\\\n            \\\\\\\"CALL CREATE_FTS_INDEX('Community', 'community_name', ['name']);\\\\\\\",\\\\n            \\\\\\\"CALL CREATE_FTS_INDEX('RelatesToNode_', 'edge_name_and_fact', ['name', 'fact']);\\\\\\\",\\\\n        ]\\\\n\\\\n    return [\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"CREATE FULLTEXT INDEX episode_content IF NOT EXISTS\\\\n        FOR (e:Episodic) ON EACH [e.content, e.source, e.source_description, e.group_id]\\\\\\\"\\\\\\\"\\\\\\\",\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"CREATE FULLTEXT INDEX node_name_and_summary IF NOT EXISTS\\\\n        FOR (n:Entity) ON EACH [n.name, n.summary, n.group_id]\\\\\\\"\\\\\\\"\\\\\\\",\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"CREATE FULLTEXT INDEX community_name IF NOT EXISTS\\\\n        FOR (n:Community) ON EACH [n.name, n.group_id]\\\\\\\"\\\\\\\"\\\\\\\",\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"CREATE FULLTEXT INDEX edge_name_and_fact IF NOT EXISTS\\\\n        FOR ()-[e:RELATES_TO]-() ON EACH [e.name, e.fact, e.group_id]\\\\\\\"\\\\\\\"\\\\\\\",\\\\n    ]\\\\n\\\\n\\\\ndef get_nodes_query(name: str, query: str, limit: int, provider: GraphProvider) -> str:\\\\n    if provider == GraphProvider.FALKORDB:\\\\n        label = NEO4J_TO_FALKORDB_MAPPING[name]\\\\n        return f\\\\\\\"CALL db.idx.fulltext.queryNodes('{label}', {query})\\\\\\\"\\\\n\\\\n    if provider == GraphProvider.KUZU:\\\\n        label = INDEX_TO_LABEL_KUZU_MAPPING[name]\\\\n        return f\\\\\\\"CALL QUERY_FTS_INDEX('{label}', '{name}', {query}, TOP := $limit)\\\\\\\"\\\\n\\\\n    return f'CALL db.index.fulltext.queryNodes(\\\\\\\"{name}\\\\\\\", {query}, {{limit: $limit}})'\\\\n\\\\n\\\\ndef get_vector_cosine_func_query(vec1, vec2, provider: GraphProvider) -> str:\\\\n    if provider == GraphProvider.FALKORDB:\\\\n        # FalkorDB uses a different syntax for regular cosine similarity and Neo4j uses normalized cosine similarity\\\\n        return f'(2 - vec.cosineDistance({vec1}, vecf32({vec2})))/2'\\\\n\\\\n    if provider == GraphProvider.KUZU:\\\\n        return f'array_cosine_similarity({vec1}, {vec2})'\\\\n\\\\n    return f'vector.similarity.cosine({vec1}, {vec2})'\\\\n\\\\n\\\\ndef get_relationships_query(name: str, limit: int, provider: GraphProvider) -> str:\\\\n    if provider == GraphProvider.FALKORDB:\\\\n        label = NEO4J_TO_FALKORDB_MAPPING[name]\\\\n        return f\\\\\\\"CALL db.idx.fulltext.queryRelationships('{label}', $query)\\\\\\\"\\\\n\\\\n    if provider == GraphProvider.KUZU:\\\\n        label = INDEX_TO_LABEL_KUZU_MAPPING[name]\\\\n        return f\\\\\\\"CALL QUERY_FTS_INDEX('{label}', '{name}', cast($query AS STRING), TOP := $limit)\\\\\\\"\\\\n\\\\n    return f'CALL db.index.fulltext.queryRelationships(\\\\\\\"{name}\\\\\\\", $query, {{limit: $limit}})'\\\\n\\\",\\\"graphiti/graphiti_core/models/nodes/node_db_queries.py\\\":\\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nCopyright 2024, Zep Software, Inc.\\\\n\\\\nLicensed under the Apache License, Version 2.0 (the \\\\\\\"License\\\\\\\");\\\\nyou may not use this file except in compliance with the License.\\\\nYou may obtain a copy of the License at\\\\n\\\\n    http://www.apache.org/licenses/LICENSE-2.0\\\\n\\\\nUnless required by applicable law or agreed to in writing, software\\\\ndistributed under the License is distributed on an \\\\\\\"AS IS\\\\\\\" BASIS,\\\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\nSee the License for the specific language governing permissions and\\\\nlimitations under the License.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom typing import Any\\\\n\\\\nfrom graphiti_core.driver.driver import GraphProvider\\\\n\\\\n\\\\ndef get_episode_node_save_query(provider: GraphProvider) -> str:\\\\n    match provider:\\\\n        case GraphProvider.NEPTUNE:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Episodic {uuid: $uuid})\\\\n                SET n = {uuid: $uuid, name: $name, group_id: $group_id, source_description: $source_description, source: $source, content: $content,\\\\n                entity_edges: join([x IN coalesce($entity_edges, []) | toString(x) ], '|'), created_at: $created_at, valid_at: $valid_at}\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.KUZU:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Episodic {uuid: $uuid})\\\\n                SET\\\\n                    n.name = $name,\\\\n                    n.group_id = $group_id,\\\\n                    n.created_at = $created_at,\\\\n                    n.source = $source,\\\\n                    n.source_description = $source_description,\\\\n                    n.content = $content,\\\\n                    n.valid_at = $valid_at,\\\\n                    n.entity_edges = $entity_edges\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.FALKORDB:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Episodic {uuid: $uuid})\\\\n                SET n = {uuid: $uuid, name: $name, group_id: $group_id, source_description: $source_description, source: $source, content: $content,\\\\n                entity_edges: $entity_edges, created_at: $created_at, valid_at: $valid_at}\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case _:  # Neo4j\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Episodic {uuid: $uuid})\\\\n                SET n = {uuid: $uuid, name: $name, group_id: $group_id, source_description: $source_description, source: $source, content: $content,\\\\n                entity_edges: $entity_edges, created_at: $created_at, valid_at: $valid_at}\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\ndef get_episode_node_save_bulk_query(provider: GraphProvider) -> str:\\\\n    match provider:\\\\n        case GraphProvider.NEPTUNE:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $episodes AS episode\\\\n                MERGE (n:Episodic {uuid: episode.uuid})\\\\n                SET n = {uuid: episode.uuid, name: episode.name, group_id: episode.group_id, source_description: episode.source_description,\\\\n                    source: episode.source, content: episode.content,\\\\n                entity_edges: join([x IN coalesce(episode.entity_edges, []) | toString(x) ], '|'), created_at: episode.created_at, valid_at: episode.valid_at}\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.KUZU:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Episodic {uuid: $uuid})\\\\n                SET\\\\n                    n.name = $name,\\\\n                    n.group_id = $group_id,\\\\n                    n.created_at = $created_at,\\\\n                    n.source = $source,\\\\n                    n.source_description = $source_description,\\\\n                    n.content = $content,\\\\n                    n.valid_at = $valid_at,\\\\n                    n.entity_edges = $entity_edges\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.FALKORDB:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $episodes AS episode\\\\n                MERGE (n:Episodic {uuid: episode.uuid})\\\\n                SET n = {uuid: episode.uuid, name: episode.name, group_id: episode.group_id, source_description: episode.source_description, source: episode.source, content: episode.content, \\\\n                entity_edges: episode.entity_edges, created_at: episode.created_at, valid_at: episode.valid_at}\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case _:  # Neo4j\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $episodes AS episode\\\\n                MERGE (n:Episodic {uuid: episode.uuid})\\\\n                SET n = {uuid: episode.uuid, name: episode.name, group_id: episode.group_id, source_description: episode.source_description, source: episode.source, content: episode.content, \\\\n                entity_edges: episode.entity_edges, created_at: episode.created_at, valid_at: episode.valid_at}\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\nEPISODIC_NODE_RETURN = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    e.uuid AS uuid,\\\\n    e.name AS name,\\\\n    e.group_id AS group_id,\\\\n    e.created_at AS created_at,\\\\n    e.source AS source,\\\\n    e.source_description AS source_description,\\\\n    e.content AS content,\\\\n    e.valid_at AS valid_at,\\\\n    e.entity_edges AS entity_edges\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nEPISODIC_NODE_RETURN_NEPTUNE = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    e.content AS content,\\\\n    e.created_at AS created_at,\\\\n    e.valid_at AS valid_at,\\\\n    e.uuid AS uuid,\\\\n    e.name AS name,\\\\n    e.group_id AS group_id,\\\\n    e.source_description AS source_description,\\\\n    e.source AS source,\\\\n    split(e.entity_edges, \\\\\\\",\\\\\\\") AS entity_edges\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\ndef get_entity_node_save_query(provider: GraphProvider, labels: str, has_aoss: bool = False) -> str:\\\\n    match provider:\\\\n        case GraphProvider.FALKORDB:\\\\n            return f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Entity {{uuid: $entity_data.uuid}})\\\\n                SET n:{labels}\\\\n                SET n = $entity_data\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.KUZU:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Entity {uuid: $uuid})\\\\n                SET\\\\n                    n.name = $name,\\\\n                    n.group_id = $group_id,\\\\n                    n.labels = $labels,\\\\n                    n.created_at = $created_at,\\\\n                    n.name_embedding = $name_embedding,\\\\n                    n.summary = $summary,\\\\n                    n.attributes = $attributes\\\\n                WITH n\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.NEPTUNE:\\\\n            label_subquery = ''\\\\n            for label in labels.split(':'):\\\\n                label_subquery += f' SET n:{label}\\\\\\\\n'\\\\n            return f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Entity {{uuid: $entity_data.uuid}})\\\\n                {label_subquery}\\\\n                SET n = removeKeyFromMap(removeKeyFromMap($entity_data, \\\\\\\"labels\\\\\\\"), \\\\\\\"name_embedding\\\\\\\")\\\\n                SET n.name_embedding = join([x IN coalesce($entity_data.name_embedding, []) | toString(x) ], \\\\\\\",\\\\\\\")\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case _:\\\\n            save_embedding_query = (\\\\n                'WITH n CALL db.create.setNodeVectorProperty(n, \\\\\\\"name_embedding\\\\\\\", $entity_data.name_embedding)'\\\\n                if not has_aoss\\\\n                else ''\\\\n            )\\\\n            return (\\\\n                f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Entity {{uuid: $entity_data.uuid}})\\\\n                SET n:{labels}\\\\n                SET n = $entity_data\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + save_embedding_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n\\\\n\\\\ndef get_entity_node_save_bulk_query(\\\\n    provider: GraphProvider, nodes: list[dict], has_aoss: bool = False\\\\n) -> str | Any:\\\\n    match provider:\\\\n        case GraphProvider.FALKORDB:\\\\n            queries = []\\\\n            for node in nodes:\\\\n                for label in node['labels']:\\\\n                    queries.append(\\\\n                        (\\\\n                            f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                            UNWIND $nodes AS node\\\\n                            MERGE (n:Entity {{uuid: node.uuid}})\\\\n                            SET n:{label}\\\\n                            SET n = node\\\\n                            WITH n, node\\\\n                            SET n.name_embedding = vecf32(node.name_embedding)\\\\n                            RETURN n.uuid AS uuid\\\\n                            \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                            {'nodes': [node]},\\\\n                        )\\\\n                    )\\\\n            return queries\\\\n        case GraphProvider.NEPTUNE:\\\\n            queries = []\\\\n            for node in nodes:\\\\n                labels = ''\\\\n                for label in node['labels']:\\\\n                    labels += f' SET n:{label}\\\\\\\\n'\\\\n                queries.append(\\\\n                    f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        UNWIND $nodes AS node\\\\n                        MERGE (n:Entity {{uuid: node.uuid}})\\\\n                        {labels}\\\\n                        SET n = removeKeyFromMap(removeKeyFromMap(node, \\\\\\\"labels\\\\\\\"), \\\\\\\"name_embedding\\\\\\\")\\\\n                        SET n.name_embedding = join([x IN coalesce(node.name_embedding, []) | toString(x) ], \\\\\\\",\\\\\\\")\\\\n                        RETURN n.uuid AS uuid\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                )\\\\n            return queries\\\\n        case GraphProvider.KUZU:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Entity {uuid: $uuid})\\\\n                SET\\\\n                    n.name = $name,\\\\n                    n.group_id = $group_id,\\\\n                    n.labels = $labels,\\\\n                    n.created_at = $created_at,\\\\n                    n.name_embedding = $name_embedding,\\\\n                    n.summary = $summary,\\\\n                    n.attributes = $attributes\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case _:  # Neo4j\\\\n            save_embedding_query = (\\\\n                'WITH n, node CALL db.create.setNodeVectorProperty(n, \\\\\\\"name_embedding\\\\\\\", node.name_embedding)'\\\\n                if not has_aoss\\\\n                else ''\\\\n            )\\\\n            return (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    UNWIND $nodes AS node\\\\n                    MERGE (n:Entity {uuid: node.uuid})\\\\n                    SET n:$(node.labels)\\\\n                    SET n = node\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + save_embedding_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n\\\\n\\\\ndef get_entity_node_return_query(provider: GraphProvider) -> str:\\\\n    # `name_embedding` is not returned by default and must be loaded manually using `load_name_embedding()`.\\\\n    if provider == GraphProvider.KUZU:\\\\n        return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            n.uuid AS uuid,\\\\n            n.name AS name,\\\\n            n.group_id AS group_id,\\\\n            n.labels AS labels,\\\\n            n.created_at AS created_at,\\\\n            n.summary AS summary,\\\\n            n.attributes AS attributes\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        n.uuid AS uuid,\\\\n        n.name AS name,\\\\n        n.group_id AS group_id,\\\\n        n.created_at AS created_at,\\\\n        n.summary AS summary,\\\\n        labels(n) AS labels,\\\\n        properties(n) AS attributes\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\ndef get_community_node_save_query(provider: GraphProvider) -> str:\\\\n    match provider:\\\\n        case GraphProvider.FALKORDB:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Community {uuid: $uuid})\\\\n                SET n = {uuid: $uuid, name: $name, group_id: $group_id, summary: $summary, created_at: $created_at, name_embedding: vecf32($name_embedding)}\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.NEPTUNE:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Community {uuid: $uuid})\\\\n                SET n = {uuid: $uuid, name: $name, group_id: $group_id, summary: $summary, created_at: $created_at}\\\\n                SET n.name_embedding = join([x IN coalesce($name_embedding, []) | toString(x) ], \\\\\\\",\\\\\\\")\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.KUZU:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Community {uuid: $uuid})\\\\n                SET\\\\n                    n.name = $name,\\\\n                    n.group_id = $group_id,\\\\n                    n.created_at = $created_at,\\\\n                    n.name_embedding = $name_embedding,\\\\n                    n.summary = $summary\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case _:  # Neo4j\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MERGE (n:Community {uuid: $uuid})\\\\n                SET n = {uuid: $uuid, name: $name, group_id: $group_id, summary: $summary, created_at: $created_at}\\\\n                WITH n CALL db.create.setNodeVectorProperty(n, \\\\\\\"name_embedding\\\\\\\", $name_embedding)\\\\n                RETURN n.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\nCOMMUNITY_NODE_RETURN = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    c.uuid AS uuid,\\\\n    c.name AS name,\\\\n    c.group_id AS group_id,\\\\n    c.created_at AS created_at,\\\\n    c.name_embedding AS name_embedding,\\\\n    c.summary AS summary\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nCOMMUNITY_NODE_RETURN_NEPTUNE = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    n.uuid AS uuid,\\\\n    n.name AS name,\\\\n    [x IN split(n.name_embedding, \\\\\\\",\\\\\\\") | toFloat(x)] AS name_embedding,\\\\n    n.group_id AS group_id,\\\\n    n.summary AS summary,\\\\n    n.created_at AS created_at\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\\"graphiti/graphiti_core/models/edges/edge_db_queries.py\\\":\\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nCopyright 2024, Zep Software, Inc.\\\\n\\\\nLicensed under the Apache License, Version 2.0 (the \\\\\\\"License\\\\\\\");\\\\nyou may not use this file except in compliance with the License.\\\\nYou may obtain a copy of the License at\\\\n\\\\n    http://www.apache.org/licenses/LICENSE-2.0\\\\n\\\\nUnless required by applicable law or agreed to in writing, software\\\\ndistributed under the License is distributed on an \\\\\\\"AS IS\\\\\\\" BASIS,\\\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\nSee the License for the specific language governing permissions and\\\\nlimitations under the License.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nfrom graphiti_core.driver.driver import GraphProvider\\\\n\\\\nEPISODIC_EDGE_SAVE = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    MATCH (episode:Episodic {uuid: $episode_uuid})\\\\n    MATCH (node:Entity {uuid: $entity_uuid})\\\\n    MERGE (episode)-[e:MENTIONS {uuid: $uuid}]->(node)\\\\n    SET\\\\n        e.group_id = $group_id,\\\\n        e.created_at = $created_at\\\\n    RETURN e.uuid AS uuid\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\ndef get_episodic_edge_save_bulk_query(provider: GraphProvider) -> str:\\\\n    if provider == GraphProvider.KUZU:\\\\n        return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            MATCH (episode:Episodic {uuid: $source_node_uuid})\\\\n            MATCH (node:Entity {uuid: $target_node_uuid})\\\\n            MERGE (episode)-[e:MENTIONS {uuid: $uuid}]->(node)\\\\n            SET\\\\n                e.group_id = $group_id,\\\\n                e.created_at = $created_at\\\\n            RETURN e.uuid AS uuid\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        UNWIND $episodic_edges AS edge\\\\n        MATCH (episode:Episodic {uuid: edge.source_node_uuid})\\\\n        MATCH (node:Entity {uuid: edge.target_node_uuid})\\\\n        MERGE (episode)-[e:MENTIONS {uuid: edge.uuid}]->(node)\\\\n        SET\\\\n            e.group_id = edge.group_id,\\\\n            e.created_at = edge.created_at\\\\n        RETURN e.uuid AS uuid\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\nEPISODIC_EDGE_RETURN = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    e.uuid AS uuid,\\\\n    e.group_id AS group_id,\\\\n    n.uuid AS source_node_uuid,\\\\n    m.uuid AS target_node_uuid,\\\\n    e.created_at AS created_at\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\ndef get_entity_edge_save_query(provider: GraphProvider, has_aoss: bool = False) -> str:\\\\n    match provider:\\\\n        case GraphProvider.FALKORDB:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MATCH (source:Entity {uuid: $edge_data.source_uuid})\\\\n                MATCH (target:Entity {uuid: $edge_data.target_uuid})\\\\n                MERGE (source)-[e:RELATES_TO {uuid: $edge_data.uuid}]->(target)\\\\n                SET e = $edge_data\\\\n                RETURN e.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.NEPTUNE:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MATCH (source:Entity {uuid: $edge_data.source_uuid})\\\\n                MATCH (target:Entity {uuid: $edge_data.target_uuid})\\\\n                MERGE (source)-[e:RELATES_TO {uuid: $edge_data.uuid}]->(target)\\\\n                SET e = removeKeyFromMap(removeKeyFromMap($edge_data, \\\\\\\"fact_embedding\\\\\\\"), \\\\\\\"episodes\\\\\\\")\\\\n                SET e.fact_embedding = join([x IN coalesce($edge_data.fact_embedding, []) | toString(x) ], \\\\\\\",\\\\\\\")\\\\n                SET e.episodes = join($edge_data.episodes, \\\\\\\",\\\\\\\")\\\\n                RETURN $edge_data.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.KUZU:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MATCH (source:Entity {uuid: $source_uuid})\\\\n                MATCH (target:Entity {uuid: $target_uuid})\\\\n                MERGE (source)-[:RELATES_TO]->(e:RelatesToNode_ {uuid: $uuid})-[:RELATES_TO]->(target)\\\\n                SET\\\\n                    e.group_id = $group_id,\\\\n                    e.created_at = $created_at,\\\\n                    e.name = $name,\\\\n                    e.fact = $fact,\\\\n                    e.fact_embedding = $fact_embedding,\\\\n                    e.episodes = $episodes,\\\\n                    e.expired_at = $expired_at,\\\\n                    e.valid_at = $valid_at,\\\\n                    e.invalid_at = $invalid_at,\\\\n                    e.attributes = $attributes\\\\n                RETURN e.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case _:  # Neo4j\\\\n            save_embedding_query = (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"WITH e CALL db.create.setRelationshipVectorProperty(e, \\\\\\\"fact_embedding\\\\\\\", $edge_data.fact_embedding)\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                if not has_aoss\\\\n                else ''\\\\n            )\\\\n            return (\\\\n                (\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                        MATCH (source:Entity {uuid: $edge_data.source_uuid})\\\\n                        MATCH (target:Entity {uuid: $edge_data.target_uuid})\\\\n                        MERGE (source)-[e:RELATES_TO {uuid: $edge_data.uuid}]->(target)\\\\n                        SET e = $edge_data\\\\n                        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    + save_embedding_query\\\\n                )\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                RETURN e.uuid AS uuid\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n\\\\n\\\\ndef get_entity_edge_save_bulk_query(provider: GraphProvider, has_aoss: bool = False) -> str:\\\\n    match provider:\\\\n        case GraphProvider.FALKORDB:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $entity_edges AS edge\\\\n                MATCH (source:Entity {uuid: edge.source_node_uuid})\\\\n                MATCH (target:Entity {uuid: edge.target_node_uuid})\\\\n                MERGE (source)-[r:RELATES_TO {uuid: edge.uuid}]->(target)\\\\n                SET r = {uuid: edge.uuid, name: edge.name, group_id: edge.group_id, fact: edge.fact, episodes: edge.episodes,\\\\n                created_at: edge.created_at, expired_at: edge.expired_at, valid_at: edge.valid_at, invalid_at: edge.invalid_at, fact_embedding: vecf32(edge.fact_embedding)}\\\\n                WITH r, edge\\\\n                RETURN edge.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.NEPTUNE:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $entity_edges AS edge\\\\n                MATCH (source:Entity {uuid: edge.source_node_uuid})\\\\n                MATCH (target:Entity {uuid: edge.target_node_uuid})\\\\n                MERGE (source)-[r:RELATES_TO {uuid: edge.uuid}]->(target)\\\\n                SET r = removeKeyFromMap(removeKeyFromMap(edge, \\\\\\\"fact_embedding\\\\\\\"), \\\\\\\"episodes\\\\\\\")\\\\n                SET r.fact_embedding = join([x IN coalesce(edge.fact_embedding, []) | toString(x) ], \\\\\\\",\\\\\\\")\\\\n                SET r.episodes = join(edge.episodes, \\\\\\\",\\\\\\\")\\\\n                RETURN edge.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.KUZU:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MATCH (source:Entity {uuid: $source_node_uuid})\\\\n                MATCH (target:Entity {uuid: $target_node_uuid})\\\\n                MERGE (source)-[:RELATES_TO]->(e:RelatesToNode_ {uuid: $uuid})-[:RELATES_TO]->(target)\\\\n                SET\\\\n                    e.group_id = $group_id,\\\\n                    e.created_at = $created_at,\\\\n                    e.name = $name,\\\\n                    e.fact = $fact,\\\\n                    e.fact_embedding = $fact_embedding,\\\\n                    e.episodes = $episodes,\\\\n                    e.expired_at = $expired_at,\\\\n                    e.valid_at = $valid_at,\\\\n                    e.invalid_at = $invalid_at,\\\\n                    e.attributes = $attributes\\\\n                RETURN e.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case _:\\\\n            save_embedding_query = (\\\\n                'WITH e, edge CALL db.create.setRelationshipVectorProperty(e, \\\\\\\"fact_embedding\\\\\\\", edge.fact_embedding)'\\\\n                if not has_aoss\\\\n                else ''\\\\n            )\\\\n            return (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    UNWIND $entity_edges AS edge\\\\n                    MATCH (source:Entity {uuid: edge.source_node_uuid})\\\\n                    MATCH (target:Entity {uuid: edge.target_node_uuid})\\\\n                    MERGE (source)-[e:RELATES_TO {uuid: edge.uuid}]->(target)\\\\n                    SET e = edge\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + save_embedding_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                RETURN edge.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n\\\\n\\\\ndef get_entity_edge_return_query(provider: GraphProvider) -> str:\\\\n    # `fact_embedding` is not returned by default and must be manually loaded using `load_fact_embedding()`.\\\\n\\\\n    if provider == GraphProvider.NEPTUNE:\\\\n        return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        e.uuid AS uuid,\\\\n        n.uuid AS source_node_uuid,\\\\n        m.uuid AS target_node_uuid,\\\\n        e.group_id AS group_id,\\\\n        e.name AS name,\\\\n        e.fact AS fact,\\\\n        split(e.episodes, ',') AS episodes,\\\\n        e.created_at AS created_at,\\\\n        e.expired_at AS expired_at,\\\\n        e.valid_at AS valid_at,\\\\n        e.invalid_at AS invalid_at,\\\\n        properties(e) AS attributes\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        e.uuid AS uuid,\\\\n        n.uuid AS source_node_uuid,\\\\n        m.uuid AS target_node_uuid,\\\\n        e.group_id AS group_id,\\\\n        e.created_at AS created_at,\\\\n        e.name AS name,\\\\n        e.fact AS fact,\\\\n        e.episodes AS episodes,\\\\n        e.expired_at AS expired_at,\\\\n        e.valid_at AS valid_at,\\\\n        e.invalid_at AS invalid_at,\\\\n    \\\\\\\"\\\\\\\"\\\\\\\" + (\\\\n        'e.attributes AS attributes'\\\\n        if provider == GraphProvider.KUZU\\\\n        else 'properties(e) AS attributes'\\\\n    )\\\\n\\\\n\\\\ndef get_community_edge_save_query(provider: GraphProvider) -> str:\\\\n    match provider:\\\\n        case GraphProvider.FALKORDB:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MATCH (community:Community {uuid: $community_uuid})\\\\n                MATCH (node {uuid: $entity_uuid})\\\\n                MERGE (community)-[e:HAS_MEMBER {uuid: $uuid}]->(node)\\\\n                SET e = {uuid: $uuid, group_id: $group_id, created_at: $created_at}\\\\n                RETURN e.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.NEPTUNE:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MATCH (community:Community {uuid: $community_uuid})\\\\n                MATCH (node {uuid: $entity_uuid})\\\\n                WHERE node:Entity OR node:Community\\\\n                MERGE (community)-[r:HAS_MEMBER {uuid: $uuid}]->(node)\\\\n                SET r.uuid= $uuid\\\\n                SET r.group_id= $group_id\\\\n                SET r.created_at= $created_at\\\\n                RETURN r.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case GraphProvider.KUZU:\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MATCH (community:Community {uuid: $community_uuid})\\\\n                MATCH (node:Entity {uuid: $entity_uuid})\\\\n                MERGE (community)-[e:HAS_MEMBER {uuid: $uuid}]->(node)\\\\n                SET\\\\n                    e.group_id = $group_id,\\\\n                    e.created_at = $created_at\\\\n                RETURN e.uuid AS uuid\\\\n                UNION\\\\n                MATCH (community:Community {uuid: $community_uuid})\\\\n                MATCH (node:Community {uuid: $entity_uuid})\\\\n                MERGE (community)-[e:HAS_MEMBER {uuid: $uuid}]->(node)\\\\n                SET\\\\n                    e.group_id = $group_id,\\\\n                    e.created_at = $created_at\\\\n                RETURN e.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        case _:  # Neo4j\\\\n            return \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MATCH (community:Community {uuid: $community_uuid})\\\\n                MATCH (node:Entity | Community {uuid: $entity_uuid})\\\\n                MERGE (community)-[e:HAS_MEMBER {uuid: $uuid}]->(node)\\\\n                SET e = {uuid: $uuid, group_id: $group_id, created_at: $created_at}\\\\n                RETURN e.uuid AS uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n\\\\nCOMMUNITY_EDGE_RETURN = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    e.uuid AS uuid,\\\\n    e.group_id AS group_id,\\\\n    n.uuid AS source_node_uuid,\\\\n    m.uuid AS target_node_uuid,\\\\n    e.created_at AS created_at\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\\"graphiti/graphiti_core/search/search_utils.py\\\":\\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nCopyright 2024, Zep Software, Inc.\\\\n\\\\nLicensed under the Apache License, Version 2.0 (the \\\\\\\"License\\\\\\\");\\\\nyou may not use this file except in compliance with the License.\\\\nYou may obtain a copy of the License at\\\\n\\\\n    http://www.apache.org/licenses/LICENSE-2.0\\\\n\\\\nUnless required by applicable law or agreed to in writing, software\\\\ndistributed under the License is distributed on an \\\\\\\"AS IS\\\\\\\" BASIS,\\\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\nSee the License for the specific language governing permissions and\\\\nlimitations under the License.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport logging\\\\nfrom collections import defaultdict\\\\nfrom time import time\\\\nfrom typing import Any\\\\n\\\\nimport numpy as np\\\\nfrom numpy._typing import NDArray\\\\nfrom typing_extensions import LiteralString\\\\n\\\\nfrom graphiti_core.driver.driver import GraphDriver, GraphProvider\\\\nfrom graphiti_core.edges import EntityEdge, get_entity_edge_from_record\\\\nfrom graphiti_core.graph_queries import (\\\\n    get_nodes_query,\\\\n    get_relationships_query,\\\\n    get_vector_cosine_func_query,\\\\n)\\\\nfrom graphiti_core.helpers import (\\\\n    lucene_sanitize,\\\\n    normalize_l2,\\\\n    semaphore_gather,\\\\n)\\\\nfrom graphiti_core.models.edges.edge_db_queries import get_entity_edge_return_query\\\\nfrom graphiti_core.models.nodes.node_db_queries import (\\\\n    COMMUNITY_NODE_RETURN,\\\\n    EPISODIC_NODE_RETURN,\\\\n    get_entity_node_return_query,\\\\n)\\\\nfrom graphiti_core.nodes import (\\\\n    CommunityNode,\\\\n    EntityNode,\\\\n    EpisodicNode,\\\\n    get_community_node_from_record,\\\\n    get_entity_node_from_record,\\\\n    get_episodic_node_from_record,\\\\n)\\\\nfrom graphiti_core.search.search_filters import (\\\\n    SearchFilters,\\\\n    build_aoss_edge_filters,\\\\n    build_aoss_node_filters,\\\\n    edge_search_filter_query_constructor,\\\\n    node_search_filter_query_constructor,\\\\n)\\\\n\\\\nlogger = logging.getLogger(__name__)\\\\n\\\\nRELEVANT_SCHEMA_LIMIT = 10\\\\nDEFAULT_MIN_SCORE = 0.6\\\\nDEFAULT_MMR_LAMBDA = 0.5\\\\nMAX_SEARCH_DEPTH = 3\\\\nMAX_QUERY_LENGTH = 128\\\\n\\\\n\\\\ndef calculate_cosine_similarity(vector1: list[float], vector2: list[float]) -> float:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Calculates the cosine similarity between two vectors using NumPy.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    dot_product = np.dot(vector1, vector2)\\\\n    norm_vector1 = np.linalg.norm(vector1)\\\\n    norm_vector2 = np.linalg.norm(vector2)\\\\n\\\\n    if norm_vector1 == 0 or norm_vector2 == 0:\\\\n        return 0  # Handle cases where one or both vectors are zero vectors\\\\n\\\\n    return dot_product / (norm_vector1 * norm_vector2)\\\\n\\\\n\\\\ndef fulltext_query(query: str, group_ids: list[str] | None, driver: GraphDriver):\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        # Kuzu only supports simple queries.\\\\n        if len(query.split(' ')) > MAX_QUERY_LENGTH:\\\\n            return ''\\\\n        return query\\\\n    group_ids_filter_list = (\\\\n        [driver.fulltext_syntax + f'group_id:\\\\\\\"{g}\\\\\\\"' for g in group_ids]\\\\n        if group_ids is not None\\\\n        else []\\\\n    )\\\\n    group_ids_filter = ''\\\\n    for f in group_ids_filter_list:\\\\n        group_ids_filter += f if not group_ids_filter else f' OR {f}'\\\\n\\\\n    group_ids_filter += ' AND ' if group_ids_filter else ''\\\\n\\\\n    lucene_query = lucene_sanitize(query)\\\\n    # If the lucene query is too long return no query\\\\n    if len(lucene_query.split(' ')) + len(group_ids or '') >= MAX_QUERY_LENGTH:\\\\n        return ''\\\\n\\\\n    full_query = group_ids_filter + '(' + lucene_query + ')'\\\\n\\\\n    return full_query\\\\n\\\\n\\\\nasync def get_episodes_by_mentions(\\\\n    driver: GraphDriver,\\\\n    nodes: list[EntityNode],\\\\n    edges: list[EntityEdge],\\\\n    limit: int = RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[EpisodicNode]:\\\\n    episode_uuids: list[str] = []\\\\n    for edge in edges:\\\\n        episode_uuids.extend(edge.episodes)\\\\n\\\\n    episodes = await EpisodicNode.get_by_uuids(driver, episode_uuids[:limit])\\\\n\\\\n    return episodes\\\\n\\\\n\\\\nasync def get_mentioned_nodes(\\\\n    driver: GraphDriver, episodes: list[EpisodicNode]\\\\n) -> list[EntityNode]:\\\\n    episode_uuids = [episode.uuid for episode in episodes]\\\\n\\\\n    records, _, _ = await driver.execute_query(\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        MATCH (episode:Episodic)-[:MENTIONS]->(n:Entity)\\\\n        WHERE episode.uuid IN $uuids\\\\n        RETURN DISTINCT\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        + get_entity_node_return_query(driver.provider),\\\\n        uuids=episode_uuids,\\\\n        routing_='r',\\\\n    )\\\\n\\\\n    nodes = [get_entity_node_from_record(record, driver.provider) for record in records]\\\\n\\\\n    return nodes\\\\n\\\\n\\\\nasync def get_communities_by_nodes(\\\\n    driver: GraphDriver, nodes: list[EntityNode]\\\\n) -> list[CommunityNode]:\\\\n    node_uuids = [node.uuid for node in nodes]\\\\n\\\\n    records, _, _ = await driver.execute_query(\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        MATCH (c:Community)-[:HAS_MEMBER]->(m:Entity)\\\\n        WHERE m.uuid IN $uuids\\\\n        RETURN DISTINCT\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        + COMMUNITY_NODE_RETURN,\\\\n        uuids=node_uuids,\\\\n        routing_='r',\\\\n    )\\\\n\\\\n    communities = [get_community_node_from_record(record) for record in records]\\\\n\\\\n    return communities\\\\n\\\\n\\\\nasync def edge_fulltext_search(\\\\n    driver: GraphDriver,\\\\n    query: str,\\\\n    search_filter: SearchFilters,\\\\n    group_ids: list[str] | None = None,\\\\n    limit=RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[EntityEdge]:\\\\n    # fulltext search over facts\\\\n    fuzzy_query = fulltext_query(query, group_ids, driver)\\\\n\\\\n    if fuzzy_query == '':\\\\n        return []\\\\n\\\\n    match_query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    YIELD relationship AS rel, score\\\\n    MATCH (n:Entity)-[e:RELATES_TO {uuid: rel.uuid}]->(m:Entity)\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        match_query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        YIELD node, score\\\\n        MATCH (n:Entity)-[:RELATES_TO]->(e:RelatesToNode_ {uuid: node.uuid})-[:RELATES_TO]->(m:Entity)\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    filter_queries, filter_params = edge_search_filter_query_constructor(\\\\n        search_filter, driver.provider\\\\n    )\\\\n\\\\n    if group_ids is not None:\\\\n        filter_queries.append('e.group_id IN $group_ids')\\\\n        filter_params['group_ids'] = group_ids\\\\n\\\\n    filter_query = ''\\\\n    if filter_queries:\\\\n        filter_query = ' WHERE ' + (' AND '.join(filter_queries))\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        res = driver.run_aoss_query('edge_name_and_fact', query)  # pyright: ignore reportAttributeAccessIssue\\\\n        if res['hits']['total']['value'] > 0:\\\\n            input_ids = []\\\\n            for r in res['hits']['hits']:\\\\n                input_ids.append({'id': r['_source']['uuid'], 'score': r['_score']})\\\\n\\\\n            # Match the edge ids and return the values\\\\n            query = (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                                            UNWIND $ids as id\\\\n                                                                                            MATCH (n:Entity)-[e:RELATES_TO]->(m:Entity)\\\\n                                                                                            WHERE e.group_id IN $group_ids \\\\n                                                                                            AND id(e)=id \\\\n                                                                                            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + filter_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                AND id(e)=id\\\\n                WITH e, id.score as score, startNode(e) AS n, endNode(e) AS m\\\\n                RETURN\\\\n                    e.uuid AS uuid,\\\\n                    e.group_id AS group_id,\\\\n                    n.uuid AS source_node_uuid,\\\\n                    m.uuid AS target_node_uuid,\\\\n                    e.created_at AS created_at,\\\\n                    e.name AS name,\\\\n                    e.fact AS fact,\\\\n                    split(e.episodes, \\\\\\\",\\\\\\\") AS episodes,\\\\n                    e.expired_at AS expired_at,\\\\n                    e.valid_at AS valid_at,\\\\n                    e.invalid_at AS invalid_at,\\\\n                    properties(e) AS attributes\\\\n                ORDER BY score DESC LIMIT $limit\\\\n                            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n\\\\n            records, _, _ = await driver.execute_query(\\\\n                query,\\\\n                query=fuzzy_query,\\\\n                ids=input_ids,\\\\n                limit=limit,\\\\n                routing_='r',\\\\n                **filter_params,\\\\n            )\\\\n        else:\\\\n            return []\\\\n    elif driver.aoss_client:\\\\n        route = group_ids[0] if group_ids else None\\\\n        filters = build_aoss_edge_filters(group_ids or [], search_filter)\\\\n        res = driver.aoss_client.search(\\\\n            index='entity_edges',\\\\n            routing=route,\\\\n            _source=['uuid'],\\\\n            query={\\\\n                'bool': {\\\\n                    'filter': filters,\\\\n                    'must': [{'match': {'fact': {'query': query, 'operator': 'or'}}}],\\\\n                }\\\\n            },\\\\n        )\\\\n        if res['hits']['total']['value'] > 0:\\\\n            input_uuids = {}\\\\n            for r in res['hits']['hits']:\\\\n                input_uuids[r['_source']['uuid']] = r['_score']\\\\n\\\\n            # Get edges\\\\n            entity_edges = await EntityEdge.get_by_uuids(driver, list(input_uuids.keys()))\\\\n            entity_edges.sort(key=lambda e: input_uuids.get(e.uuid, 0), reverse=True)\\\\n            return entity_edges\\\\n        else:\\\\n            return []\\\\n    else:\\\\n        query = (\\\\n            get_relationships_query('edge_name_and_fact', limit=limit, provider=driver.provider)\\\\n            + match_query\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH e, score, n, m\\\\n            RETURN\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_entity_edge_return_query(driver.provider)\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            ORDER BY score DESC\\\\n            LIMIT $limit\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n\\\\n        records, _, _ = await driver.execute_query(\\\\n            query,\\\\n            query=fuzzy_query,\\\\n            limit=limit,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n\\\\n    edges = [get_entity_edge_from_record(record, driver.provider) for record in records]\\\\n\\\\n    return edges\\\\n\\\\n\\\\nasync def edge_similarity_search(\\\\n    driver: GraphDriver,\\\\n    search_vector: list[float],\\\\n    source_node_uuid: str | None,\\\\n    target_node_uuid: str | None,\\\\n    search_filter: SearchFilters,\\\\n    group_ids: list[str] | None = None,\\\\n    limit: int = RELEVANT_SCHEMA_LIMIT,\\\\n    min_score: float = DEFAULT_MIN_SCORE,\\\\n) -> list[EntityEdge]:\\\\n    match_query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        MATCH (n:Entity)-[e:RELATES_TO]->(m:Entity)\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        match_query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            MATCH (n:Entity)-[:RELATES_TO]->(e:RelatesToNode_)-[:RELATES_TO]->(m:Entity)\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    filter_queries, filter_params = edge_search_filter_query_constructor(\\\\n        search_filter, driver.provider\\\\n    )\\\\n\\\\n    if group_ids is not None:\\\\n        filter_queries.append('e.group_id IN $group_ids')\\\\n        filter_params['group_ids'] = group_ids\\\\n\\\\n        if source_node_uuid is not None:\\\\n            filter_params['source_uuid'] = source_node_uuid\\\\n            filter_queries.append('n.uuid = $source_uuid')\\\\n\\\\n        if target_node_uuid is not None:\\\\n            filter_params['target_uuid'] = target_node_uuid\\\\n            filter_queries.append('m.uuid = $target_uuid')\\\\n\\\\n    filter_query = ''\\\\n    if filter_queries:\\\\n        filter_query = ' WHERE ' + (' AND '.join(filter_queries))\\\\n\\\\n    search_vector_var = '$search_vector'\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        search_vector_var = f'CAST($search_vector AS FLOAT[{len(search_vector)}])'\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        query = (\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                    MATCH (n:Entity)-[e:RELATES_TO]->(m:Entity)\\\\n                                                                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            RETURN DISTINCT id(e) as id, e.fact_embedding as embedding\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n        resp, header, _ = await driver.execute_query(\\\\n            query,\\\\n            search_vector=search_vector,\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n\\\\n        if len(resp) > 0:\\\\n            # Calculate Cosine similarity then return the edge ids\\\\n            input_ids = []\\\\n            for r in resp:\\\\n                if r['embedding']:\\\\n                    score = calculate_cosine_similarity(\\\\n                        search_vector, list(map(float, r['embedding'].split(',')))\\\\n                    )\\\\n                    if score > min_score:\\\\n                        input_ids.append({'id': r['id'], 'score': score})\\\\n\\\\n            # Match the edge ides and return the values\\\\n            query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $ids as i\\\\n                MATCH ()-[r]->()\\\\n                WHERE id(r) = i.id\\\\n                RETURN\\\\n                    r.uuid AS uuid,\\\\n                    r.group_id AS group_id,\\\\n                    startNode(r).uuid AS source_node_uuid,\\\\n                    endNode(r).uuid AS target_node_uuid,\\\\n                    r.created_at AS created_at,\\\\n                    r.name AS name,\\\\n                    r.fact AS fact,\\\\n                    split(r.episodes, \\\\\\\",\\\\\\\") AS episodes,\\\\n                    r.expired_at AS expired_at,\\\\n                    r.valid_at AS valid_at,\\\\n                    r.invalid_at AS invalid_at,\\\\n                    properties(r) AS attributes\\\\n                ORDER BY i.score DESC\\\\n                LIMIT $limit\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            records, _, _ = await driver.execute_query(\\\\n                query,\\\\n                ids=input_ids,\\\\n                search_vector=search_vector,\\\\n                limit=limit,\\\\n                min_score=min_score,\\\\n                routing_='r',\\\\n                **filter_params,\\\\n            )\\\\n        else:\\\\n            return []\\\\n    elif driver.aoss_client:\\\\n        route = group_ids[0] if group_ids else None\\\\n        filters = build_aoss_edge_filters(group_ids or [], search_filter)\\\\n        res = driver.aoss_client.search(\\\\n            index='entity_edges',\\\\n            routing=route,\\\\n            _source=['uuid'],\\\\n            knn={\\\\n                'field': 'fact_embedding',\\\\n                'query_vector': search_vector,\\\\n                'k': limit,\\\\n                'num_candidates': 1000,\\\\n            },\\\\n            query={'bool': {'filter': filters}},\\\\n        )\\\\n\\\\n        if res['hits']['total']['value'] > 0:\\\\n            input_uuids = {}\\\\n            for r in res['hits']['hits']:\\\\n                input_uuids[r['_source']['uuid']] = r['_score']\\\\n\\\\n            # Get edges\\\\n            entity_edges = await EntityEdge.get_by_uuids(driver, list(input_uuids.keys()))\\\\n            entity_edges.sort(key=lambda e: input_uuids.get(e.uuid, 0), reverse=True)\\\\n            return entity_edges\\\\n\\\\n    else:\\\\n        query = (\\\\n            match_query\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH DISTINCT e, n, m, \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_vector_cosine_func_query('e.fact_embedding', search_vector_var, driver.provider)\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\" AS score\\\\n            WHERE score > $min_score\\\\n            RETURN\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_entity_edge_return_query(driver.provider)\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            ORDER BY score DESC\\\\n            LIMIT $limit\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n\\\\n        records, _, _ = await driver.execute_query(\\\\n            query,\\\\n            search_vector=search_vector,\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n\\\\n    edges = [get_entity_edge_from_record(record, driver.provider) for record in records]\\\\n\\\\n    return edges\\\\n\\\\n\\\\nasync def edge_bfs_search(\\\\n    driver: GraphDriver,\\\\n    bfs_origin_node_uuids: list[str] | None,\\\\n    bfs_max_depth: int,\\\\n    search_filter: SearchFilters,\\\\n    group_ids: list[str] | None = None,\\\\n    limit: int = RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[EntityEdge]:\\\\n    # vector similarity search over embedded facts\\\\n    if bfs_origin_node_uuids is None or len(bfs_origin_node_uuids) == 0:\\\\n        return []\\\\n\\\\n    filter_queries, filter_params = edge_search_filter_query_constructor(\\\\n        search_filter, driver.provider\\\\n    )\\\\n\\\\n    if group_ids is not None:\\\\n        filter_queries.append('e.group_id IN $group_ids')\\\\n        filter_params['group_ids'] = group_ids\\\\n\\\\n    filter_query = ''\\\\n    if filter_queries:\\\\n        filter_query = ' WHERE ' + (' AND '.join(filter_queries))\\\\n\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        # Kuzu stores entity edges twice with an intermediate node, so we need to match them\\\\n        # separately for the correct BFS depth.\\\\n        depth = bfs_max_depth * 2 - 1\\\\n        match_queries = [\\\\n            f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n            UNWIND $bfs_origin_node_uuids AS origin_uuid\\\\n            MATCH path = (origin:Entity {{uuid: origin_uuid}})-[:RELATES_TO*1..{depth}]->(:RelatesToNode_)\\\\n            UNWIND nodes(path) AS relNode\\\\n            MATCH (n:Entity)-[:RELATES_TO]->(e:RelatesToNode_ {{uuid: relNode.uuid}})-[:RELATES_TO]->(m:Entity)\\\\n            \\\\\\\"\\\\\\\"\\\\\\\",\\\\n        ]\\\\n        if bfs_max_depth > 1:\\\\n            depth = (bfs_max_depth - 1) * 2 - 1\\\\n            match_queries.append(f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $bfs_origin_node_uuids AS origin_uuid\\\\n                MATCH path = (origin:Episodic {{uuid: origin_uuid}})-[:MENTIONS]->(:Entity)-[:RELATES_TO*1..{depth}]->(:RelatesToNode_)\\\\n                UNWIND nodes(path) AS relNode\\\\n                MATCH (n:Entity)-[:RELATES_TO]->(e:RelatesToNode_ {{uuid: relNode.uuid}})-[:RELATES_TO]->(m:Entity)\\\\n            \\\\\\\"\\\\\\\"\\\\\\\")\\\\n\\\\n        records = []\\\\n        for match_query in match_queries:\\\\n            sub_records, _, _ = await driver.execute_query(\\\\n                match_query\\\\n                + filter_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                RETURN DISTINCT\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + get_entity_edge_return_query(driver.provider)\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                LIMIT $limit\\\\n                \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                bfs_origin_node_uuids=bfs_origin_node_uuids,\\\\n                limit=limit,\\\\n                routing_='r',\\\\n                **filter_params,\\\\n            )\\\\n            records.extend(sub_records)\\\\n    else:\\\\n        if driver.provider == GraphProvider.NEPTUNE:\\\\n            query = (\\\\n                f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $bfs_origin_node_uuids AS origin_uuid\\\\n                MATCH path = (origin {{uuid: origin_uuid}})-[:RELATES_TO|MENTIONS *1..{bfs_max_depth}]->(n:Entity)\\\\n                WHERE origin:Entity OR origin:Episodic\\\\n                UNWIND relationships(path) AS rel\\\\n                MATCH (n:Entity)-[e:RELATES_TO {{uuid: rel.uuid}}]-(m:Entity)\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + filter_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                RETURN DISTINCT\\\\n                    e.uuid AS uuid,\\\\n                    e.group_id AS group_id,\\\\n                    startNode(e).uuid AS source_node_uuid,\\\\n                    endNode(e).uuid AS target_node_uuid,\\\\n                    e.created_at AS created_at,\\\\n                    e.name AS name,\\\\n                    e.fact AS fact,\\\\n                    split(e.episodes, ',') AS episodes,\\\\n                    e.expired_at AS expired_at,\\\\n                    e.valid_at AS valid_at,\\\\n                    e.invalid_at AS invalid_at,\\\\n                    properties(e) AS attributes\\\\n                LIMIT $limit\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n        else:\\\\n            query = (\\\\n                f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $bfs_origin_node_uuids AS origin_uuid\\\\n                MATCH path = (origin {{uuid: origin_uuid}})-[:RELATES_TO|MENTIONS*1..{bfs_max_depth}]->(:Entity)\\\\n                UNWIND relationships(path) AS rel\\\\n                MATCH (n:Entity)-[e:RELATES_TO {{uuid: rel.uuid}}]-(m:Entity)\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + filter_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                RETURN DISTINCT\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + get_entity_edge_return_query(driver.provider)\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                LIMIT $limit\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n\\\\n        records, _, _ = await driver.execute_query(\\\\n            query,\\\\n            bfs_origin_node_uuids=bfs_origin_node_uuids,\\\\n            depth=bfs_max_depth,\\\\n            limit=limit,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n\\\\n    edges = [get_entity_edge_from_record(record, driver.provider) for record in records]\\\\n\\\\n    return edges\\\\n\\\\n\\\\nasync def node_fulltext_search(\\\\n    driver: GraphDriver,\\\\n    query: str,\\\\n    search_filter: SearchFilters,\\\\n    group_ids: list[str] | None = None,\\\\n    limit=RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[EntityNode]:\\\\n    # BM25 search to get top nodes\\\\n    fuzzy_query = fulltext_query(query, group_ids, driver)\\\\n    if fuzzy_query == '':\\\\n        return []\\\\n\\\\n    filter_queries, filter_params = node_search_filter_query_constructor(\\\\n        search_filter, driver.provider\\\\n    )\\\\n\\\\n    if group_ids is not None:\\\\n        filter_queries.append('n.group_id IN $group_ids')\\\\n        filter_params['group_ids'] = group_ids\\\\n\\\\n    filter_query = ''\\\\n    if filter_queries:\\\\n        filter_query = ' WHERE ' + (' AND '.join(filter_queries))\\\\n\\\\n    yield_query = 'YIELD node AS n, score'\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        yield_query = 'WITH node AS n, score'\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        res = driver.run_aoss_query('node_name_and_summary', query, limit=limit)  # pyright: ignore reportAttributeAccessIssue\\\\n        if res['hits']['total']['value'] > 0:\\\\n            input_ids = []\\\\n            for r in res['hits']['hits']:\\\\n                input_ids.append({'id': r['_source']['uuid'], 'score': r['_score']})\\\\n\\\\n            # Match the edge ides and return the values\\\\n            query = (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                                            UNWIND $ids as i\\\\n                                                                                            MATCH (n:Entity)\\\\n                                                                                            WHERE n.uuid=i.id\\\\n                                                                                            RETURN\\\\n                                                                            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + get_entity_node_return_query(driver.provider)\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                ORDER BY i.score DESC\\\\n                LIMIT $limit\\\\n                            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n            records, _, _ = await driver.execute_query(\\\\n                query,\\\\n                ids=input_ids,\\\\n                query=fuzzy_query,\\\\n                limit=limit,\\\\n                routing_='r',\\\\n                **filter_params,\\\\n            )\\\\n        else:\\\\n            return []\\\\n    elif driver.aoss_client:\\\\n        route = group_ids[0] if group_ids else None\\\\n        filters = build_aoss_node_filters(group_ids or [], search_filter)\\\\n        res = driver.aoss_client.search(\\\\n            'entities',\\\\n            routing=route,\\\\n            _source=['uuid'],\\\\n            query={\\\\n                'bool': {\\\\n                    'filter': filters,\\\\n                    'must': [\\\\n                        {\\\\n                            'multi_match': {\\\\n                                'query': query,\\\\n                                'field': ['name', 'summary'],\\\\n                                'operator': 'or',\\\\n                            }\\\\n                        }\\\\n                    ],\\\\n                }\\\\n            },\\\\n            limit=limit,\\\\n        )\\\\n\\\\n        if res['hits']['total']['value'] > 0:\\\\n            input_uuids = {}\\\\n            for r in res['hits']['hits']:\\\\n                input_uuids[r['_source']['uuid']] = r['_score']\\\\n\\\\n            # Get nodes\\\\n            entities = await EntityNode.get_by_uuids(driver, list(input_uuids.keys()))\\\\n            entities.sort(key=lambda e: input_uuids.get(e.uuid, 0), reverse=True)\\\\n            return entities\\\\n        else:\\\\n            return []\\\\n    else:\\\\n        query = (\\\\n            get_nodes_query(\\\\n                'node_name_and_summary', '$query', limit=limit, provider=driver.provider\\\\n            )\\\\n            + yield_query\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH n, score\\\\n            ORDER BY score DESC\\\\n            LIMIT $limit\\\\n            RETURN\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_entity_node_return_query(driver.provider)\\\\n        )\\\\n\\\\n        records, _, _ = await driver.execute_query(\\\\n            query,\\\\n            query=fuzzy_query,\\\\n            limit=limit,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n\\\\n    nodes = [get_entity_node_from_record(record, driver.provider) for record in records]\\\\n\\\\n    return nodes\\\\n\\\\n\\\\nasync def node_similarity_search(\\\\n    driver: GraphDriver,\\\\n    search_vector: list[float],\\\\n    search_filter: SearchFilters,\\\\n    group_ids: list[str] | None = None,\\\\n    limit=RELEVANT_SCHEMA_LIMIT,\\\\n    min_score: float = DEFAULT_MIN_SCORE,\\\\n) -> list[EntityNode]:\\\\n    filter_queries, filter_params = node_search_filter_query_constructor(\\\\n        search_filter, driver.provider\\\\n    )\\\\n\\\\n    if group_ids is not None:\\\\n        filter_queries.append('n.group_id IN $group_ids')\\\\n        filter_params['group_ids'] = group_ids\\\\n\\\\n    filter_query = ''\\\\n    if filter_queries:\\\\n        filter_query = ' WHERE ' + (' AND '.join(filter_queries))\\\\n\\\\n    search_vector_var = '$search_vector'\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        search_vector_var = f'CAST($search_vector AS FLOAT[{len(search_vector)}])'\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        query = (\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                    MATCH (n:Entity)\\\\n                                                                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            RETURN DISTINCT id(n) as id, n.name_embedding as embedding\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n        resp, header, _ = await driver.execute_query(\\\\n            query,\\\\n            params=filter_params,\\\\n            search_vector=search_vector,\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n        )\\\\n\\\\n        if len(resp) > 0:\\\\n            # Calculate Cosine similarity then return the edge ids\\\\n            input_ids = []\\\\n            for r in resp:\\\\n                if r['embedding']:\\\\n                    score = calculate_cosine_similarity(\\\\n                        search_vector, list(map(float, r['embedding'].split(',')))\\\\n                    )\\\\n                    if score > min_score:\\\\n                        input_ids.append({'id': r['id'], 'score': score})\\\\n\\\\n            # Match the edge ides and return the values\\\\n            query = (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                                                UNWIND $ids as i\\\\n                                                                                                MATCH (n:Entity)\\\\n                                                                                                WHERE id(n)=i.id\\\\n                                                                                                RETURN \\\\n                                                                                                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + get_entity_node_return_query(driver.provider)\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    ORDER BY i.score DESC\\\\n                    LIMIT $limit\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n            records, header, _ = await driver.execute_query(\\\\n                query,\\\\n                ids=input_ids,\\\\n                search_vector=search_vector,\\\\n                limit=limit,\\\\n                min_score=min_score,\\\\n                routing_='r',\\\\n                **filter_params,\\\\n            )\\\\n        else:\\\\n            return []\\\\n    elif driver.aoss_client:\\\\n        route = group_ids[0] if group_ids else None\\\\n        filters = build_aoss_node_filters(group_ids or [], search_filter)\\\\n        res = driver.aoss_client.search(\\\\n            index='entities',\\\\n            routing=route,\\\\n            _source=['uuid'],\\\\n            knn={\\\\n                'field': 'fact_embedding',\\\\n                'query_vector': search_vector,\\\\n                'k': limit,\\\\n                'num_candidates': 1000,\\\\n            },\\\\n            query={'bool': {'filter': filters}},\\\\n        )\\\\n\\\\n        if res['hits']['total']['value'] > 0:\\\\n            input_uuids = {}\\\\n            for r in res['hits']['hits']:\\\\n                input_uuids[r['_source']['uuid']] = r['_score']\\\\n\\\\n            # Get edges\\\\n            entity_nodes = await EntityNode.get_by_uuids(driver, list(input_uuids.keys()))\\\\n            entity_nodes.sort(key=lambda e: input_uuids.get(e.uuid, 0), reverse=True)\\\\n            return entity_nodes\\\\n    else:\\\\n        query = (\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                    MATCH (n:Entity)\\\\n                                                                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH n, \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_vector_cosine_func_query('n.name_embedding', search_vector_var, driver.provider)\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\" AS score\\\\n            WHERE score > $min_score\\\\n            RETURN\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_entity_node_return_query(driver.provider)\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            ORDER BY score DESC\\\\n            LIMIT $limit\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n\\\\n        records, _, _ = await driver.execute_query(\\\\n            query,\\\\n            search_vector=search_vector,\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n\\\\n    nodes = [get_entity_node_from_record(record, driver.provider) for record in records]\\\\n\\\\n    return nodes\\\\n\\\\n\\\\nasync def node_bfs_search(\\\\n    driver: GraphDriver,\\\\n    bfs_origin_node_uuids: list[str] | None,\\\\n    search_filter: SearchFilters,\\\\n    bfs_max_depth: int,\\\\n    group_ids: list[str] | None = None,\\\\n    limit: int = RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[EntityNode]:\\\\n    if bfs_origin_node_uuids is None or len(bfs_origin_node_uuids) == 0 or bfs_max_depth < 1:\\\\n        return []\\\\n\\\\n    filter_queries, filter_params = node_search_filter_query_constructor(\\\\n        search_filter, driver.provider\\\\n    )\\\\n\\\\n    if group_ids is not None:\\\\n        filter_queries.append('n.group_id IN $group_ids')\\\\n        filter_queries.append('origin.group_id IN $group_ids')\\\\n        filter_params['group_ids'] = group_ids\\\\n\\\\n    filter_query = ''\\\\n    if filter_queries:\\\\n        filter_query = ' AND ' + (' AND '.join(filter_queries))\\\\n\\\\n    match_queries = [\\\\n        f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        UNWIND $bfs_origin_node_uuids AS origin_uuid\\\\n        MATCH (origin {{uuid: origin_uuid}})-[:RELATES_TO|MENTIONS*1..{bfs_max_depth}]->(n:Entity)\\\\n        WHERE n.group_id = origin.group_id\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    ]\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        match_queries = [\\\\n            f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n            UNWIND $bfs_origin_node_uuids AS origin_uuid\\\\n            MATCH (origin {{uuid: origin_uuid}})-[e:RELATES_TO|MENTIONS*1..{bfs_max_depth}]->(n:Entity)\\\\n            WHERE origin:Entity OR origin.Episode\\\\n            AND n.group_id = origin.group_id\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        ]\\\\n\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        depth = bfs_max_depth * 2\\\\n        match_queries = [\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            UNWIND $bfs_origin_node_uuids AS origin_uuid\\\\n            MATCH (origin:Episodic {uuid: origin_uuid})-[:MENTIONS]->(n:Entity)\\\\n            WHERE n.group_id = origin.group_id\\\\n            \\\\\\\"\\\\\\\"\\\\\\\",\\\\n            f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n            UNWIND $bfs_origin_node_uuids AS origin_uuid\\\\n            MATCH (origin:Entity {{uuid: origin_uuid}})-[:RELATES_TO*2..{depth}]->(n:Entity)\\\\n            WHERE n.group_id = origin.group_id\\\\n            \\\\\\\"\\\\\\\"\\\\\\\",\\\\n        ]\\\\n        if bfs_max_depth > 1:\\\\n            depth = (bfs_max_depth - 1) * 2\\\\n            match_queries.append(f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $bfs_origin_node_uuids AS origin_uuid\\\\n                MATCH (origin:Episodic {{uuid: origin_uuid}})-[:MENTIONS]->(:Entity)-[:RELATES_TO*2..{depth}]->(n:Entity)\\\\n                WHERE n.group_id = origin.group_id\\\\n            \\\\\\\"\\\\\\\"\\\\\\\")\\\\n\\\\n    records = []\\\\n    for match_query in match_queries:\\\\n        sub_records, _, _ = await driver.execute_query(\\\\n            match_query\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            RETURN\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_entity_node_return_query(driver.provider)\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            LIMIT $limit\\\\n            \\\\\\\"\\\\\\\"\\\\\\\",\\\\n            bfs_origin_node_uuids=bfs_origin_node_uuids,\\\\n            limit=limit,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n        records.extend(sub_records)\\\\n\\\\n    nodes = [get_entity_node_from_record(record, driver.provider) for record in records]\\\\n\\\\n    return nodes\\\\n\\\\n\\\\nasync def episode_fulltext_search(\\\\n    driver: GraphDriver,\\\\n    query: str,\\\\n    _search_filter: SearchFilters,\\\\n    group_ids: list[str] | None = None,\\\\n    limit=RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[EpisodicNode]:\\\\n    # BM25 search to get top episodes\\\\n    fuzzy_query = fulltext_query(query, group_ids, driver)\\\\n    if fuzzy_query == '':\\\\n        return []\\\\n\\\\n    filter_params: dict[str, Any] = {}\\\\n    group_filter_query: LiteralString = ''\\\\n    if group_ids is not None:\\\\n        group_filter_query += '\\\\\\\\nAND e.group_id IN $group_ids'\\\\n        filter_params['group_ids'] = group_ids\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        res = driver.run_aoss_query('episode_content', query, limit=limit)  # pyright: ignore reportAttributeAccessIssue\\\\n        if res['hits']['total']['value'] > 0:\\\\n            input_ids = []\\\\n            for r in res['hits']['hits']:\\\\n                input_ids.append({'id': r['_source']['uuid'], 'score': r['_score']})\\\\n\\\\n            # Match the edge ides and return the values\\\\n            query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $ids as i\\\\n                MATCH (e:Episodic)\\\\n                WHERE e.uuid=i.uuid\\\\n            RETURN\\\\n                    e.content AS content,\\\\n                    e.created_at AS created_at,\\\\n                    e.valid_at AS valid_at,\\\\n                    e.uuid AS uuid,\\\\n                    e.name AS name,\\\\n                    e.group_id AS group_id,\\\\n                    e.source_description AS source_description,\\\\n                    e.source AS source,\\\\n                    e.entity_edges AS entity_edges\\\\n                ORDER BY i.score DESC\\\\n                LIMIT $limit\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            records, _, _ = await driver.execute_query(\\\\n                query,\\\\n                ids=input_ids,\\\\n                query=fuzzy_query,\\\\n                limit=limit,\\\\n                routing_='r',\\\\n                **filter_params,\\\\n            )\\\\n        else:\\\\n            return []\\\\n    elif driver.aoss_client:\\\\n        route = group_ids[0] if group_ids else None\\\\n        res = driver.aoss_client.search(\\\\n            'episodes',\\\\n            routing=route,\\\\n            _source=['uuid'],\\\\n            query={\\\\n                'bool': {\\\\n                    'filter': {'terms': group_ids},\\\\n                    'must': [\\\\n                        {\\\\n                            'multi_match': {\\\\n                                'query': query,\\\\n                                'field': ['name', 'content'],\\\\n                                'operator': 'or',\\\\n                            }\\\\n                        }\\\\n                    ],\\\\n                }\\\\n            },\\\\n            limit=limit,\\\\n        )\\\\n\\\\n        if res['hits']['total']['value'] > 0:\\\\n            input_uuids = {}\\\\n            for r in res['hits']['hits']:\\\\n                input_uuids[r['_source']['uuid']] = r['_score']\\\\n\\\\n            # Get nodes\\\\n            episodes = await EpisodicNode.get_by_uuids(driver, list(input_uuids.keys()))\\\\n            episodes.sort(key=lambda e: input_uuids.get(e.uuid, 0), reverse=True)\\\\n            return episodes\\\\n        else:\\\\n            return []\\\\n    else:\\\\n        query = (\\\\n            get_nodes_query('episode_content', '$query', limit=limit, provider=driver.provider)\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            YIELD node AS episode, score\\\\n            MATCH (e:Episodic)\\\\n            WHERE e.uuid = episode.uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + group_filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            RETURN\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + EPISODIC_NODE_RETURN\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            ORDER BY score DESC\\\\n            LIMIT $limit\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n\\\\n        records, _, _ = await driver.execute_query(\\\\n            query, query=fuzzy_query, limit=limit, routing_='r', **filter_params\\\\n        )\\\\n\\\\n    episodes = [get_episodic_node_from_record(record) for record in records]\\\\n\\\\n    return episodes\\\\n\\\\n\\\\nasync def community_fulltext_search(\\\\n    driver: GraphDriver,\\\\n    query: str,\\\\n    group_ids: list[str] | None = None,\\\\n    limit=RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[CommunityNode]:\\\\n    # BM25 search to get top communities\\\\n    fuzzy_query = fulltext_query(query, group_ids, driver)\\\\n    if fuzzy_query == '':\\\\n        return []\\\\n\\\\n    filter_params: dict[str, Any] = {}\\\\n    group_filter_query: LiteralString = ''\\\\n    if group_ids is not None:\\\\n        group_filter_query = 'WHERE c.group_id IN $group_ids'\\\\n        filter_params['group_ids'] = group_ids\\\\n\\\\n    yield_query = 'YIELD node AS c, score'\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        yield_query = 'WITH node AS c, score'\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        res = driver.run_aoss_query('community_name', query, limit=limit)  # pyright: ignore reportAttributeAccessIssue\\\\n        if res['hits']['total']['value'] > 0:\\\\n            # Calculate Cosine similarity then return the edge ids\\\\n            input_ids = []\\\\n            for r in res['hits']['hits']:\\\\n                input_ids.append({'id': r['_source']['uuid'], 'score': r['_score']})\\\\n\\\\n            # Match the edge ides and return the values\\\\n            query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                UNWIND $ids as i\\\\n                MATCH (comm:Community)\\\\n                WHERE comm.uuid=i.id\\\\n                RETURN\\\\n                    comm.uuid AS uuid,\\\\n                    comm.group_id AS group_id,\\\\n                    comm.name AS name,\\\\n                    comm.created_at AS created_at,\\\\n                    comm.summary AS summary,\\\\n                    [x IN split(comm.name_embedding, \\\\\\\",\\\\\\\") | toFloat(x)]AS name_embedding\\\\n                ORDER BY i.score DESC\\\\n                LIMIT $limit\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            records, _, _ = await driver.execute_query(\\\\n                query,\\\\n                ids=input_ids,\\\\n                query=fuzzy_query,\\\\n                limit=limit,\\\\n                routing_='r',\\\\n                **filter_params,\\\\n            )\\\\n        else:\\\\n            return []\\\\n    else:\\\\n        query = (\\\\n            get_nodes_query('community_name', '$query', limit=limit, provider=driver.provider)\\\\n            + yield_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH c, score\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + group_filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            RETURN\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + COMMUNITY_NODE_RETURN\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            ORDER BY score DESC\\\\n            LIMIT $limit\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n\\\\n        records, _, _ = await driver.execute_query(\\\\n            query, query=fuzzy_query, limit=limit, routing_='r', **filter_params\\\\n        )\\\\n\\\\n    communities = [get_community_node_from_record(record) for record in records]\\\\n\\\\n    return communities\\\\n\\\\n\\\\nasync def community_similarity_search(\\\\n    driver: GraphDriver,\\\\n    search_vector: list[float],\\\\n    group_ids: list[str] | None = None,\\\\n    limit=RELEVANT_SCHEMA_LIMIT,\\\\n    min_score=DEFAULT_MIN_SCORE,\\\\n) -> list[CommunityNode]:\\\\n    # vector similarity search over entity names\\\\n    query_params: dict[str, Any] = {}\\\\n\\\\n    group_filter_query: LiteralString = ''\\\\n    if group_ids is not None:\\\\n        group_filter_query += ' WHERE c.group_id IN $group_ids'\\\\n        query_params['group_ids'] = group_ids\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        query = (\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                    MATCH (n:Community)\\\\n                                                                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + group_filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            RETURN DISTINCT id(n) as id, n.name_embedding as embedding\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n        resp, header, _ = await driver.execute_query(\\\\n            query,\\\\n            search_vector=search_vector,\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **query_params,\\\\n        )\\\\n\\\\n        if len(resp) > 0:\\\\n            # Calculate Cosine similarity then return the edge ids\\\\n            input_ids = []\\\\n            for r in resp:\\\\n                if r['embedding']:\\\\n                    score = calculate_cosine_similarity(\\\\n                        search_vector, list(map(float, r['embedding'].split(',')))\\\\n                    )\\\\n                    if score > min_score:\\\\n                        input_ids.append({'id': r['id'], 'score': score})\\\\n\\\\n            # Match the edge ides and return the values\\\\n            query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    UNWIND $ids as i\\\\n                    MATCH (comm:Community)\\\\n                    WHERE id(comm)=i.id\\\\n                    RETURN\\\\n                        comm.uuid As uuid,\\\\n                        comm.group_id AS group_id,\\\\n                        comm.name AS name,\\\\n                        comm.created_at AS created_at,\\\\n                        comm.summary AS summary,\\\\n                        comm.name_embedding AS name_embedding\\\\n                    ORDER BY i.score DESC\\\\n                    LIMIT $limit\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            records, header, _ = await driver.execute_query(\\\\n                query,\\\\n                ids=input_ids,\\\\n                search_vector=search_vector,\\\\n                limit=limit,\\\\n                min_score=min_score,\\\\n                routing_='r',\\\\n                **query_params,\\\\n            )\\\\n        else:\\\\n            return []\\\\n    else:\\\\n        search_vector_var = '$search_vector'\\\\n        if driver.provider == GraphProvider.KUZU:\\\\n            search_vector_var = f'CAST($search_vector AS FLOAT[{len(search_vector)}])'\\\\n\\\\n        query = (\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                    MATCH (c:Community)\\\\n                                                                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + group_filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH c,\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_vector_cosine_func_query('c.name_embedding', search_vector_var, driver.provider)\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\" AS score\\\\n            WHERE score > $min_score\\\\n            RETURN\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + COMMUNITY_NODE_RETURN\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            ORDER BY score DESC\\\\n            LIMIT $limit\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n\\\\n        records, _, _ = await driver.execute_query(\\\\n            query,\\\\n            search_vector=search_vector,\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **query_params,\\\\n        )\\\\n\\\\n    communities = [get_community_node_from_record(record) for record in records]\\\\n\\\\n    return communities\\\\n\\\\n\\\\nasync def hybrid_node_search(\\\\n    queries: list[str],\\\\n    embeddings: list[list[float]],\\\\n    driver: GraphDriver,\\\\n    search_filter: SearchFilters,\\\\n    group_ids: list[str] | None = None,\\\\n    limit: int = RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[EntityNode]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Perform a hybrid search for nodes using both text queries and embeddings.\\\\n\\\\n    This method combines fulltext search and vector similarity search to find\\\\n    relevant nodes in the graph database. It uses a rrf reranker.\\\\n\\\\n    Parameters\\\\n    ----------\\\\n    queries : list[str]\\\\n        A list of text queries to search for.\\\\n    embeddings : list[list[float]]\\\\n        A list of embedding vectors corresponding to the queries. If empty only fulltext search is performed.\\\\n    driver : GraphDriver\\\\n        The Neo4j driver instance for database operations.\\\\n    group_ids : list[str] | None, optional\\\\n        The list of group ids to retrieve nodes from.\\\\n    limit : int | None, optional\\\\n        The maximum number of results to return per search method. If None, a default limit will be applied.\\\\n\\\\n    Returns\\\\n    -------\\\\n    list[EntityNode]\\\\n        A list of unique EntityNode objects that match the search criteria.\\\\n\\\\n    Notes\\\\n    -----\\\\n    This method performs the following steps:\\\\n    1. Executes fulltext searches for each query.\\\\n    2. Executes vector similarity searches for each embedding.\\\\n    3. Combines and deduplicates the results from both search types.\\\\n    4. Logs the performance metrics of the search operation.\\\\n\\\\n    The search results are deduplicated based on the node UUIDs to ensure\\\\n    uniqueness in the returned list. The 'limit' parameter is applied to each\\\\n    individual search method before deduplication. If not specified, a default\\\\n    limit (defined in the individual search functions) will be used.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    start = time()\\\\n    results: list[list[EntityNode]] = list(\\\\n        await semaphore_gather(\\\\n            *[\\\\n                node_fulltext_search(driver, q, search_filter, group_ids, 2 * limit)\\\\n                for q in queries\\\\n            ],\\\\n            *[\\\\n                node_similarity_search(driver, e, search_filter, group_ids, 2 * limit)\\\\n                for e in embeddings\\\\n            ],\\\\n        )\\\\n    )\\\\n\\\\n    node_uuid_map: dict[str, EntityNode] = {\\\\n        node.uuid: node for result in results for node in result\\\\n    }\\\\n    result_uuids = [[node.uuid for node in result] for result in results]\\\\n\\\\n    ranked_uuids, _ = rrf(result_uuids)\\\\n\\\\n    relevant_nodes: list[EntityNode] = [node_uuid_map[uuid] for uuid in ranked_uuids]\\\\n\\\\n    end = time()\\\\n    logger.debug(f'Found relevant nodes: {ranked_uuids} in {(end - start) * 1000} ms')\\\\n    return relevant_nodes\\\\n\\\\n\\\\nasync def get_relevant_nodes(\\\\n    driver: GraphDriver,\\\\n    nodes: list[EntityNode],\\\\n    search_filter: SearchFilters,\\\\n    min_score: float = DEFAULT_MIN_SCORE,\\\\n    limit: int = RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[list[EntityNode]]:\\\\n    if len(nodes) == 0:\\\\n        return []\\\\n\\\\n    group_id = nodes[0].group_id\\\\n    query_nodes = [\\\\n        {\\\\n            'uuid': node.uuid,\\\\n            'name': node.name,\\\\n            'name_embedding': node.name_embedding,\\\\n            'fulltext_query': fulltext_query(node.name, [node.group_id], driver),\\\\n        }\\\\n        for node in nodes\\\\n    ]\\\\n\\\\n    filter_queries, filter_params = node_search_filter_query_constructor(\\\\n        search_filter, driver.provider\\\\n    )\\\\n\\\\n    filter_query = ''\\\\n    if filter_queries:\\\\n        filter_query = 'WHERE ' + (' AND '.join(filter_queries))\\\\n\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        embedding_size = len(nodes[0].name_embedding) if nodes[0].name_embedding is not None else 0\\\\n        if embedding_size == 0:\\\\n            return []\\\\n\\\\n        # FIXME: Kuzu currently does not support using variables such as `node.fulltext_query` as an input to FTS, which means `get_relevant_nodes()` won't work with Kuzu as the graph driver.\\\\n        query = (\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                    UNWIND $nodes AS node\\\\n                                                                    MATCH (n:Entity {group_id: $group_id})\\\\n                                                                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH node, n, \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_vector_cosine_func_query(\\\\n                'n.name_embedding',\\\\n                f'CAST(node.name_embedding AS FLOAT[{embedding_size}])',\\\\n                driver.provider,\\\\n            )\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\" AS score\\\\n            WHERE score > $min_score\\\\n            WITH node, collect(n)[:$limit] AS top_vector_nodes, collect(n.uuid) AS vector_node_uuids\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_nodes_query(\\\\n                'node_name_and_summary',\\\\n                'node.fulltext_query',\\\\n                limit=limit,\\\\n                provider=driver.provider,\\\\n            )\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH node AS m\\\\n            WHERE m.group_id = $group_id AND NOT m.uuid IN vector_node_uuids\\\\n            WITH node, top_vector_nodes, collect(m) AS fulltext_nodes\\\\n\\\\n            WITH node, list_concat(top_vector_nodes, fulltext_nodes) AS combined_nodes\\\\n\\\\n            UNWIND combined_nodes AS x\\\\n            WITH node, collect(DISTINCT {\\\\n                uuid: x.uuid,\\\\n                name: x.name,\\\\n                name_embedding: x.name_embedding,\\\\n                group_id: x.group_id,\\\\n                created_at: x.created_at,\\\\n                summary: x.summary,\\\\n                labels: x.labels,\\\\n                attributes: x.attributes\\\\n            }) AS matches\\\\n\\\\n            RETURN\\\\n            node.uuid AS search_node_uuid, matches\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n    else:\\\\n        query = (\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                    UNWIND $nodes AS node\\\\n                                                                    MATCH (n:Entity {group_id: $group_id})\\\\n                                                                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH node, n, \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_vector_cosine_func_query(\\\\n                'n.name_embedding', 'node.name_embedding', driver.provider\\\\n            )\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\" AS score\\\\n            WHERE score > $min_score\\\\n            WITH node, collect(n)[..$limit] AS top_vector_nodes, collect(n.uuid) AS vector_node_uuids\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + get_nodes_query(\\\\n                'node_name_and_summary',\\\\n                'node.fulltext_query',\\\\n                limit=limit,\\\\n                provider=driver.provider,\\\\n            )\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            YIELD node AS m\\\\n            WHERE m.group_id = $group_id\\\\n            WITH node, top_vector_nodes, vector_node_uuids, collect(m) AS fulltext_nodes\\\\n\\\\n            WITH node,\\\\n                top_vector_nodes,\\\\n                [m IN fulltext_nodes WHERE NOT m.uuid IN vector_node_uuids] AS filtered_fulltext_nodes\\\\n\\\\n            WITH node, top_vector_nodes + filtered_fulltext_nodes AS combined_nodes\\\\n\\\\n            UNWIND combined_nodes AS combined_node\\\\n            WITH node, collect(DISTINCT combined_node) AS deduped_nodes\\\\n\\\\n            RETURN\\\\n            node.uuid AS search_node_uuid,\\\\n            [x IN deduped_nodes | {\\\\n                uuid: x.uuid,\\\\n                name: x.name,\\\\n                name_embedding: x.name_embedding,\\\\n                group_id: x.group_id,\\\\n                created_at: x.created_at,\\\\n                summary: x.summary,\\\\n                labels: labels(x),\\\\n                attributes: properties(x)\\\\n            }] AS matches\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n\\\\n    results, _, _ = await driver.execute_query(\\\\n        query,\\\\n        nodes=query_nodes,\\\\n        group_id=group_id,\\\\n        limit=limit,\\\\n        min_score=min_score,\\\\n        routing_='r',\\\\n        **filter_params,\\\\n    )\\\\n\\\\n    relevant_nodes_dict: dict[str, list[EntityNode]] = {\\\\n        result['search_node_uuid']: [\\\\n            get_entity_node_from_record(record, driver.provider) for record in result['matches']\\\\n        ]\\\\n        for result in results\\\\n    }\\\\n\\\\n    relevant_nodes = [relevant_nodes_dict.get(node.uuid, []) for node in nodes]\\\\n\\\\n    return relevant_nodes\\\\n\\\\n\\\\nasync def get_relevant_edges(\\\\n    driver: GraphDriver,\\\\n    edges: list[EntityEdge],\\\\n    search_filter: SearchFilters,\\\\n    min_score: float = DEFAULT_MIN_SCORE,\\\\n    limit: int = RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[list[EntityEdge]]:\\\\n    if len(edges) == 0:\\\\n        return []\\\\n\\\\n    filter_queries, filter_params = edge_search_filter_query_constructor(\\\\n        search_filter, driver.provider\\\\n    )\\\\n\\\\n    filter_query = ''\\\\n    if filter_queries:\\\\n        filter_query = ' WHERE ' + (' AND '.join(filter_queries))\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        query = (\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                    UNWIND $edges AS edge\\\\n                                                                    MATCH (n:Entity {uuid: edge.source_node_uuid})-[e:RELATES_TO {group_id: edge.group_id}]-(m:Entity {uuid: edge.target_node_uuid})\\\\n                                                                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH e, edge\\\\n            RETURN DISTINCT id(e) as id, e.fact_embedding as source_embedding, edge.uuid as search_edge_uuid,\\\\n            edge.fact_embedding as target_embedding\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n        resp, _, _ = await driver.execute_query(\\\\n            query,\\\\n            edges=[edge.model_dump() for edge in edges],\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n\\\\n        # Calculate Cosine similarity then return the edge ids\\\\n        input_ids = []\\\\n        for r in resp:\\\\n            score = calculate_cosine_similarity(\\\\n                list(map(float, r['source_embedding'].split(','))), r['target_embedding']\\\\n            )\\\\n            if score > min_score:\\\\n                input_ids.append({'id': r['id'], 'score': score, 'uuid': r['search_edge_uuid']})\\\\n\\\\n        # Match the edge ides and return the values\\\\n        query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        UNWIND $ids AS edge\\\\n        MATCH ()-[e]->()\\\\n        WHERE id(e) = edge.id\\\\n        WITH edge, e\\\\n        ORDER BY edge.score DESC\\\\n        RETURN edge.uuid AS search_edge_uuid,\\\\n            collect({\\\\n                uuid: e.uuid,\\\\n                source_node_uuid: startNode(e).uuid,\\\\n                target_node_uuid: endNode(e).uuid,\\\\n                created_at: e.created_at,\\\\n                name: e.name,\\\\n                group_id: e.group_id,\\\\n                fact: e.fact,\\\\n                fact_embedding: [x IN split(e.fact_embedding, \\\\\\\",\\\\\\\") | toFloat(x)],\\\\n                episodes: split(e.episodes, \\\\\\\",\\\\\\\"),\\\\n                expired_at: e.expired_at,\\\\n                valid_at: e.valid_at,\\\\n                invalid_at: e.invalid_at,\\\\n                attributes: properties(e)\\\\n            })[..$limit] AS matches\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        results, _, _ = await driver.execute_query(\\\\n            query,\\\\n            ids=input_ids,\\\\n            edges=[edge.model_dump() for edge in edges],\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n    else:\\\\n        if driver.provider == GraphProvider.KUZU:\\\\n            embedding_size = (\\\\n                len(edges[0].fact_embedding) if edges[0].fact_embedding is not None else 0\\\\n            )\\\\n            if embedding_size == 0:\\\\n                return []\\\\n\\\\n            query = (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                        UNWIND $edges AS edge\\\\n                                                                        MATCH (n:Entity {uuid: edge.source_node_uuid})-[:RELATES_TO]-(e:RelatesToNode_ {group_id: edge.group_id})-[:RELATES_TO]-(m:Entity {uuid: edge.target_node_uuid})\\\\n                                                                        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + filter_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                WITH e, edge, n, m, \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + get_vector_cosine_func_query(\\\\n                    'e.fact_embedding',\\\\n                    f'CAST(edge.fact_embedding AS FLOAT[{embedding_size}])',\\\\n                    driver.provider,\\\\n                )\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\" AS score\\\\n                WHERE score > $min_score\\\\n                WITH e, edge, n, m, score\\\\n                ORDER BY score DESC\\\\n                LIMIT $limit\\\\n                RETURN\\\\n                    edge.uuid AS search_edge_uuid,\\\\n                    collect({\\\\n                        uuid: e.uuid,\\\\n                        source_node_uuid: n.uuid,\\\\n                        target_node_uuid: m.uuid,\\\\n                        created_at: e.created_at,\\\\n                        name: e.name,\\\\n                        group_id: e.group_id,\\\\n                        fact: e.fact,\\\\n                        fact_embedding: e.fact_embedding,\\\\n                        episodes: e.episodes,\\\\n                        expired_at: e.expired_at,\\\\n                        valid_at: e.valid_at,\\\\n                        invalid_at: e.invalid_at,\\\\n                        attributes: e.attributes\\\\n                    }) AS matches\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n        else:\\\\n            query = (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                        UNWIND $edges AS edge\\\\n                                                                        MATCH (n:Entity {uuid: edge.source_node_uuid})-[e:RELATES_TO {group_id: edge.group_id}]-(m:Entity {uuid: edge.target_node_uuid})\\\\n                                                                        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + filter_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                WITH e, edge, \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + get_vector_cosine_func_query(\\\\n                    'e.fact_embedding', 'edge.fact_embedding', driver.provider\\\\n                )\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\" AS score\\\\n                WHERE score > $min_score\\\\n                WITH edge, e, score\\\\n                ORDER BY score DESC\\\\n                RETURN\\\\n                    edge.uuid AS search_edge_uuid,\\\\n                    collect({\\\\n                        uuid: e.uuid,\\\\n                        source_node_uuid: startNode(e).uuid,\\\\n                        target_node_uuid: endNode(e).uuid,\\\\n                        created_at: e.created_at,\\\\n                        name: e.name,\\\\n                        group_id: e.group_id,\\\\n                        fact: e.fact,\\\\n                        fact_embedding: e.fact_embedding,\\\\n                        episodes: e.episodes,\\\\n                        expired_at: e.expired_at,\\\\n                        valid_at: e.valid_at,\\\\n                        invalid_at: e.invalid_at,\\\\n                        attributes: properties(e)\\\\n                    })[..$limit] AS matches\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n\\\\n        results, _, _ = await driver.execute_query(\\\\n            query,\\\\n            edges=[edge.model_dump() for edge in edges],\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n\\\\n    relevant_edges_dict: dict[str, list[EntityEdge]] = {\\\\n        result['search_edge_uuid']: [\\\\n            get_entity_edge_from_record(record, driver.provider) for record in result['matches']\\\\n        ]\\\\n        for result in results\\\\n    }\\\\n\\\\n    relevant_edges = [relevant_edges_dict.get(edge.uuid, []) for edge in edges]\\\\n\\\\n    return relevant_edges\\\\n\\\\n\\\\nasync def get_edge_invalidation_candidates(\\\\n    driver: GraphDriver,\\\\n    edges: list[EntityEdge],\\\\n    search_filter: SearchFilters,\\\\n    min_score: float = DEFAULT_MIN_SCORE,\\\\n    limit: int = RELEVANT_SCHEMA_LIMIT,\\\\n) -> list[list[EntityEdge]]:\\\\n    if len(edges) == 0:\\\\n        return []\\\\n\\\\n    filter_queries, filter_params = edge_search_filter_query_constructor(\\\\n        search_filter, driver.provider\\\\n    )\\\\n\\\\n    filter_query = ''\\\\n    if filter_queries:\\\\n        filter_query = ' AND ' + (' AND '.join(filter_queries))\\\\n\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        query = (\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                    UNWIND $edges AS edge\\\\n                                                                    MATCH (n:Entity)-[e:RELATES_TO {group_id: edge.group_id}]->(m:Entity)\\\\n                                                                    WHERE n.uuid IN [edge.source_node_uuid, edge.target_node_uuid] OR m.uuid IN [edge.target_node_uuid, edge.source_node_uuid]\\\\n                                                                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            + filter_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            WITH e, edge\\\\n            RETURN DISTINCT id(e) as id, e.fact_embedding as source_embedding,\\\\n            edge.fact_embedding as target_embedding,\\\\n            edge.uuid as search_edge_uuid\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n        resp, _, _ = await driver.execute_query(\\\\n            query,\\\\n            edges=[edge.model_dump() for edge in edges],\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n\\\\n        # Calculate Cosine similarity then return the edge ids\\\\n        input_ids = []\\\\n        for r in resp:\\\\n            score = calculate_cosine_similarity(\\\\n                list(map(float, r['source_embedding'].split(','))), r['target_embedding']\\\\n            )\\\\n            if score > min_score:\\\\n                input_ids.append({'id': r['id'], 'score': score, 'uuid': r['search_edge_uuid']})\\\\n\\\\n        # Match the edge ides and return the values\\\\n        query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        UNWIND $ids AS edge\\\\n        MATCH ()-[e]->()\\\\n        WHERE id(e) = edge.id\\\\n        WITH edge, e\\\\n        ORDER BY edge.score DESC\\\\n        RETURN edge.uuid AS search_edge_uuid,\\\\n            collect({\\\\n                uuid: e.uuid,\\\\n                source_node_uuid: startNode(e).uuid,\\\\n                target_node_uuid: endNode(e).uuid,\\\\n                created_at: e.created_at,\\\\n                name: e.name,\\\\n                group_id: e.group_id,\\\\n                fact: e.fact,\\\\n                fact_embedding: [x IN split(e.fact_embedding, \\\\\\\",\\\\\\\") | toFloat(x)],\\\\n                episodes: split(e.episodes, \\\\\\\",\\\\\\\"),\\\\n                expired_at: e.expired_at,\\\\n                valid_at: e.valid_at,\\\\n                invalid_at: e.invalid_at,\\\\n                attributes: properties(e)\\\\n            })[..$limit] AS matches\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        results, _, _ = await driver.execute_query(\\\\n            query,\\\\n            ids=input_ids,\\\\n            edges=[edge.model_dump() for edge in edges],\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n    else:\\\\n        if driver.provider == GraphProvider.KUZU:\\\\n            embedding_size = (\\\\n                len(edges[0].fact_embedding) if edges[0].fact_embedding is not None else 0\\\\n            )\\\\n            if embedding_size == 0:\\\\n                return []\\\\n\\\\n            query = (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                        UNWIND $edges AS edge\\\\n                                                                        MATCH (n:Entity)-[:RELATES_TO]->(e:RelatesToNode_ {group_id: edge.group_id})-[:RELATES_TO]->(m:Entity)\\\\n                                                                        WHERE (n.uuid IN [edge.source_node_uuid, edge.target_node_uuid] OR m.uuid IN [edge.target_node_uuid, edge.source_node_uuid])\\\\n                                                                        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + filter_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                WITH edge, e, n, m, \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + get_vector_cosine_func_query(\\\\n                    'e.fact_embedding',\\\\n                    f'CAST(edge.fact_embedding AS FLOAT[{embedding_size}])',\\\\n                    driver.provider,\\\\n                )\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\" AS score\\\\n                WHERE score > $min_score\\\\n                WITH edge, e, n, m, score\\\\n                ORDER BY score DESC\\\\n                LIMIT $limit\\\\n                RETURN\\\\n                    edge.uuid AS search_edge_uuid,\\\\n                    collect({\\\\n                        uuid: e.uuid,\\\\n                        source_node_uuid: n.uuid,\\\\n                        target_node_uuid: m.uuid,\\\\n                        created_at: e.created_at,\\\\n                        name: e.name,\\\\n                        group_id: e.group_id,\\\\n                        fact: e.fact,\\\\n                        fact_embedding: e.fact_embedding,\\\\n                        episodes: e.episodes,\\\\n                        expired_at: e.expired_at,\\\\n                        valid_at: e.valid_at,\\\\n                        invalid_at: e.invalid_at,\\\\n                        attributes: e.attributes\\\\n                    }) AS matches\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n        else:\\\\n            query = (\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                                                                        UNWIND $edges AS edge\\\\n                                                                        MATCH (n:Entity)-[e:RELATES_TO {group_id: edge.group_id}]->(m:Entity)\\\\n                                                                        WHERE n.uuid IN [edge.source_node_uuid, edge.target_node_uuid] OR m.uuid IN [edge.target_node_uuid, edge.source_node_uuid]\\\\n                                                                        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + filter_query\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                WITH edge, e, \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                + get_vector_cosine_func_query(\\\\n                    'e.fact_embedding', 'edge.fact_embedding', driver.provider\\\\n                )\\\\n                + \\\\\\\"\\\\\\\"\\\\\\\" AS score\\\\n                WHERE score > $min_score\\\\n                WITH edge, e, score\\\\n                ORDER BY score DESC\\\\n                RETURN\\\\n                    edge.uuid AS search_edge_uuid,\\\\n                    collect({\\\\n                        uuid: e.uuid,\\\\n                        source_node_uuid: startNode(e).uuid,\\\\n                        target_node_uuid: endNode(e).uuid,\\\\n                        created_at: e.created_at,\\\\n                        name: e.name,\\\\n                        group_id: e.group_id,\\\\n                        fact: e.fact,\\\\n                        fact_embedding: e.fact_embedding,\\\\n                        episodes: e.episodes,\\\\n                        expired_at: e.expired_at,\\\\n                        valid_at: e.valid_at,\\\\n                        invalid_at: e.invalid_at,\\\\n                        attributes: properties(e)\\\\n                    })[..$limit] AS matches\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            )\\\\n\\\\n        results, _, _ = await driver.execute_query(\\\\n            query,\\\\n            edges=[edge.model_dump() for edge in edges],\\\\n            limit=limit,\\\\n            min_score=min_score,\\\\n            routing_='r',\\\\n            **filter_params,\\\\n        )\\\\n    invalidation_edges_dict: dict[str, list[EntityEdge]] = {\\\\n        result['search_edge_uuid']: [\\\\n            get_entity_edge_from_record(record, driver.provider) for record in result['matches']\\\\n        ]\\\\n        for result in results\\\\n    }\\\\n\\\\n    invalidation_edges = [invalidation_edges_dict.get(edge.uuid, []) for edge in edges]\\\\n\\\\n    return invalidation_edges\\\\n\\\\n\\\\n# takes in a list of rankings of uuids\\\\ndef rrf(\\\\n    results: list[list[str]], rank_const=1, min_score: float = 0\\\\n) -> tuple[list[str], list[float]]:\\\\n    scores: dict[str, float] = defaultdict(float)\\\\n    for result in results:\\\\n        for i, uuid in enumerate(result):\\\\n            scores[uuid] += 1 / (i + rank_const)\\\\n\\\\n    scored_uuids = [term for term in scores.items()]\\\\n    scored_uuids.sort(reverse=True, key=lambda term: term[1])\\\\n\\\\n    sorted_uuids = [term[0] for term in scored_uuids]\\\\n\\\\n    return [uuid for uuid in sorted_uuids if scores[uuid] >= min_score], [\\\\n        scores[uuid] for uuid in sorted_uuids if scores[uuid] >= min_score\\\\n    ]\\\\n\\\\n\\\\nasync def node_distance_reranker(\\\\n    driver: GraphDriver,\\\\n    node_uuids: list[str],\\\\n    center_node_uuid: str,\\\\n    min_score: float = 0,\\\\n) -> tuple[list[str], list[float]]:\\\\n    # filter out node_uuid center node node uuid\\\\n    filtered_uuids = list(filter(lambda node_uuid: node_uuid != center_node_uuid, node_uuids))\\\\n    scores: dict[str, float] = {center_node_uuid: 0.0}\\\\n\\\\n    query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    UNWIND $node_uuids AS node_uuid\\\\n    MATCH (center:Entity {uuid: $center_uuid})-[:RELATES_TO]-(n:Entity {uuid: node_uuid})\\\\n    RETURN 1 AS score, node_uuid AS uuid\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        UNWIND $node_uuids AS node_uuid\\\\n        MATCH (center:Entity {uuid: $center_uuid})-[:RELATES_TO]->(e:RelatesToNode_)-[:RELATES_TO]->(n:Entity {uuid: node_uuid})\\\\n        RETURN 1 AS score, node_uuid AS uuid\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    # Find the shortest path to center node\\\\n    results, header, _ = await driver.execute_query(\\\\n        query,\\\\n        node_uuids=filtered_uuids,\\\\n        center_uuid=center_node_uuid,\\\\n        routing_='r',\\\\n    )\\\\n    if driver.provider == GraphProvider.FALKORDB:\\\\n        results = [dict(zip(header, row, strict=True)) for row in results]\\\\n\\\\n    for result in results:\\\\n        uuid = result['uuid']\\\\n        score = result['score']\\\\n        scores[uuid] = score\\\\n\\\\n    for uuid in filtered_uuids:\\\\n        if uuid not in scores:\\\\n            scores[uuid] = float('inf')\\\\n\\\\n    # rerank on shortest distance\\\\n    filtered_uuids.sort(key=lambda cur_uuid: scores[cur_uuid])\\\\n\\\\n    # add back in filtered center uuid if it was filtered out\\\\n    if center_node_uuid in node_uuids:\\\\n        scores[center_node_uuid] = 0.1\\\\n        filtered_uuids = [center_node_uuid] + filtered_uuids\\\\n\\\\n    return [uuid for uuid in filtered_uuids if (1 / scores[uuid]) >= min_score], [\\\\n        1 / scores[uuid] for uuid in filtered_uuids if (1 / scores[uuid]) >= min_score\\\\n    ]\\\\n\\\\n\\\\nasync def episode_mentions_reranker(\\\\n    driver: GraphDriver, node_uuids: list[list[str]], min_score: float = 0\\\\n) -> tuple[list[str], list[float]]:\\\\n    # use rrf as a preliminary ranker\\\\n    sorted_uuids, _ = rrf(node_uuids)\\\\n    scores: dict[str, float] = {}\\\\n\\\\n    # Find the shortest path to center node\\\\n    results, _, _ = await driver.execute_query(\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        UNWIND $node_uuids AS node_uuid\\\\n        MATCH (episode:Episodic)-[r:MENTIONS]->(n:Entity {uuid: node_uuid})\\\\n        RETURN count(*) AS score, n.uuid AS uuid\\\\n        \\\\\\\"\\\\\\\"\\\\\\\",\\\\n        node_uuids=sorted_uuids,\\\\n        routing_='r',\\\\n    )\\\\n\\\\n    for result in results:\\\\n        scores[result['uuid']] = result['score']\\\\n\\\\n    for uuid in sorted_uuids:\\\\n        if uuid not in scores:\\\\n            scores[uuid] = float('inf')\\\\n\\\\n    # rerank on shortest distance\\\\n    sorted_uuids.sort(key=lambda cur_uuid: scores[cur_uuid])\\\\n\\\\n    return [uuid for uuid in sorted_uuids if scores[uuid] >= min_score], [\\\\n        scores[uuid] for uuid in sorted_uuids if scores[uuid] >= min_score\\\\n    ]\\\\n\\\\n\\\\ndef maximal_marginal_relevance(\\\\n    query_vector: list[float],\\\\n    candidates: dict[str, list[float]],\\\\n    mmr_lambda: float = DEFAULT_MMR_LAMBDA,\\\\n    min_score: float = -2.0,\\\\n) -> tuple[list[str], list[float]]:\\\\n    start = time()\\\\n    query_array = np.array(query_vector)\\\\n    candidate_arrays: dict[str, NDArray] = {}\\\\n    for uuid, embedding in candidates.items():\\\\n        candidate_arrays[uuid] = normalize_l2(embedding)\\\\n\\\\n    uuids: list[str] = list(candidate_arrays.keys())\\\\n\\\\n    similarity_matrix = np.zeros((len(uuids), len(uuids)))\\\\n\\\\n    for i, uuid_1 in enumerate(uuids):\\\\n        for j, uuid_2 in enumerate(uuids[:i]):\\\\n            u = candidate_arrays[uuid_1]\\\\n            v = candidate_arrays[uuid_2]\\\\n            similarity = np.dot(u, v)\\\\n\\\\n            similarity_matrix[i, j] = similarity\\\\n            similarity_matrix[j, i] = similarity\\\\n\\\\n    mmr_scores: dict[str, float] = {}\\\\n    for i, uuid in enumerate(uuids):\\\\n        max_sim = np.max(similarity_matrix[i, :])\\\\n        mmr = mmr_lambda * np.dot(query_array, candidate_arrays[uuid]) + (mmr_lambda - 1) * max_sim\\\\n        mmr_scores[uuid] = mmr\\\\n\\\\n    uuids.sort(reverse=True, key=lambda c: mmr_scores[c])\\\\n\\\\n    end = time()\\\\n    logger.debug(f'Completed MMR reranking in {(end - start) * 1000} ms')\\\\n\\\\n    return [uuid for uuid in uuids if mmr_scores[uuid] >= min_score], [\\\\n        mmr_scores[uuid] for uuid in uuids if mmr_scores[uuid] >= min_score\\\\n    ]\\\\n\\\\n\\\\nasync def get_embeddings_for_nodes(\\\\n    driver: GraphDriver, nodes: list[EntityNode]\\\\n) -> dict[str, list[float]]:\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        MATCH (n:Entity)\\\\n        WHERE n.uuid IN $node_uuids\\\\n        RETURN DISTINCT\\\\n            n.uuid AS uuid,\\\\n            split(n.name_embedding, \\\\\\\",\\\\\\\") AS name_embedding\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    else:\\\\n        query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        MATCH (n:Entity)\\\\n        WHERE n.uuid IN $node_uuids\\\\n        RETURN DISTINCT\\\\n            n.uuid AS uuid,\\\\n            n.name_embedding AS name_embedding\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    results, _, _ = await driver.execute_query(\\\\n        query,\\\\n        node_uuids=[node.uuid for node in nodes],\\\\n        routing_='r',\\\\n    )\\\\n\\\\n    embeddings_dict: dict[str, list[float]] = {}\\\\n    for result in results:\\\\n        uuid: str = result.get('uuid')\\\\n        embedding: list[float] = result.get('name_embedding')\\\\n        if uuid is not None and embedding is not None:\\\\n            embeddings_dict[uuid] = embedding\\\\n\\\\n    return embeddings_dict\\\\n\\\\n\\\\nasync def get_embeddings_for_communities(\\\\n    driver: GraphDriver, communities: list[CommunityNode]\\\\n) -> dict[str, list[float]]:\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        MATCH (c:Community)\\\\n        WHERE c.uuid IN $community_uuids\\\\n        RETURN DISTINCT\\\\n            c.uuid AS uuid,\\\\n            split(c.name_embedding, \\\\\\\",\\\\\\\") AS name_embedding\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    else:\\\\n        query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        MATCH (c:Community)\\\\n        WHERE c.uuid IN $community_uuids\\\\n        RETURN DISTINCT\\\\n            c.uuid AS uuid,\\\\n            c.name_embedding AS name_embedding\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    results, _, _ = await driver.execute_query(\\\\n        query,\\\\n        community_uuids=[community.uuid for community in communities],\\\\n        routing_='r',\\\\n    )\\\\n\\\\n    embeddings_dict: dict[str, list[float]] = {}\\\\n    for result in results:\\\\n        uuid: str = result.get('uuid')\\\\n        embedding: list[float] = result.get('name_embedding')\\\\n        if uuid is not None and embedding is not None:\\\\n            embeddings_dict[uuid] = embedding\\\\n\\\\n    return embeddings_dict\\\\n\\\\n\\\\nasync def get_embeddings_for_edges(\\\\n    driver: GraphDriver, edges: list[EntityEdge]\\\\n) -> dict[str, list[float]]:\\\\n    if driver.provider == GraphProvider.NEPTUNE:\\\\n        query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        MATCH (n:Entity)-[e:RELATES_TO]-(m:Entity)\\\\n        WHERE e.uuid IN $edge_uuids\\\\n        RETURN DISTINCT\\\\n            e.uuid AS uuid,\\\\n            split(e.fact_embedding, \\\\\\\",\\\\\\\") AS fact_embedding\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    else:\\\\n        match_query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            MATCH (n:Entity)-[e:RELATES_TO]-(m:Entity)\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if driver.provider == GraphProvider.KUZU:\\\\n            match_query = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                MATCH (n:Entity)-[:RELATES_TO]-(e:RelatesToNode_)-[:RELATES_TO]-(m:Entity)\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        query = (\\\\n            match_query\\\\n            + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        WHERE e.uuid IN $edge_uuids\\\\n        RETURN DISTINCT\\\\n            e.uuid AS uuid,\\\\n            e.fact_embedding AS fact_embedding\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        )\\\\n    results, _, _ = await driver.execute_query(\\\\n        query,\\\\n        edge_uuids=[edge.uuid for edge in edges],\\\\n        routing_='r',\\\\n    )\\\\n\\\\n    embeddings_dict: dict[str, list[float]] = {}\\\\n    for result in results:\\\\n        uuid: str = result.get('uuid')\\\\n        embedding: list[float] = result.get('fact_embedding')\\\\n        if uuid is not None and embedding is not None:\\\\n            embeddings_dict[uuid] = embedding\\\\n\\\\n    return embeddings_dict\\\\n\\\"}\"}]",
          "turn": 2,
          "askedAt": "2025-09-12T19:35:38.868Z",
          "completedAt": "2025-09-12T19:35:38.873Z",
          "source": "tools",
          "promptTokens": 0,
          "completionTokens": 0
        },
        {
          "role": "assistant",
          "content": "{\"thoughts\":\"We need to ensure Neo4j schema and fulltext indexes are created before first usage. The Graphiti library provides build_indices_and_constraints. We'll hook schema initialization into app startup using GraphService to call graph.build_indices_and_constraints(delete_existing=False). Also add an optional env GRAPHITI_INIT_SCHEMA to control this. Provide a maintenance endpoint or automatic init at first _init_graph_service. Update README to mention schema auto-init and troubleshooting. Implement changes in graph_service.py and main.py.\",\"tool_calls\":[{\"tool_name\":\"read_files\",\"arguments\":{\"paths\":[\"graphiti/graphiti_core/utils/maintenance/graph_data_operations.py\"]}},{\"tool_name\":\"write_file\",\"arguments\":{\"filename\":\"src/graph_service.py\",\"content\":\"from __future__ import annotations\\nimport os\\nfrom typing import Optional, Any, Dict, List\\nfrom graphiti_core import Graphiti\\nfrom graphiti_core.nodes import EpisodeType\\nfrom graphiti_core.utils.datetime_utils import utc_now\\n\\n\\nclass GraphServiceError(RuntimeError):\\n    \\\"\\\"\\\"Domain error raised for GraphService-related failures.\\\"\\\"\\\"\\n\\n\\nclass GraphService:\\n    \\\"\\\"\\\"\\n    Centralized service to manage the Graphiti knowledge graph lifecycle and access.\\n\\n    This service correctly initializes the Graphiti library from graphiti-core and\\n    exposes simple async helpers to add text episodes and search the graph.\\n\\n    Usage:\\n        service = GraphService.from_env()\\n        await service.add_document(text=\\\"...\\\")\\n        await service.search(query=\\\"...\\\")\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        *,\\n        uri: str,\\n        user: Optional[str] = None,\\n        password: Optional[str] = None,\\n        graphiti_kwargs: Optional[Dict[str, Any]] = None,\\n        init_schema: bool = True,\\n        delete_existing_indexes: bool = False,\\n    ) -> None:\\n        try:\\n            # Instantiate Graphiti using its official constructor (driver defaults to Neo4j)\\n            self._graph = Graphiti(uri=uri, user=user, password=password, **(graphiti_kwargs or {}))\\n        except Exception as exc:\\n            raise GraphServiceError(f\\\"Failed to initialize Graphiti: {exc}\\\")\\n\\n        # Optionally initialize schema and fulltext indexes on first startup\\n        self._init_schema = init_schema\\n        self._delete_existing_indexes = delete_existing_indexes\\n        self._initialized = False\\n\\n    @classmethod\\n    def from_env(\\n        cls,\\n        *,\\n        uri_env: str = \\\"NEO4J_URI\\\",\\n        user_env: str = \\\"NEO4J_USER\\\",\\n        password_env: str = \\\"NEO4J_PASSWORD\\\",\\n        **graphiti_kwargs: Any,\\n    ) -> \\\"GraphService\\\":\\n        \\\"\\\"\\\"Create a GraphService using environment variables for database connectivity.\\n\\n        Expected env vars:\\n        - NEO4J_URI (e.g., bolt://localhost:7687)\\n        - NEO4J_USER\\n        - NEO4J_PASSWORD\\n\\n        Optional env vars:\\n        - GRAPHITI_INIT_SCHEMA: default true. If truthy, creates required indexes/constraints/fulltext on startup.\\n        - GRAPHITI_DELETE_EXISTING_INDEXES: default false. If truthy, drops and recreates indexes.\\n        \\\"\\\"\\\"\\n        uri = os.getenv(uri_env)\\n        if not uri:\\n            raise GraphServiceError(\\n                f\\\"Missing required environment variable: {uri_env}. Example: bolt://localhost:7687\\\"\\n            )\\n        user = os.getenv(user_env)\\n        password = os.getenv(password_env)\\n\\n        # Parse booleans\\n        def _as_bool(name: str, default: bool) -> bool:\\n            val = os.getenv(name)\\n            if val is None:\\n                return default\\n            return val.strip().lower() in {\\\"1\\\", \\\"true\\\", \\\"yes\\\", \\\"y\\\", \\\"on\\\"}\\n\\n        init_schema = _as_bool(\\\"GRAPHITI_INIT_SCHEMA\\\", True)\\n        delete_existing = _as_bool(\\\"GRAPHITI_DELETE_EXISTING_INDEXES\\\", False)\\n\\n        return cls(\\n            uri=uri,\\n            user=user,\\n            password=password,\\n            graphiti_kwargs=graphiti_kwargs,\\n            init_schema=init_schema,\\n            delete_existing_indexes=delete_existing,\\n        )\\n\\n    def get_graph(self) -> Graphiti:\\n        \\\"\\\"\\\"Return the underlying Graphiti instance.\\\"\\\"\\\"\\n        return self._graph\\n\\n    async def ensure_schema(self) -> None:\\n        \\\"\\\"\\\"Ensure Neo4j indexes/constraints and fulltext indexes exist.\\n\\n        Creates fulltext index node_name_and_summary and others used by Graphiti to avoid\\n        UnknownLabel/UnknownProperty warnings and ProcedureCallFailed for missing fulltext indexes.\\n        \\\"\\\"\\\"\\n        if not self._init_schema or self._initialized:\\n            return\\n        try:\\n            await self._graph.build_indices_and_constraints(delete_existing=self._delete_existing_indexes)\\n        except Exception as exc:\\n            # Do not permanently mark initialized if schema creation failed\\n            raise GraphServiceError(f\\\"Failed to build Neo4j indexes/constraints: {exc}\\\")\\n        self._initialized = True\\n\\n    async def add_document(self, *, text: str, metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\\n        \\\"\\\"\\\"\\n        Ingest a text input as an Episode into the Graphiti knowledge graph.\\n\\n        Maps to Graphiti.add_episode(...), using sensible defaults derived from metadata.\\n\\n        Returns a summary dictionary including the new episode UUID and counts of created items.\\n        \\\"\\\"\\\"\\n        # Ensure schema before first write\\n        await self.ensure_schema()\\n\\n        meta = metadata or {}\\n        name = str(meta.get(\\\"name\\\") or meta.get(\\\"title\\\") or \\\"episode\\\")\\n        source_description = str(meta.get(\\\"source_description\\\") or meta.get(\\\"source\\\") or \\\"api\\\")\\n        group_id = meta.get(\\\"group_id\\\")\\n\\n        # Add the text as an episode\\n        result = await self._graph.add_episode(\\n            name=name,\\n            episode_body=text,\\n            source_description=source_description,\\n            reference_time=utc_now(),\\n            source=EpisodeType.text,\\n            group_id=group_id,\\n        )\\n\\n        # Pydantic BaseModel -> dict\\n        try:\\n            payload = result.model_dump()  # pydantic v2\\n        except Exception:\\n            try:\\n                payload = result.dict()  # pydantic v1 fallback\\n            except Exception:\\n                payload = {\\n                    \\\"episode_uuid\\\": getattr(result.episode, \\\"uuid\\\", None),\\n                }\\n\\n        # Provide a compact summary as the return value while keeping full payload\\n        summary: Dict[str, Any] = {\\n            \\\"episode_uuid\\\": payload.get(\\\"episode\\\", {}).get(\\\"uuid\\\") if isinstance(payload.get(\\\"episode\\\"), dict) else getattr(result.episode, \\\"uuid\\\", None),\\n            \\\"counts\\\": {\\n                \\\"nodes\\\": len(getattr(result, \\\"nodes\\\", [])),\\n                \\\"edges\\\": len(getattr(result, \\\"edges\\\", [])),\\n                \\\"episodic_edges\\\": len(getattr(result, \\\"episodic_edges\\\", [])),\\n                \\\"communities\\\": len(getattr(result, \\\"communities\\\", [])),\\n                \\\"community_edges\\\": len(getattr(result, \\\"community_edges\\\", [])),\\n            },\\n            \\\"raw\\\": payload,\\n        }\\n        return summary\\n\\n    async def search(\\n        self,\\n        *,\\n        query: str,\\n        top_k: int = 5,\\n        center_node_uuid: Optional[str] = None,\\n        group_ids: Optional[List[str]] = None,\\n    ) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"\\n        Execute Graphiti's hybrid search and return a list of edge dicts.\\n        \\\"\\\"\\\"\\n        # Ensure schema before search paths that rely on fulltext indexes\\n        await self.ensure_schema()\\n\\n        edges = await self._graph.search(\\n            query=query,\\n            center_node_uuid=center_node_uuid,\\n            group_ids=group_ids,\\n            num_results=top_k,\\n        )\\n\\n        def edge_to_dict(edge: Any) -> Dict[str, Any]:\\n            try:\\n                return edge.model_dump()\\n            except Exception:\\n                try:\\n                    return edge.dict()\\n                except Exception:\\n                    # As a final fallback, return basic attributes if present\\n                    return {\\n                        \\\"uuid\\\": getattr(edge, \\\"uuid\\\", None),\\n                        \\\"fact\\\": getattr(edge, \\\"fact\\\", None),\\n                        \\\"source_node_uuid\\\": getattr(edge, \\\"source_node_uuid\\\", None),\\n                        \\\"target_node_uuid\\\": getattr(edge, \\\"target_node_uuid\\\", None),\\n                        \\\"score\\\": getattr(edge, \\\"score\\\", None),\\n                    }\\n\\n        return [edge_to_dict(e) for e in edges]\\n\\n\\n__all__ = [\\\"GraphService\\\", \\\"GraphServiceError\\\"]\\n\"}},{\"tool_name\":\"write_file\",\"arguments\":{\"filename\":\"src/main.py\",\"content\":\"from __future__ import annotations\\nfrom typing import Any, Dict, Optional\\nfrom fastapi import FastAPI, HTTPException, Query\\nfrom fastapi.responses import JSONResponse\\nfrom pydantic import BaseModel, Field\\nfrom .graph_service import GraphService, GraphServiceError\\nfrom .config import configure_logging\\n\\n# Initialize FastAPI application\\napp = FastAPI(title=\\\"Graphiti API\\\", version=\\\"0.1.0\\\")\\n\\nclass DocumentCreate(BaseModel):\\n    text: str = Field(..., description=\\\"Raw text content to ingest into the knowledge graph\\\")\\n    metadata: Optional[Dict[str, Any]] = Field(\\n        default=None, description=\\\"Optional metadata associated with the text\\\"\\n    )\\n\\n@app.on_event(\\\"startup\\\")\\nasync def on_startup() -> None:\\n    configure_logging()\\n    # Pre-initialize the graph service and schema if possible\\n    try:\\n        service = _init_graph_service()\\n        # try to ensure schema at startup to avoid first-request latency\\n        await service.ensure_schema()\\n    except Exception:\\n        # Ignore at startup; endpoints will still attempt to init lazily and return clear errors if misconfigured\\n        pass\\n\\ndef _init_graph_service() -> GraphService:\\n    \\\"\\\"\\\"Initialize and cache a GraphService instance on the app state using environment variables.\\\"\\\"\\\"\\n    if getattr(app.state, \\\"graph_service\\\", None) is not None:\\n        return app.state.graph_service  # type: ignore[attr-defined]\\n    try:\\n        service = GraphService.from_env()\\n    except GraphServiceError:\\n        raise\\n    app.state.graph_service = service  # type: ignore[attr-defined]\\n    return service\\n\\n\\n@app.get(\\\"/health\\\")\\nasync def health_check() -> JSONResponse:\\n    \\\"\\\"\\\"Basic health check endpoint.\\n\\n    Returns HTTP 200 OK with a simple payload to indicate the service is running.\\n    \\\"\\\"\\\"\\n    return JSONResponse(status_code=200, content={\\\"status\\\": \\\"ok\\\"})\\n\\n\\n@app.post(\\\"/documents\\\")\\nasync def add_document(payload: DocumentCreate) -> JSONResponse:\\n    \\\"\\\"\\\"Ingest a text document into the knowledge graph as an Episode.\\n\\n    Expects JSON body: {\\\"text\\\": \\\"...\\\", \\\"metadata\\\": {...}}\\n    Returns a success response including the new episode UUID.\\n    \\\"\\\"\\\"\\n    try:\\n        service = _init_graph_service()\\n    except GraphServiceError as exc:\\n        # Graph backend not available or misconfigured\\n        raise HTTPException(status_code=503, detail=str(exc))\\n\\n    try:\\n        result = await service.add_document(text=payload.text, metadata=payload.metadata)\\n    except GraphServiceError as exc:\\n        raise HTTPException(status_code=500, detail=str(exc))\\n    except Exception as exc:  # Defensive: unknown client error\\n        raise HTTPException(status_code=500, detail=f\\\"Failed to add document: {exc}\\\")\\n\\n    return JSONResponse(status_code=201, content={\\\"success\\\": True, \\\"result\\\": result})\\n\\n\\n@app.get(\\\"/query\\\")\\nasync def query(\\n    q: str = Query(..., description=\\\"Natural language query to search the knowledge graph\\\"),\\n    top_k: int = Query(5, ge=1, le=100, description=\\\"Maximum number of results to return\\\"),\\n) -> JSONResponse:\\n    \\\"\\\"\\\"Query the knowledge graph for relevant information using hybrid search.\\n\\n    Example: GET /query?q=what+is+graphiti&top_k=5\\n    \\\"\\\"\\\"\\n    try:\\n        service = _init_graph_service()\\n    except GraphServiceError as exc:\\n        raise HTTPException(status_code=503, detail=str(exc))\\n\\n    try:\\n        results = await service.search(query=q, top_k=top_k)\\n    except GraphServiceError as exc:\\n        raise HTTPException(status_code=500, detail=str(exc))\\n    except Exception as exc:\\n        raise HTTPException(status_code=500, detail=f\\\"Failed to execute query: {exc}\\\")\\n\\n    return JSONResponse(status_code=200, content={\\\"query\\\": q, \\\"results\\\": results})\\n\"}},{\"tool_name\":\"write_file\",\"arguments\":{\"filename\":\"README.md\",\"content\":\"Graphiti API\\n\\nA FastAPI application that exposes a simple HTTP API over the Graphiti knowledge graph library. Use it to ingest text into a knowledge graph and run hybrid semantic queries locally.\\n\\nHighlights\\n- Endpoints:\\n  - GET /health: service liveness\\n  - POST /documents: ingest raw text as a Graphiti Episode\\n  - GET /query: hybrid search over the knowledge graph\\n- Configuration via environment variables (see Configuration below)\\n- Runs locally with Poetry or in a container with Docker\\n\\nPrerequisites\\n- Neo4j database (required by Graphiti)\\n  - Example container: neo4j:5-community (detailed instructions below)\\n- Python 3.10–3.13\\n- Poetry 1.8+\\n- Alternatively: Docker and Docker Compose\\n\\nSetting Up Neo4j Database (Required)\\n\\nThe Graphiti API requires a Neo4j database to function. Follow these step-by-step instructions to set up Neo4j locally from scratch:\\n\\nOption 1: Neo4j with Docker (Recommended for Development)\\n\\n1) Install Docker\\n   - Download and install Docker Desktop from https://www.docker.com/products/docker-desktop\\n   - Verify installation: `docker --version`\\n\\n2) Create a Neo4j container\\n   Choose a strong password and replace 'your_secure_password' in the command below:\\n   \\n   docker run -d \\\\\\n     --name neo4j-graphiti \\\\\\n     -p 7474:7474 -p 7687:7687 \\\\\\n     -e NEO4J_AUTH=neo4j/your_secure_password \\\\\\n     -v neo4j-data:/data \\\\\\n     -v neo4j-logs:/logs \\\\\\n     -v neo4j-import:/var/lib/neo4j/import \\\\\\n     -v neo4j-plugins:/plugins \\\\\\n     neo4j:5-community\\n\\n   This command:\\n   - Creates a container named 'neo4j-graphiti'\\n   - Exposes port 7474 (web interface) and 7687 (bolt protocol)\\n   - Sets username 'neo4j' with your chosen password\\n   - Creates persistent volumes for data, logs, imports, and plugins\\n   - Uses Neo4j Community Edition version 5\\n\\n3) Verify Neo4j is running\\n   Check container status:\\n   docker ps\\n   \\n   You should see the neo4j-graphiti container in the list.\\n   \\n   Check logs for any errors:\\n   docker logs neo4j-graphiti\\n   \\n   Wait for the message \\\"Started\\\" to appear in the logs (this may take 30-60 seconds on first startup).\\n\\n4) Access Neo4j Browser (Optional)\\n   Open your web browser and go to: http://localhost:7474\\n   \\n   Login with:\\n   - Username: neo4j\\n   - Password: your_secure_password (the one you set in step 2)\\n   \\n   You should see the Neo4j Browser interface, confirming the database is ready.\\n\\n5) Test connectivity\\n   Run a simple test query in Neo4j Browser:\\n   MATCH (n) RETURN count(n)\\n   \\n   This should return 0 (empty database) without errors.\\n\\nOption 2: Neo4j Desktop (GUI Application)\\n\\n1) Download Neo4j Desktop\\n   - Go to https://neo4j.com/download/\\n   - Download Neo4j Desktop for your operating system\\n   - Install following the platform-specific instructions\\n\\n2) Create a new project\\n   - Launch Neo4j Desktop\\n   - Click \\\"New Project\\\" and give it a name (e.g., \\\"Graphiti API\\\")\\n\\n3) Create a database\\n   - In your project, click \\\"Add Database\\\" → \\\"Local DBMS\\\"\\n   - Name: \\\"graphiti-db\\\" (or your preferred name)\\n   - Password: Choose a secure password\\n   - Version: Select Neo4j 5.x (latest available)\\n   - Click \\\"Create\\\"\\n\\n4) Start the database\\n   - Click the \\\"Start\\\" button on your database\\n   - Wait for the status to show \\\"Active\\\" (green dot)\\n\\n5) Note connection details\\n   - Click on your database to see details\\n   - Note the bolt URL (typically bolt://localhost:7687)\\n   - Username is 'neo4j' by default\\n   - Password is what you set in step 3\\n\\nOption 3: Neo4j Server Installation (Production)\\n\\nFor production deployments, follow the official Neo4j installation guide:\\nhttps://neo4j.com/docs/operations-manual/current/installation/\\n\\nManaging Your Neo4j Instance\\n\\nStarting Neo4j (Docker method):\\ndocker start neo4j-graphiti\\n\\nStopping Neo4j (Docker method):\\ndocker stop neo4j-graphiti\\n\\nViewing logs (Docker method):\\ndocker logs neo4j-graphiti\\n\\nRemoving Neo4j container (if needed):\\ndocker stop neo4j-graphiti\\ndocker rm neo4j-graphiti\\n# Note: This removes the container but preserves data in volumes\\n\\nQuick Start\\n\\nOnce Neo4j is running, choose one of these options to run the Graphiti API:\\n\\nOption A: Run locally with Poetry\\n1) Clone and enter the repo\\n   git clone <your-repo-url>\\n   cd <your-repo>\\n\\n2) Set required environment (Neo4j)\\n   The API requires access to your Neo4j instance. Create a .env file at the repo root:\\n   \\n   # Neo4j Connection (Required)\\n   NEO4J_URI=bolt://localhost:7687\\n   NEO4J_USER=neo4j\\n   NEO4J_PASSWORD=your_secure_password\\n   \\n   # API Settings (Optional)\\n   API_HOST=0.0.0.0\\n   API_PORT=8000\\n   LOG_LEVEL=INFO\\n   \\n   # Graphiti Options (Optional)\\n   GRAPHITI_STORAGE_PATH=./data/graphiti\\n   GRAPHITI_RESET=false\\n   GRAPHITI_MODEL=\\n   GRAPHITI_COLLECTION=\\n   \\n   # Graphiti Schema Init (Optional)\\n   # When true (default), the service ensures required indexes and fulltext indexes exist on startup\\n   GRAPHITI_INIT_SCHEMA=true\\n   # When true, drops existing indexes before recreating them (useful for development only)\\n   GRAPHITI_DELETE_EXISTING_INDEXES=false\\n   \\n   Replace 'your_secure_password' with the password you set for Neo4j.\\n\\n3) Install dependencies\\n   poetry install\\n\\n4) Run the application\\n   poetry run uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload\\n\\n5) Verify everything works\\n   Test the health endpoint:\\n   curl http://localhost:8000/health\\n   \\n   Expected response: {\\\"status\\\": \\\"ok\\\"}\\n   \\n   Open the API docs:\\n   - Swagger UI: http://localhost:8000/docs\\n   - ReDoc: http://localhost:8000/redoc\\n\\nOption B: Run with Docker\\nA. Build and run directly\\n1) Build the image\\n   docker build -t local .\\n\\n2) Run the container (pass Neo4j creds)\\n   docker run --rm -p 8000:8000 \\\\\\n     -e NEO4J_URI=bolt://host.docker.internal:7687 \\\\\\n     -e NEO4J_USER=neo4j \\\\\\n     -e NEO4J_PASSWORD=your_secure_password \\\\\\n     -e LOG_LEVEL=INFO \\\\\\n     -e GRAPHITI_INIT_SCHEMA=true \\\\\\n     --name thefactory-knowledge local\\n\\n   Note: On Linux, replace host.docker.internal with your host IP or run Neo4j in another container on the same network.\\n\\n3) Visit docs\\n   http://localhost:8000/docs\\n\\nB. Use Docker Compose\\nThe provided docker-compose.yml defines the API service but does not inject your environment variables by default. Create an override file to pass them through.\\n\\n1) Create docker-compose.override.yml with your env:\\n   services:\\n     api:\\n       environment:\\n         - NEO4J_URI=${NEO4J_URI}\\n         - NEO4J_USER=${NEO4J_USER}\\n         - NEO4J_PASSWORD=${NEO4J_PASSWORD}\\n         - API_HOST=${API_HOST:-0.0.0.0}\\n         - API_PORT=${API_PORT:-8000}\\n         - LOG_LEVEL=${LOG_LEVEL:-INFO}\\n         - GRAPHITI_INIT_SCHEMA=${GRAPHITI_INIT_SCHEMA:-true}\\n         - GRAPHITI_DELETE_EXISTING_INDEXES=${GRAPHITI_DELETE_EXISTING_INDEXES:-false}\\n\\n2) Create a .env file at repo root with values:\\n   NEO4J_URI=bolt://localhost:7687\\n   NEO4J_USER=neo4j\\n   NEO4J_PASSWORD=your_secure_password\\n\\n3) Start the service\\n   docker compose up --build\\n\\n4) Visit docs\\n   http://localhost:8000/docs\\n\\nComplete Setup Verification\\n\\nTo ensure everything is working correctly:\\n\\n1) Test the health endpoint:\\n   curl http://localhost:8000/health\\n   Expected: {\\\"status\\\": \\\"ok\\\"}\\n\\n2) Test document ingestion:\\n   curl -X POST http://localhost:8000/documents \\\\\\n     -H \\\"Content-Type: application/json\\\" \\\\\\n     -d '{\\\"text\\\": \\\"Neo4j is a graph database that stores data as nodes and relationships.\\\", \\\"metadata\\\": {\\\"title\\\": \\\"Neo4j Intro\\\"}}'\\n   \\n   Expected: {\\\"success\\\": true, \\\"result\\\": {\\\"episode_uuid\\\": \\\"...\\\", ...}}\\n\\n3) Test querying:\\n   curl -G http://localhost:8000/query --data-urlencode \\\"q=what is Neo4j\\\"\\n   \\n   Expected: {\\\"query\\\": \\\"what is Neo4j\\\", \\\"results\\\": [...]} \\n\\nConfiguration\\nEnvironment variables (authoritative names are in src/config.py):\\n- API_HOST: Host interface for the API (default: 0.0.0.0)\\n- API_PORT: Port for the API (default: 8000)\\n- LOG_LEVEL: Logging level (default: INFO)\\n\\n- NEO4J_URI: Required. Example: bolt://localhost:7687\\n- NEO4J_USER: Required. Example: neo4j\\n- NEO4J_PASSWORD: Required. Example: your_password\\n\\nOptional Graphiti-related settings (may be used in future features):\\n- GRAPHITI_STORAGE_PATH: Default ./data/graphiti\\n- GRAPHITI_RESET: Reset underlying storage on startup (default: false)\\n- GRAPHITI_MODEL: Optional model name\\n- GRAPHITI_COLLECTION: Optional collection/namespace\\n- GRAPHITI_INIT_SCHEMA: Ensure indexes/constraints/fulltext exist (default: true)\\n- GRAPHITI_DELETE_EXISTING_INDEXES: Drop and recreate indexes (default: false)\\n\\nAPI Usage\\n- Health check\\n  Method: GET\\n  URL: /health\\n  Example:\\n    curl -s http://localhost:8000/health\\n  Response:\\n    {\\\"status\\\": \\\"ok\\\"}\\n\\n- Ingest document\\n  Method: POST\\n  URL: /documents\\n  Body (JSON):\\n    {\\n      \\\"text\\\": \\\"Graphiti is a knowledge graph for RAG.\\\",\\n      \\\"metadata\\\": {\\\"title\\\": \\\"Intro\\\", \\\"source\\\": \\\"docs\\\"}\\n    }\\n  Example:\\n    curl -X POST http://localhost:8000/documents \\\\\\n      -H \\\"Content-Type: application/json\\\" \\\\\\n      -d '{\\\"text\\\": \\\"Graphiti is a knowledge graph for RAG.\\\", \\\"metadata\\\": {\\\"title\\\": \\\"Intro\\\"}}'\\n  Success response (201):\\n    {\\\"success\\\": true, \\\"result\\\": {\\\"episode_uuid\\\": \\\"...\\\", \\\"counts\\\": { ... }, \\\"raw\\\": { ... }}}\\n\\n- Query graph\\n  Method: GET\\n  URL: /query\\n  Params:\\n    - q: query string (required)\\n    - top_k: max results (default 5)\\n  Example:\\n    curl -G http://localhost:8000/query --data-urlencode \\\"q=what is graphiti\\\" --data-urlencode \\\"top_k=5\\\"\\n  Success response (200):\\n    {\\\"query\\\": \\\"what is graphiti\\\", \\\"results\\\": [ {\\\"uuid\\\": \\\"...\\\", \\\"fact\\\": \\\"...\\\", ...}, ... ]}\\n\\nNotes\\n- The Graphiti API expects a working Neo4j connection. If connection variables are missing or incorrect, endpoints like /documents and /query will return 503/500 errors.\\n- On first run against an empty Neo4j database, the service now auto-creates the schema and fulltext indexes used by Graphiti (e.g., node_name_and_summary, community_name, episode_content, edge_name_and_fact). This prevents errors like \\\"There is no such fulltext schema index: node_name_and_summary\\\" and UnknownLabel/UnknownProperty warnings.\\n- You can disable automatic schema creation by setting GRAPHITI_INIT_SCHEMA=false.\\n- To rebuild indexes from scratch (development only), set GRAPHITI_DELETE_EXISTING_INDEXES=true.\\n\\nTroubleshooting\\n\\nNeo4j Connection Issues:\\n- Connection refused to bolt://localhost:7687: \\n  * Check if Neo4j is running: `docker ps` (for Docker) or check Neo4j Desktop\\n  * Verify the port 7687 is not blocked by firewall\\n  * Ensure NEO4J_URI matches your Neo4j instance address\\n\\n- Authentication failed:\\n  * Verify NEO4J_USER and NEO4J_PASSWORD match your Neo4j credentials\\n  * For new Neo4j instances, the default user is 'neo4j'\\n  * Check if you need to change the initial password\\n\\n- Neo4j container won't start:\\n  * Check logs: `docker logs neo4j-graphiti`\\n  * Ensure ports 7474 and 7687 are not already in use\\n  * Try removing and recreating the container\\n\\nIndex/Schema Issues:\\n- Error: Failed to invoke procedure `db.index.fulltext.queryNodes`: There is no such fulltext schema index: node_name_and_summary\\n  * Cause: Schema not initialized.\\n  * Fix: Ensure GRAPHITI_INIT_SCHEMA=true (default) and restart the API, or call POST /documents once to trigger initialization.\\n\\nAPI Issues:\\n- 503 Service Unavailable when calling endpoints: Ensure NEO4J_URI/USER/PASSWORD are set correctly and Neo4j is reachable.\\n- 500 errors during ingestion/search: Increase verbosity with LOG_LEVEL=DEBUG and check logs.\\n- Docker networking on Linux: If using docker run, host.docker.internal may not resolve; use the host IP or run Neo4j in a user-defined network with the API container.\\n\\nLicense\\nSee LICENSE in this repository.\\n\\nAcknowledgements\\n- Graphiti by Zep: https://github.com/getzep/graphiti\\n- FastAPI: https://fastapi.tiangolo.com/\\n- Neo4j: https://neo4j.com/\\n\"}},{\"tool_name\":\"finish_feature\",\"arguments\":{}}]}",
          "promptTokens": 60071,
          "completionTokens": 6390,
          "provider": "openai",
          "model": "gpt-5",
          "turn": 3,
          "askedAt": "2025-09-12T19:35:38.878Z",
          "completedAt": "2025-09-12T19:37:31.197Z"
        },
        {
          "role": "user",
          "content": "[{\"name\":\"read_files\",\"result\":\"{\\\"graphiti/graphiti_core/utils/maintenance/graph_data_operations.py\\\":\\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nCopyright 2024, Zep Software, Inc.\\\\n\\\\nLicensed under the Apache License, Version 2.0 (the \\\\\\\"License\\\\\\\");\\\\nyou may not use this file except in compliance with the License.\\\\nYou may obtain a copy of the License at\\\\n\\\\n    http://www.apache.org/licenses/LICENSE-2.0\\\\n\\\\nUnless required by applicable law or agreed to in writing, software\\\\ndistributed under the License is distributed on an \\\\\\\"AS IS\\\\\\\" BASIS,\\\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\nSee the License for the specific language governing permissions and\\\\nlimitations under the License.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport logging\\\\nfrom datetime import datetime\\\\n\\\\nfrom typing_extensions import LiteralString\\\\n\\\\nfrom graphiti_core.driver.driver import GraphDriver, GraphProvider\\\\nfrom graphiti_core.graph_queries import get_fulltext_indices, get_range_indices\\\\nfrom graphiti_core.helpers import semaphore_gather\\\\nfrom graphiti_core.models.nodes.node_db_queries import (\\\\n    EPISODIC_NODE_RETURN,\\\\n    EPISODIC_NODE_RETURN_NEPTUNE,\\\\n)\\\\nfrom graphiti_core.nodes import EpisodeType, EpisodicNode, get_episodic_node_from_record\\\\n\\\\nEPISODE_WINDOW_LEN = 3\\\\n\\\\nlogger = logging.getLogger(__name__)\\\\n\\\\n\\\\nasync def build_indices_and_constraints(driver: GraphDriver, delete_existing: bool = False):\\\\n    if driver.aoss_client:\\\\n        await driver.create_aoss_indices()  # pyright: ignore[reportAttributeAccessIssue]\\\\n        return\\\\n    if delete_existing:\\\\n        records, _, _ = await driver.execute_query(\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n            SHOW INDEXES YIELD name\\\\n            \\\\\\\"\\\\\\\"\\\\\\\",\\\\n        )\\\\n        index_names = [record['name'] for record in records]\\\\n        await semaphore_gather(\\\\n            *[\\\\n                driver.execute_query(\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"DROP INDEX $name\\\\\\\"\\\\\\\"\\\\\\\",\\\\n                    name=name,\\\\n                )\\\\n                for name in index_names\\\\n            ]\\\\n        )\\\\n\\\\n    range_indices: list[LiteralString] = get_range_indices(driver.provider)\\\\n\\\\n    # Don't create fulltext indices if OpenSearch is being used\\\\n    if not driver.aoss_client:\\\\n        fulltext_indices: list[LiteralString] = get_fulltext_indices(driver.provider)\\\\n\\\\n    if driver.provider == GraphProvider.KUZU:\\\\n        # Skip creating fulltext indices if they already exist. Need to do this manually\\\\n        # until Kuzu supports `IF NOT EXISTS` for indices.\\\\n        result, _, _ = await driver.execute_query('CALL SHOW_INDEXES() RETURN *;')\\\\n        if len(result) > 0:\\\\n            fulltext_indices = []\\\\n\\\\n        # Only load the `fts` extension if it's not already loaded, otherwise throw an error.\\\\n        result, _, _ = await driver.execute_query('CALL SHOW_LOADED_EXTENSIONS() RETURN *;')\\\\n        if len(result) == 0:\\\\n            fulltext_indices.insert(\\\\n                0,\\\\n                \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                INSTALL fts;\\\\n                LOAD fts;\\\\n                \\\\\\\"\\\\\\\"\\\\\\\",\\\\n            )\\\\n\\\\n    index_queries: list[LiteralString] = range_indices + fulltext_indices\\\\n\\\\n    await semaphore_gather(\\\\n        *[\\\\n            driver.execute_query(\\\\n                query,\\\\n            )\\\\n            for query in index_queries\\\\n        ]\\\\n    )\\\\n\\\\n\\\\nasync def clear_data(driver: GraphDriver, group_ids: list[str] | None = None):\\\\n    async with driver.session() as session:\\\\n\\\\n        async def delete_all(tx):\\\\n            await tx.run('MATCH (n) DETACH DELETE n')\\\\n\\\\n        async def delete_group_ids(tx):\\\\n            labels = ['Entity', 'Episodic', 'Community']\\\\n            if driver.provider == GraphProvider.KUZU:\\\\n                labels.append('RelatesToNode_')\\\\n\\\\n            for label in labels:\\\\n                await tx.run(\\\\n                    f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    MATCH (n:{label})\\\\n                    WHERE n.group_id IN $group_ids\\\\n                    DETACH DELETE n\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\",\\\\n                    group_ids=group_ids,\\\\n                )\\\\n\\\\n        if group_ids is None:\\\\n            await session.execute_write(delete_all)\\\\n        else:\\\\n            await session.execute_write(delete_group_ids)\\\\n\\\\n\\\\nasync def retrieve_episodes(\\\\n    driver: GraphDriver,\\\\n    reference_time: datetime,\\\\n    last_n: int = EPISODE_WINDOW_LEN,\\\\n    group_ids: list[str] | None = None,\\\\n    source: EpisodeType | None = None,\\\\n) -> list[EpisodicNode]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Retrieve the last n episodic nodes from the graph.\\\\n\\\\n    Args:\\\\n        driver (Driver): The Neo4j driver instance.\\\\n        reference_time (datetime): The reference time to filter episodes. Only episodes with a valid_at timestamp\\\\n                                   less than or equal to this reference_time will be retrieved. This allows for\\\\n                                   querying the graph's state at a specific point in time.\\\\n        last_n (int, optional): The number of most recent episodes to retrieve, relative to the reference_time.\\\\n        group_ids (list[str], optional): The list of group ids to return data from.\\\\n\\\\n    Returns:\\\\n        list[EpisodicNode]: A list of EpisodicNode objects representing the retrieved episodes.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    query_params: dict = {}\\\\n    query_filter = ''\\\\n    if group_ids and len(group_ids) > 0:\\\\n        query_filter += '\\\\\\\\nAND e.group_id IN $group_ids'\\\\n        query_params['group_ids'] = group_ids\\\\n\\\\n    if source is not None:\\\\n        query_filter += '\\\\\\\\nAND e.source = $source'\\\\n        query_params['source'] = source.name\\\\n\\\\n    query: LiteralString = (\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n                    MATCH (e:Episodic)\\\\n                    WHERE e.valid_at <= $reference_time\\\\n                    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        + query_filter\\\\n        + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        RETURN\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        + (\\\\n            EPISODIC_NODE_RETURN_NEPTUNE\\\\n            if driver.provider == GraphProvider.NEPTUNE\\\\n            else EPISODIC_NODE_RETURN\\\\n        )\\\\n        + \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        ORDER BY e.valid_at DESC\\\\n        LIMIT $num_episodes\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    )\\\\n    result, _, _ = await driver.execute_query(\\\\n        query,\\\\n        reference_time=reference_time,\\\\n        num_episodes=last_n,\\\\n        **query_params,\\\\n    )\\\\n\\\\n    episodes = [get_episodic_node_from_record(record) for record in result]\\\\n    return list(reversed(episodes))  # Return in chronological order\\\\n\\\"}\"},{\"name\":\"write_file\",\"result\":\"File securely written to: src/graph_service.py\"},{\"name\":\"write_file\",\"result\":\"File securely written to: src/main.py\"},{\"name\":\"write_file\",\"result\":\"File securely written to: README.md\"},{\"name\":\"finish_feature\",\"result\":\"Feature 6e697fe2-b9d8-41b6-b7ac-ffad70689109 finished by developer and changes committed.\"}]",
          "turn": 3,
          "askedAt": "2025-09-12T19:37:31.207Z",
          "completedAt": "2025-09-12T19:37:32.573Z",
          "source": "tools",
          "promptTokens": 0,
          "completionTokens": 0
        }
      ],
      "state": "completed",
      "startedAt": "2025-09-12T19:35:22.798Z",
      "updatedAt": "2025-09-12T19:37:32.575Z",
      "finishedAt": "2025-09-12T19:37:32.575Z"
    }
  ],
  "startedAt": "2025-09-12T19:35:20.545Z",
  "updatedAt": "2025-09-13T17:16:56.648Z",
  "id": "run_xby6ku90_mfh8lq01",
  "projectId": "thefactory-knowledge",
  "taskId": "f72dbcdb-77e7-4d00-bf72-e2cc59271644",
  "llmConfig": {
    "provider": "openai",
    "model": "gpt-5",
    "apiBaseUrl": "https://api.openai.com/v1/chat/completions"
  },
  "price": {
    "inputPerMTokensUSD": 1.25,
    "outputPerMTokensUSD": 10
  },
  "finishedAt": "2025-09-12T19:37:32.926Z",
  "rating": {
    "score": 1,
    "createdAt": "2025-09-13T17:16:56.648Z"
  }
}